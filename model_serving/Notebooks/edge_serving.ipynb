{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf92fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in /opt/anaconda3/lib/python3.12/site-packages (0.5.1)\n",
      "Requirement already satisfied: soundfile in /opt/anaconda3/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: librosa in /opt/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: onnxruntime in /opt/anaconda3/lib/python3.12/site-packages (1.22.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sounddevice) (1.16.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.59.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: coloredlogs in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime) (25.1.24)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime) (4.25.6)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/anaconda3/lib/python3.12/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install sounddevice soundfile numpy librosa onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51391221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording... Press ENTER to stop.\n",
      "Recording saved to recorded.wav\n",
      "Running inference on 1 chunks...\n",
      "[Chunk 1] Class: 97 | Conf: 0.4661 | Median Latency: 74.23ms | Mean Latency: 90.33ms | 95th Percentile Latency: 161.13ms | FPS: 11.07 FPS\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import queue\n",
    "import threading\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import onnxruntime as ort\n",
    "\n",
    "# === Constants ===\n",
    "NUM_CLASSES = 206\n",
    "EMB_DIM = 2048\n",
    "MEL_SHAPE = (1, 64, 313)\n",
    "WAV_LEN = 320000\n",
    "FUSION_DIM = NUM_CLASSES * 4\n",
    "SAMPLE_RATE = 16000\n",
    "CHUNK_DURATION = 10\n",
    "INPUT_LEN = SAMPLE_RATE * CHUNK_DURATION\n",
    "NUM_TRIALS = 10  # Number of inference trials per chunk\n",
    "\n",
    "# === ONNX Model Paths ===\n",
    "MODEL_PATHS = {\n",
    "    \"embedding\":    \"embedding_quantized.onnx\",\n",
    "    \"resnet\":       \"resnet_quantized.onnx\",\n",
    "    \"efficientnet\": \"effnet_quantized.onnx\",\n",
    "    \"rawaudio\":     \"rawaudio_quantized.onnx\",\n",
    "    \"meta\":         \"meta_quantized.onnx\"\n",
    "}\n",
    "\n",
    "# === Load ONNX Sessions ===\n",
    "sessions = {k: ort.InferenceSession(v, providers=[\"CPUExecutionProvider\"]) for k, v in MODEL_PATHS.items()}\n",
    "\n",
    "# === Normalize waveform ===\n",
    "def normalize(wav):\n",
    "    mean = wav.mean()\n",
    "    std = wav.std() if wav.std() > 1e-6 else 1e-6\n",
    "    return (wav - mean) / std\n",
    "\n",
    "# === Extract mel spectrogram ===\n",
    "def extract_mel_tensor(wav, height=64, width=313):\n",
    "    mel = librosa.feature.melspectrogram(y=wav, sr=SAMPLE_RATE, n_fft=1024, hop_length=512, n_mels=height)\n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    mel_norm = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-6)\n",
    "\n",
    "    if mel_norm.shape[1] < width:\n",
    "        mel_norm = np.pad(mel_norm, ((0, 0), (0, width - mel_norm.shape[1])))\n",
    "    else:\n",
    "        mel_norm = mel_norm[:, :width]\n",
    "\n",
    "    return mel_norm.astype(np.float32).reshape(1, 1, height, width)\n",
    "\n",
    "# === Extract pooled embedding from mel ===\n",
    "def extract_embedding_from_mel(mel_tensor):\n",
    "    pooled = mel_tensor.squeeze(0).squeeze(0).mean(axis=1)\n",
    "    emb = np.pad(pooled, (0, EMB_DIM - pooled.shape[0]), mode='constant')  # zero-pad to EMB_DIM\n",
    "    return emb.reshape(1, -1).astype(np.float32)\n",
    "\n",
    "# === Inference over multiple trials with timing ===\n",
    "def run_full_inference(wav_chunk, num_trials=NUM_TRIALS):\n",
    "    wav = normalize(wav_chunk).astype(np.float32)\n",
    "    if wav.shape[0] < WAV_LEN:\n",
    "        wav = np.pad(wav, (0, WAV_LEN - wav.shape[0]))\n",
    "    wav = wav[:WAV_LEN].reshape(1, -1)\n",
    "\n",
    "    mel_tensor = extract_mel_tensor(wav_chunk, height=MEL_SHAPE[1], width=MEL_SHAPE[2])\n",
    "    mel_aug_tensor = mel_tensor.copy()\n",
    "    emb = extract_embedding_from_mel(mel_tensor)\n",
    "\n",
    "    input_dicts = {\n",
    "        \"embedding\":    {sessions[\"embedding\"].get_inputs()[0].name: emb},\n",
    "        \"resnet\":       {sessions[\"resnet\"].get_inputs()[0].name: mel_aug_tensor},\n",
    "        \"efficientnet\": {sessions[\"efficientnet\"].get_inputs()[0].name: mel_tensor},\n",
    "        \"rawaudio\":     {sessions[\"rawaudio\"].get_inputs()[0].name: wav}\n",
    "    }\n",
    "\n",
    "    latencies = []\n",
    "    for _ in range(num_trials):\n",
    "        t0 = time.time()\n",
    "        emb_out = sessions[\"embedding\"].run(None, input_dicts[\"embedding\"])[0]\n",
    "        res_out = sessions[\"resnet\"].run(None, input_dicts[\"resnet\"])[0]\n",
    "        eff_out = sessions[\"efficientnet\"].run(None, input_dicts[\"efficientnet\"])[0]\n",
    "        raw_out = sessions[\"rawaudio\"].run(None, input_dicts[\"rawaudio\"])[0]\n",
    "\n",
    "        fused = np.concatenate([emb_out, res_out, eff_out, raw_out], axis=1).astype(np.float32)\n",
    "        _ = sessions[\"meta\"].run(None, {sessions[\"meta\"].get_inputs()[0].name: fused})[0]\n",
    "        latencies.append((time.time() - t0) * 1000)\n",
    "\n",
    "    # Final prediction (use last run)\n",
    "    meta_out = sessions[\"meta\"].run(None, {sessions[\"meta\"].get_inputs()[0].name: fused})[0]\n",
    "\n",
    "    return meta_out, {\n",
    "        \"median_ms\": np.median(latencies),\n",
    "        \"mean_ms\": np.mean(latencies),\n",
    "        \"p95_ms\": np.percentile(latencies, 95),\n",
    "        \"fps\": 1000.0 / np.mean(latencies)\n",
    "    }\n",
    "\n",
    "# === Record audio until ENTER ===\n",
    "print(\"Recording... Press ENTER to stop.\")\n",
    "audio_q = queue.Queue()\n",
    "flag = {\"stop\": False}\n",
    "\n",
    "def key_listener():\n",
    "    input()\n",
    "    flag[\"stop\"] = True\n",
    "\n",
    "def audio_callback(indata, frames, time_info, status):\n",
    "    audio_q.put(indata.copy())\n",
    "\n",
    "threading.Thread(target=key_listener, daemon=True).start()\n",
    "\n",
    "buffer = []\n",
    "with sd.InputStream(callback=audio_callback, channels=1, samplerate=SAMPLE_RATE):\n",
    "    while not flag[\"stop\"]:\n",
    "        buffer.append(audio_q.get())\n",
    "\n",
    "audio = np.concatenate(buffer, axis=0).squeeze()\n",
    "sf.write(\"recorded.wav\", audio, SAMPLE_RATE)\n",
    "print(\"Recording saved to recorded.wav\")\n",
    "\n",
    "# === Split into 10s chunks ===\n",
    "chunks = []\n",
    "for i in range(0, len(audio), INPUT_LEN):\n",
    "    clip = audio[i:i+INPUT_LEN]\n",
    "    if len(clip) < INPUT_LEN:\n",
    "        clip = np.pad(clip, (0, INPUT_LEN - len(clip)))\n",
    "    chunks.append(clip)\n",
    "\n",
    "print(f\"Running inference on {len(chunks)} chunks...\")\n",
    "\n",
    "# === Inference per chunk ===\n",
    "for idx, clip in enumerate(chunks):\n",
    "    meta_out, stats = run_full_inference(clip)\n",
    "    pred = int(np.argmax(meta_out))\n",
    "    conf = float(np.max(meta_out))\n",
    "    print(\n",
    "        f\"[Chunk {idx+1}] Class: {pred} | Conf: {conf:.4f} | \"\n",
    "        f\"Median Latency: {stats['median_ms']:.2f}ms | \"\n",
    "        f\"Mean Latency: {stats['mean_ms']:.2f}ms | \"\n",
    "        f\"95th Percentile Latency: {stats['p95_ms']:.2f}ms | \"\n",
    "        f\"FPS: {stats['fps']:.2f} FPS\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d68a6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ea41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a1b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
