{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74516879-cdfe-411e-a2ba-cbc0fb002bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from peft) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from peft) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.12/site-packages (from peft) (2.5.1+cu124)\n",
      "Collecting transformers (from peft)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Collecting accelerate>=0.21.0 (from peft)\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.12/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.12/site-packages (from peft) (0.31.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2024.12.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Collecting regex!=2019.12.17 (from transformers->peft)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers->peft)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.12.14)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: regex, tokenizers, transformers, accelerate, peft\n",
      "Successfully installed accelerate-1.6.0 peft-0.15.2 regex-2024.11.6 tokenizers-0.21.1 transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa0126ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grad-cam in /opt/conda/lib/python3.12/site-packages (1.5.5)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.12/site-packages (8.3.5)\n",
      "Collecting SHAP\n",
      "  Downloading shap-0.47.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from grad-cam) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from grad-cam) (11.1.0)\n",
      "Requirement already satisfied: torch>=1.7.1 in /opt/conda/lib/python3.12/site-packages (from grad-cam) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in /opt/conda/lib/python3.12/site-packages (from grad-cam) (0.20.1+cu124)\n",
      "Requirement already satisfied: ttach in /opt/conda/lib/python3.12/site-packages (from grad-cam) (0.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from grad-cam) (4.67.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.12/site-packages (from grad-cam) (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (from grad-cam) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from grad-cam) (1.6.1)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.12/site-packages (from pytest) (2.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from pytest) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/conda/lib/python3.12/site-packages (from pytest) (1.5.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from SHAP) (1.15.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from SHAP) (2.2.3)\n",
      "Collecting slicer==0.0.8 (from SHAP)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba>=0.54 in /opt/conda/lib/python3.12/site-packages (from SHAP) (0.60.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.12/site-packages (from SHAP) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.12/site-packages (from SHAP) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.12/site-packages (from numba>=0.54->SHAP) (0.43.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (3.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.7.1->grad-cam) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib->grad-cam) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->SHAP) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->SHAP) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->grad-cam) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->grad-cam) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->grad-cam) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n",
      "Downloading shap-0.47.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, SHAP\n",
      "Successfully installed SHAP-0.47.2 slicer-0.0.8\n"
     ]
    }
   ],
   "source": [
    "!pip install grad-cam pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a400c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from random import sample as rand_sample\n",
    "from sklearn.metrics import accuracy_score\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import timm\n",
    "\n",
    "5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57fa4db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_MANIFEST = \"/mnt/BirdCLEF-2025/birdclef_dataset/features_sampled/manifest_test.csv\"\n",
    "TAXONOMY_CSV = \"/mnt/BirdCLEF-2025/birdclef_dataset/features_sampled/taxonomy.csv\"\n",
    "FEATURE_BASE = \"/mnt/BirdCLEF-2025/birdclef_dataset/features_sampled\"\n",
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DROPOUT = 0.3\n",
    "THRESHOLD   = 0.5\n",
    "\n",
    "NUM_CLASSES = 206\n",
    "WAV_LEN = 320000\n",
    "MEL_SHAPE = (1, 64, 313)\n",
    "HIDDEN_DIMS = [1024, 512]\n",
    "THRESHOLD   = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5af226a1-73d5-4ce7-93e4-d00820327480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/jovyan/.cache/torch/hub/pytorch_vision_v0.14.0\n",
      "/home/jovyan/.cache/torch/hub/pytorch_vision_v0.14.0/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.cache/torch/hub/pytorch_vision_v0.14.0/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_7214/4232278570.py:122: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
      "/tmp/ipykernel_7214/4232278570.py:128: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta_model.load_state_dict(torch.load(CKPT_META, map_location=DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MetaMLP(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=824, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=512, out_features=206, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASSES = sorted(tax[\"primary_label\"].astype(str).tolist())\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "#CELL 4\n",
    "class MetaMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dims, dropout):\n",
    "        super().__init__()\n",
    "        layers, dims = [], [in_dim]+hidden_dims\n",
    "        for i in range(len(hidden_dims)):\n",
    "            layers += [\n",
    "                nn.Linear(dims[i], dims[i+1]),\n",
    "                nn.BatchNorm1d(dims[i+1]),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout)\n",
    "            ]\n",
    "        layers.append(nn.Linear(dims[-1], NUM_CLASSES))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "#CELL 5\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, emb_dim, num_cls):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2048), nn.BatchNorm1d(2048), nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(2048, 1024),    nn.BatchNorm1d(1024), nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(1024, 512),     nn.BatchNorm1d(512),  nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(512, num_cls)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "def get_resnet50_multilabel(num_classes):\n",
    "    m = torch.hub.load('pytorch/vision:v0.14.0', 'resnet50', pretrained=False)\n",
    "    m.conv1 = nn.Conv2d(1, m.conv1.out_channels,\n",
    "                        kernel_size=m.conv1.kernel_size,\n",
    "                        stride=m.conv1.stride,\n",
    "                        padding=m.conv1.padding,\n",
    "                        bias=False)\n",
    "    m.fc    = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m\n",
    "\n",
    "TARGET_MODULES  = [\"conv_pw\",\"conv_dw\",\"conv_pwl\",\"conv_head\"]\n",
    "MODULES_TO_SAVE = [\"classifier\"]\n",
    "def build_efficientnetb3_lora(num_classes):\n",
    "    base = timm.create_model(\"efficientnet_b3\", pretrained=True)\n",
    "    # patch forward\n",
    "    orig_fwd = base.forward\n",
    "    def forward_patch(*args, input_ids=None, **kwargs):\n",
    "        x = input_ids if input_ids is not None else args[0]\n",
    "        return orig_fwd(x)\n",
    "    base.forward = forward_patch\n",
    "    # adapt stem & head\n",
    "    stem = base.conv_stem\n",
    "    base.conv_stem = nn.Conv2d(1, stem.out_channels,\n",
    "                               kernel_size=stem.kernel_size,\n",
    "                               stride=stem.stride,\n",
    "                               padding=stem.padding,\n",
    "                               bias=False)\n",
    "    base.classifier = nn.Linear(base.classifier.in_features, num_classes)\n",
    "    # LoRA\n",
    "    lora_cfg = LoraConfig(\n",
    "        r=12, lora_alpha=24,\n",
    "        target_modules=TARGET_MODULES,\n",
    "        lora_dropout=0.1, bias=\"none\",\n",
    "        modules_to_save=MODULES_TO_SAVE,\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=False\n",
    "    )\n",
    "    return get_peft_model(base, lora_cfg)\n",
    "\n",
    "class RawAudioCNN(nn.Module):\n",
    "    def __init__(self, num_cls):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16,  kernel_size=15, stride=4, padding=7)\n",
    "        self.bn1   = nn.BatchNorm1d(16)\n",
    "        self.pool  = nn.MaxPool1d(4)\n",
    "        self.conv2 = nn.Conv1d(16,32,  kernel_size=15, stride=2, padding=7)\n",
    "        self.bn2   = nn.BatchNorm1d(32)\n",
    "        self.conv3 = nn.Conv1d(32,64,  kernel_size=15, stride=2, padding=7)\n",
    "        self.bn3   = nn.BatchNorm1d(64)\n",
    "        self.conv4 = nn.Conv1d(64,128, kernel_size=15, stride=2, padding=7)\n",
    "        self.bn4   = nn.BatchNorm1d(128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc          = nn.Linear(128, num_cls)\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # [B,T]→[B,1,T]\n",
    "        x = F.relu(self.bn1(self.conv1(x))); x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.global_pool(x).squeeze(-1)\n",
    "        return self.fc(x)\n",
    "# === Step 1: Get emb_dim ===\n",
    "class EmbeddingDatasetForDim:\n",
    "    def __init__(self, manifest, base, key=\"embedding\"):\n",
    "        df = pd.read_csv(manifest)\n",
    "        df[\"emb_path\"] = df[\"emb_path\"].astype(str).apply(\n",
    "            lambda p: os.path.join(base, \"embeddings\", p.lstrip(os.sep))\n",
    "        )\n",
    "        first_sample_path = df.iloc[0].emb_path\n",
    "        arr = np.load(first_sample_path)[key]  # shape: (n_windows, emb_dim)\n",
    "        self.emb_dim = arr.shape[1]\n",
    "\n",
    "_emb_ds = EmbeddingDatasetForDim(TEST_MANIFEST, FEATURE_BASE)\n",
    "emb_dim = _emb_ds.emb_dim\n",
    "\n",
    "# === Step 2: Instantiate all models ===\n",
    "emb_model  = EmbeddingClassifier(emb_dim=emb_dim, num_cls=NUM_CLASSES).to(DEVICE)\n",
    "res_model  = get_resnet50_multilabel(NUM_CLASSES).to(DEVICE)\n",
    "eff_model  = build_efficientnetb3_lora(NUM_CLASSES).to(DEVICE)\n",
    "raw_model  = RawAudioCNN(NUM_CLASSES).to(DEVICE)\n",
    "meta_model = MetaMLP(NUM_CLASSES * 4, HIDDEN_DIMS, DROPOUT).to(DEVICE)\n",
    "\n",
    "# === Step 3: Load weights & freeze base models ===\n",
    "for model, ckpt in [\n",
    "    (emb_model, CKPT_EMB),\n",
    "    (res_model, CKPT_RES),\n",
    "    (eff_model, CKPT_EFF),\n",
    "    (raw_model, CKPT_RAW)\n",
    "]:\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=\"cpu\"))\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# === Step 4: Load meta model weights (not frozen) ===\n",
    "meta_model.load_state_dict(torch.load(CKPT_META, map_location=DEVICE))\n",
    "meta_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d07b8afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax = pd.read_csv(TAXONOMY_CSV)\n",
    "CLASSES = sorted(tax[\"primary_label\"].astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b5bfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_manifest = pd.read_csv(TEST_MANIFEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d425d9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# === Update checkpoint paths ===\n",
    "\n",
    "\n",
    "# === Inference sample preprocessor ===\n",
    "def preprocess_sample(sample):\n",
    "    emb_path = os.path.join(FEATURE_BASE, \"embeddings\", sample.emb_path.lstrip(\"/\"))\n",
    "    emb_arr = np.load(emb_path)[\"embedding\"].mean(axis=0).astype(np.float32)\n",
    "    emb = torch.from_numpy(emb_arr).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    ma_path = os.path.join(FEATURE_BASE, \"mel_aug\", sample.mel_aug_path.lstrip(\"/\"))\n",
    "    ma_arr = np.load(ma_path)[\"mel\"].astype(np.float32)\n",
    "    ma = torch.from_numpy(ma_arr).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    m_path = os.path.join(FEATURE_BASE, \"mel\", sample.mel_path.lstrip(\"/\"))\n",
    "    m_arr = np.load(m_path)[\"mel\"].astype(np.float32)\n",
    "    m = torch.from_numpy(m_arr).unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    wav_path = os.path.join(FEATURE_BASE, \"denoised\", sample.audio_path.lstrip(\"/\"))\n",
    "    if not os.path.exists(wav_path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {wav_path}\")\n",
    "    wav, sr = torchaudio.load(wav_path)\n",
    "    wav = wav.mean(dim=0) if wav.dim() > 1 else wav\n",
    "    T = sr * 10\n",
    "    wav = F.pad(wav, (0, max(0, T - wav.size(0))))[:T]\n",
    "    wav = (wav - wav.mean()) / wav.std().clamp_min(1e-6)\n",
    "    wav = wav.unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    return emb, ma, m, wav\n",
    "\n",
    "# === Inference function ===\n",
    "def run_full_inference(sample):\n",
    "    emb, ma, m, wav = preprocess_sample(sample)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        p1 = torch.sigmoid(emb_model(emb))   # Embedding MLP\n",
    "        p2 = torch.sigmoid(res_model(ma))    # ResNet (mel_aug)\n",
    "        p3 = torch.sigmoid(eff_model(m))     # EfficientNet (mel)\n",
    "        p4 = torch.sigmoid(raw_model(wav))   # Raw waveform CNN\n",
    "\n",
    "        feat = torch.cat([p1, p2, p3, p4], dim=1)\n",
    "        logits = meta_model(feat)\n",
    "        probs = torch.sigmoid(logits)[0].cpu().numpy()\n",
    "\n",
    "    return probs  # shape: (NUM_CLASSES,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fc8e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "class_names = sorted(test_manifest[\"primary_label\"].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(class_names)}\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "class_hits = defaultdict(int)\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "for idx, row in test_manifest.head(200).iterrows():\n",
    "    try:\n",
    "        true_label = label2id[row[\"primary_label\"]]\n",
    "        probs = run_full_inference(row)\n",
    "        pred_label = int(np.argmax(probs))\n",
    "\n",
    "        class_counts[true_label] += 1\n",
    "        if pred_label == true_label:\n",
    "            total_correct += 1\n",
    "            class_hits[true_label] += 1\n",
    "        total_samples += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab352c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Overall Accuracy: 0.0000 (0/200)\n",
      "\n",
      " Top 20 Least Accurate Classes:\n",
      "1139490                        Acc: 0.0000\n",
      "1192948                        Acc: 0.0000\n",
      "1194042                        Acc: 0.0000\n",
      "126247                         Acc: 0.0000\n",
      "1346504                        Acc: 0.0000\n",
      "134933                         Acc: 0.0000\n",
      "135045                         Acc: 0.0000\n",
      "1462711                        Acc: 0.0000\n",
      "1462737                        Acc: 0.0000\n",
      "1564122                        Acc: 0.0000\n",
      "21038                          Acc: 0.0000\n",
      "21116                          Acc: 0.0000\n",
      "21211                          Acc: 0.0000\n",
      "22333                          Acc: 0.0000\n",
      "22973                          Acc: 0.0000\n",
      "22976                          Acc: 0.0000\n",
      "24272                          Acc: 0.0000\n",
      "24292                          Acc: 0.0000\n",
      "24322                          Acc: 0.0000\n",
      "41663                          Acc: 0.0000\n",
      "41778                          Acc: 0.0000\n",
      "41970                          Acc: 0.0000\n",
      "42007                          Acc: 0.0000\n",
      "42087                          Acc: 0.0000\n",
      "42113                          Acc: 0.0000\n",
      "46010                          Acc: 0.0000\n",
      "47067                          Acc: 0.0000\n",
      "476537                         Acc: 0.0000\n",
      "476538                         Acc: 0.0000\n",
      "48124                          Acc: 0.0000\n",
      "50186                          Acc: 0.0000\n",
      "517119                         Acc: 0.0000\n",
      "523060                         Acc: 0.0000\n",
      "528041                         Acc: 0.0000\n",
      "52884                          Acc: 0.0000\n",
      "548639                         Acc: 0.0000\n",
      "555086                         Acc: 0.0000\n",
      "555142                         Acc: 0.0000\n",
      "566513                         Acc: 0.0000\n",
      "64862                          Acc: 0.0000\n",
      "65336                          Acc: 0.0000\n",
      "65344                          Acc: 0.0000\n",
      "65349                          Acc: 0.0000\n",
      "65373                          Acc: 0.0000\n",
      "65419                          Acc: 0.0000\n",
      "65448                          Acc: 0.0000\n",
      "65547                          Acc: 0.0000\n",
      "65962                          Acc: 0.0000\n",
      "66016                          Acc: 0.0000\n",
      "66531                          Acc: 0.0000\n",
      "66578                          Acc: 0.0000\n",
      "66893                          Acc: 0.0000\n",
      "67082                          Acc: 0.0000\n",
      "67252                          Acc: 0.0000\n",
      "714022                         Acc: 0.0000\n",
      "715170                         Acc: 0.0000\n",
      "787625                         Acc: 0.0000\n",
      "81930                          Acc: 0.0000\n",
      "868458                         Acc: 0.0000\n",
      "963335                         Acc: 0.0000\n",
      "amakin1                        Acc: 0.0000\n",
      "amekes                         Acc: 0.0000\n",
      "ampkin1                        Acc: 0.0000\n",
      "anhing                         Acc: 0.0000\n",
      "babwar                         Acc: 0.0000\n",
      "bafibi1                        Acc: 0.0000\n",
      "banana                         Acc: 0.0000\n",
      "baymac                         Acc: 0.0000\n",
      "bbwduc                         Acc: 0.0000\n",
      "bicwre1                        Acc: 0.0000\n",
      "bkcdon                         Acc: 0.0000\n",
      "bkmtou1                        Acc: 0.0000\n",
      "blbgra1                        Acc: 0.0000\n",
      "blbwre1                        Acc: 0.0000\n",
      "blcant4                        Acc: 0.0000\n",
      "blchaw1                        Acc: 0.0000\n",
      "blcjay1                        Acc: 0.0000\n",
      "blctit1                        Acc: 0.0000\n",
      "blhpar1                        Acc: 0.0000\n",
      "blkvul                         Acc: 0.0000\n",
      "bobfly1                        Acc: 0.0000\n",
      "bobher1                        Acc: 0.0000\n",
      "brtpar1                        Acc: 0.0000\n",
      "bubcur1                        Acc: 0.0000\n",
      "bubwre1                        Acc: 0.0000\n",
      "bucmot3                        Acc: 0.0000\n",
      "bugtan                         Acc: 0.0000\n",
      "butsal1                        Acc: 0.0000\n",
      "cargra1                        Acc: 0.0000\n",
      "cattyr                         Acc: 0.0000\n",
      "chbant1                        Acc: 0.0000\n",
      "chfmac1                        Acc: 0.0000\n",
      "cinbec1                        Acc: 0.0000\n",
      "cocher1                        Acc: 0.0000\n",
      "cocwoo1                        Acc: 0.0000\n",
      "colara1                        Acc: 0.0000\n",
      "colcha1                        Acc: 0.0000\n",
      "compau                         Acc: 0.0000\n",
      "compot1                        Acc: 0.0000\n",
      "cotfly1                        Acc: 0.0000\n",
      "crbtan1                        Acc: 0.0000\n",
      "crcwoo1                        Acc: 0.0000\n",
      "crebob1                        Acc: 0.0000\n",
      "cregua1                        Acc: 0.0000\n",
      "creoro1                        Acc: 0.0000\n",
      "eardov1                        Acc: 0.0000\n",
      "fotfly                         Acc: 0.0000\n",
      "gohman1                        Acc: 0.0000\n",
      "grasal4                        Acc: 0.0000\n",
      "grbhaw1                        Acc: 0.0000\n",
      "greani1                        Acc: 0.0000\n",
      "greegr                         Acc: 0.0000\n",
      "greibi1                        Acc: 0.0000\n",
      "grekis                         Acc: 0.0000\n",
      "grepot1                        Acc: 0.0000\n",
      "gretin1                        Acc: 0.0000\n",
      "grnkin                         Acc: 0.0000\n",
      "grysee1                        Acc: 0.0000\n",
      "gybmar                         Acc: 0.0000\n",
      "gycwor1                        Acc: 0.0000\n",
      "labter1                        Acc: 0.0000\n",
      "laufal1                        Acc: 0.0000\n",
      "leagre                         Acc: 0.0000\n",
      "linwoo1                        Acc: 0.0000\n",
      "littin1                        Acc: 0.0000\n",
      "mastit1                        Acc: 0.0000\n",
      "neocor                         Acc: 0.0000\n",
      "norscr1                        Acc: 0.0000\n",
      "olipic1                        Acc: 0.0000\n",
      "orcpar                         Acc: 0.0000\n",
      "palhor2                        Acc: 0.0000\n",
      "paltan1                        Acc: 0.0000\n",
      "pavpig2                        Acc: 0.0000\n",
      "piepuf1                        Acc: 0.0000\n",
      "pirfly1                        Acc: 0.0000\n",
      "piwtyr1                        Acc: 0.0000\n",
      "plbwoo1                        Acc: 0.0000\n",
      "plctan1                        Acc: 0.0000\n",
      "plukit1                        Acc: 0.0000\n",
      "purgal2                        Acc: 0.0000\n",
      "ragmac1                        Acc: 0.0000\n",
      "rebbla1                        Acc: 0.0000\n",
      "recwoo1                        Acc: 0.0000\n",
      "rinkin1                        Acc: 0.0000\n",
      "roahaw                         Acc: 0.0000\n",
      "rosspo1                        Acc: 0.0000\n",
      "royfly1                        Acc: 0.0000\n",
      "rtlhum                         Acc: 0.0000\n",
      "rubsee1                        Acc: 0.0000\n",
      "rufmot1                        Acc: 0.0000\n",
      "rugdov                         Acc: 0.0000\n",
      "rumfly1                        Acc: 0.0000\n",
      "ruther1                        Acc: 0.0000\n",
      "rutjac1                        Acc: 0.0000\n",
      "rutpuf1                        Acc: 0.0000\n",
      "saffin                         Acc: 0.0000\n",
      "sahpar1                        Acc: 0.0000\n",
      "savhaw1                        Acc: 0.0000\n",
      "secfly1                        Acc: 0.0000\n",
      "shghum1                        Acc: 0.0000\n",
      "shtfly1                        Acc: 0.0000\n",
      "smbani                         Acc: 0.0000\n",
      "snoegr                         Acc: 0.0000\n",
      "sobtyr1                        Acc: 0.0000\n",
      "socfly1                        Acc: 0.0000\n",
      "solsan                         Acc: 0.0000\n",
      "soulap1                        Acc: 0.0000\n",
      "spbwoo1                        Acc: 0.0000\n",
      "speowl1                        Acc: 0.0000\n",
      "spepar1                        Acc: 0.0000\n",
      "srwswa1                        Acc: 0.0000\n",
      "stbwoo2                        Acc: 0.0000\n",
      "strcuc1                        Acc: 0.0000\n",
      "strfly1                        Acc: 0.0000\n",
      "strher                         Acc: 0.0000\n",
      "strowl1                        Acc: 0.0000\n",
      "tbsfin1                        Acc: 0.0000\n",
      "thbeup1                        Acc: 0.0000\n",
      "thlsch3                        Acc: 0.0000\n",
      "trokin                         Acc: 0.0000\n",
      "tropar                         Acc: 0.0000\n",
      "trsowl                         Acc: 0.0000\n",
      "turvul                         Acc: 0.0000\n",
      "verfly                         Acc: 0.0000\n",
      "watjac1                        Acc: 0.0000\n",
      "wbwwre1                        Acc: 0.0000\n",
      "whbant1                        Acc: 0.0000\n",
      "whbman1                        Acc: 0.0000\n",
      "whfant1                        Acc: 0.0000\n",
      "whmtyr1                        Acc: 0.0000\n",
      "whtdov                         Acc: 0.0000\n",
      "whttro1                        Acc: 0.0000\n",
      "whwswa1                        Acc: 0.0000\n",
      "woosto                         Acc: 0.0000\n",
      "y00678                         Acc: 0.0000\n",
      "yebela1                        Acc: 0.0000\n",
      "yebfly1                        Acc: 0.0000\n",
      "yebsee1                        Acc: 0.0000\n",
      "yecspi2                        Acc: 0.0000\n",
      "yectyr1                        Acc: 0.0000\n",
      "yehbla2                        Acc: 0.0000\n",
      "yehcar1                        Acc: 0.0000\n",
      "yelori1                        Acc: 0.0000\n",
      "yeofly1                        Acc: 0.0000\n",
      "yercac1                        Acc: 0.0000\n",
      "ywcpar                         Acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "overall_acc = total_correct / total_samples\n",
    "print(f\"\\n Overall Accuracy: {overall_acc:.4f} ({total_correct}/{total_samples})\")\n",
    "\n",
    "per_class_acc = {\n",
    "    CLASSES[i]: class_hits[i] / class_counts[i] if class_counts[i] > 0 else 0.0\n",
    "    for i in range(NUM_CLASSES)\n",
    "}\n",
    "\n",
    "least_accurate = sorted(per_class_acc.items(), key=lambda x: x[1])[:]\n",
    "\n",
    "print(\"\\n Top 20 Least Accurate Classes:\")\n",
    "for cls, acc in least_accurate:\n",
    "    print(f\"{cls:<30} Acc: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833ae3a6-25e9-42ce-a461-b03f2da9a588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure model is in eval mode\n",
    "emb_model.eval()\n",
    "emb_model.to(DEVICE)\n",
    "\n",
    "# === Wrapper for emb_model ===\n",
    "def model_wrapper(emb_batch):\n",
    "    if isinstance(emb_batch, list):\n",
    "        emb_batch = np.stack(emb_batch)\n",
    "    tensor = torch.tensor(emb_batch, dtype=torch.float32).to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = emb_model(tensor)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "# === Load embedding vector from row ===\n",
    "def get_embedding_vector(row):\n",
    "    emb_path = os.path.join(FEATURE_BASE, \"embeddings\", row.emb_path.lstrip(\"/\"))\n",
    "    emb = np.load(emb_path)[\"embedding\"].mean(axis=0).astype(np.float32)\n",
    "    return emb\n",
    "\n",
    "# === Load manifest if needed ===\n",
    "if 'test_manifest' not in globals():\n",
    "    TEST_MANIFEST = os.path.join(FEATURE_BASE, \"manifest_test.csv\")\n",
    "    test_manifest = pd.read_csv(TEST_MANIFEST)\n",
    "\n",
    "# === SHAP Input Data ===\n",
    "background_samples = np.array([get_embedding_vector(test_manifest.iloc[i]) for i in range(5)])\n",
    "test_sample = get_embedding_vector(test_manifest.iloc[42])\n",
    "\n",
    "# === SHAP Explainer ===\n",
    "masker = shap.maskers.Partition(background_samples)\n",
    "explainer = shap.Explainer(model_wrapper, masker, algorithm=\"partition\")\n",
    "\n",
    "# === Visualize SHAP ===\n",
    "shap_values = explainer([test_sample])\n",
    "shap.plots.waterfall(shap_values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586d8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CUSTOM_TEST_ROOT = \"/mnt/BirdCLEF/custom_templates\"\n",
    "def evaluate_with_ground_truth(folder_name):\n",
    "    folder_path = os.path.join(CUSTOM_TEST_ROOT, folder_name)\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if not fname.endswith(\".wav\"): continue\n",
    "        path = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            wav = preprocess_sample(path)\n",
    "            logits = run_full_inference(wav)\n",
    "            pred_label = int(torch.argmax(logits))\n",
    "            y_pred.append(pred_label)\n",
    "            y_true.append(CLASSES.index(folder_name))  # use folder name as ground truth\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {fname}: {e}\")\n",
    "    \n",
    "    return y_true, y_pred\n",
    "\n",
    "print(\"\\nAccuracy per template folder:\\n\")\n",
    "for group in [\"insects\", \"mammalia\", \"amphibia\"]:\n",
    "    true, pred = evaluate_with_ground_truth(group)\n",
    "    if true:\n",
    "        acc = accuracy_score(true, pred)\n",
    "        print(f\"{group.capitalize():<10} → Accuracy: {acc:.4f} ({len(true)} samples)\")\n",
    "        print(classification_report(true, pred, target_names=[group]))\n",
    "    else:\n",
    "        print(f\"{group.capitalize():<10} → No valid samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cf468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Cell 9: Confusion Matrix for One Group ===\n",
    "def plot_confusion_for_group(group):\n",
    "    folder = os.path.join(CUSTOM_TEST_ROOT, group)\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.endswith(\".wav\"): continue\n",
    "        path = os.path.join(folder, fname)\n",
    "        try:\n",
    "            wav = preprocess_sample(path)\n",
    "            logits = run_full_inference(wav)\n",
    "            pred = int(torch.argmax(logits))\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(CLASSES.index(group))  # assumes folder name is the true label\n",
    "        except:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Cell 10: Evaluate on Folder with Amphibia-like Sounds ===\n",
    "def evaluate_confused_folder(folder_name, expected_class):\n",
    "    folder = os.path.join(CUSTOM_TEST_ROOT, folder_name)\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.endswith(\".wav\"): continue\n",
    "        path = os.path.join(folder, fname)\n",
    "        try:\n",
    "            wav = preprocess_sample(path)\n",
    "            logits = run_full_inference(wav)\n",
    "            pred = int(torch.argmax(logits))\n",
    "            y_pred.append(pred)\n",
    "            y_true.append(CLASSES.index(expected_class))\n",
    "        except Exception as e:\n",
    "            print(f\"Error on {fname}: {e}\")\n",
    "\n",
    "    if y_true:\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print(f\"\\n Accuracy on '{folder_name}' (expected='{expected_class}'): {acc:.4f} ({len(y_true)} samples)\")\n",
    "\n",
    "        # Show confusion distribution\n",
    "        pred_labels = [CLASSES[p] for p in y_pred]\n",
    "        error_counts = pd.Series(pred_labels).value_counts().head(10)\n",
    "        print(\"\\n Top 10 Predicted Classes (Confusion Candidates):\")\n",
    "        for lbl, count in error_counts.items():\n",
    "            print(f\"{lbl:<30} {count} predictions\")\n",
    "\n",
    "        # Optional barplot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.barplot(x=error_counts.values, y=error_counts.index)\n",
    "        plt.title(f\"Most Common Misclassifications for '{folder_name}'\")\n",
    "        plt.xlabel(\"Prediction Count\")\n",
    "        plt.ylabel(\"Predicted Label\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No valid audio samples in '{folder_name}'\")\n",
    "\n",
    "# Run on a confusion-prone folder\n",
    "evaluate_confused_folder(\"sound_similar_to_amphibia\", expected_class=\"amphibia\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest --verbose --tb=no tests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051c3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pytest --verbose --lf --tb=no tests/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7912d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
