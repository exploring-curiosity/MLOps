{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5534651c-1767-4ccc-b633-9ea1f2b575c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "import torch\n",
    "from alibi_detect.cd.pytorch import HiddenOutput, preprocess_drift\n",
    "from alibi_detect.cd import MMDDriftOnline\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === Constants ===\n",
    "SAMPLE_RATE = 16000\n",
    "RAW_MODEL_INPUT_LEN = 320000\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# === Model ===\n",
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, emb_dim=2048, num_cls=206):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 2048), nn.BatchNorm1d(2048), nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(2048, 1024),    nn.BatchNorm1d(1024), nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(1024, 512),     nn.BatchNorm1d(512),  nn.ReLU(), nn.Dropout(DROPOUT),\n",
    "            nn.Linear(512, num_cls)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# === Audio preprocessing ===\n",
    "def preprocess_audio(wav_path):\n",
    "    try:\n",
    "        _ = torchaudio.info(wav_path)  # Ensures it's readable\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Unreadable audio file: {wav_path}\") from e\n",
    "    waveform, sr = torchaudio.load(wav_path)\n",
    "    if sr != SAMPLE_RATE:\n",
    "        waveform = torchaudio.transforms.Resample(sr, SAMPLE_RATE)(waveform)\n",
    "    waveform = waveform.mean(dim=0) if waveform.dim() > 1 else waveform\n",
    "    waveform = F.pad(waveform, (0, max(0, RAW_MODEL_INPUT_LEN - waveform.shape[0])))\n",
    "    waveform = (waveform - waveform.mean()) / waveform.std().clamp_min(1e-6)\n",
    "    return waveform[:RAW_MODEL_INPUT_LEN]\n",
    "\n",
    "def get_mel_tensor(waveform_tensor):\n",
    "    mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=SAMPLE_RATE, n_fft=1024, hop_length=256, n_mels=64\n",
    "    )\n",
    "    mel = torch.log1p(mel_transform(waveform_tensor))\n",
    "    mel_padded = torch.zeros((1, 64, 313))\n",
    "    mel_len = min(mel.shape[-1], 313)\n",
    "    mel_padded[:, :, :mel_len] = mel[:, :, :mel_len]\n",
    "    return mel_padded\n",
    "\n",
    "# === Initialize drift detector ===\n",
    "def init_drift_detector(model_path: str, ref_paths: list):\n",
    "    model = EmbeddingClassifier()\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    feature_model = HiddenOutput(model, layer=-1)\n",
    "    preprocess_fn = partial(preprocess_drift, model=feature_model)\n",
    "\n",
    "    ref_mels = []\n",
    "    for p in ref_paths:\n",
    "        try:\n",
    "            print(f\"Processing {p}\")\n",
    "            waveform = preprocess_audio(p)\n",
    "            mel = get_mel_tensor(waveform)  # shape: [1, 64, 313]\n",
    "            ref_mels.append(mel)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Skipping {p} due to error: {e}\")\n",
    "\n",
    "    if not ref_mels:\n",
    "        raise RuntimeError(\"No valid reference audio files found. Please check your dataset.\")\n",
    "\n",
    "    x_ref = torch.cat(ref_mels, dim=0)  # shape: [N, 64, 313]\n",
    "\n",
    "    return MMDDriftOnline(\n",
    "        x_ref, ert=300, window_size=10, backend='pytorch', preprocess_fn=preprocess_fn\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec456f4-f675-423d-b53c-b6a115d3fafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "REF_AUDIO_FOLDER = \"training/21211\"\n",
    "TEST_AUDIO_PATH = \"validating/21211/XC925908.ogg\"\n",
    "\n",
    "ref_audio_files = [\n",
    "    os.path.join(REF_AUDIO_FOLDER, f)\n",
    "    for f in os.listdir(REF_AUDIO_FOLDER)\n",
    "    if f.lower().endswith(\".ogg\")\n",
    "]\n",
    "\n",
    "cd_online = init_drift_detector(\"best_emb_mlp.pt\", ref_audio_files)\n",
    "\n",
    "waveform = preprocess_audio(TEST_AUDIO_PATH)\n",
    "mel_tensor = get_mel_tensor(waveform)\n",
    "is_drift = cd_online.predict(mel_tensor.numpy())[\"data\"][\"is_drift\"]\n",
    "print(\"\\nDrift detected!\" if is_drift else \"\\nNo drift detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe8f14-d502-4e6a-a776-ee857f511509",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd_online.reset_state()\n",
    "save_detector(cd_online, \"cd\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05509eab-ecf2-4733-8afe-173279da472b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    waveform, sr = torchaudio.load(\"training/21211/XC909280.ogg\")\n",
    "    print(f\"Loaded with sample rate {sr}, shape: {waveform.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c7dab-34b0-45e5-bec6-e6231244fef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "ogg_dir = \"training/21211\"\n",
    "wav_dir = \"training/21211_wav\"\n",
    "os.makedirs(wav_dir, exist_ok=True)\n",
    "\n",
    "for fname in os.listdir(ogg_dir):\n",
    "    if fname.lower().endswith(\".ogg\"):\n",
    "        ogg_path = os.path.join(ogg_dir, fname)\n",
    "        wav_name = fname.replace(\".ogg\", \".wav\")\n",
    "        wav_path = os.path.join(wav_dir, wav_name)\n",
    "\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                \"ffmpeg\", \"-y\", \"-i\", ogg_path, wav_path\n",
    "            ], check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "            print(f\"Converted: {fname} â†’ {wav_name}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"Failed to convert: {fname}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b0490-eeab-472b-baa1-36356d922043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
