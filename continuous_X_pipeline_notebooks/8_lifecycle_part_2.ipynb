{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "329589f3-51ac-4c4f-81cb-1f6e9de4cd90",
   "metadata": {},
   "source": [
    "## Model and application lifecycle - Part 2\n",
    "\n",
    "Once we have a container image, the progression through the model/application lifecycle continues as the new version is promoted through different environments:\n",
    "\n",
    "-   **Staging**: The container image is deployed in a staging environment that mimics the “production” service but without live users. In this staging environmenmt, we can perform integration tests against the service and also load tests to evaluate the inference performance of the system.\n",
    "-   **Canary** (or blue/green, or other “preliminary” live environment): From the staging environment, the service can be promoted to a canary or other preliminary environment, where it gets requests from a small fraction of live users. In this environment, we are closely monitoring the service, its predictions, and the infrastructure for any signs of problems.\n",
    "-   **Production**: Finally, after a thorough offline and online evaluation, we may promote the model to the live production environment, where it serves most users. We will continue monitoring the system for signs of degradation or poor performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac88cb1-0375-4c98-83f9-28c70a4d26ca",
   "metadata": {},
   "source": [
    "## Promoting a Model\n",
    "\n",
    "Now that we have tested our new model in staging, it time to promote it to canary. And from Canary to staging. \n",
    "\n",
    "We can do this by following the below steps : \n",
    "\n",
    "1. Workflow Templates > promote-model > Submit \n",
    "2. In the source environment, mention \"staging\" and type \"canary\" in target-environment. \n",
    "3. Select the desired model version in staging to be promoted. This could be obtained from MLFlow. \n",
    "4. Hit Submit\n",
    "\n",
    "After this [build-container-image](https://github.com/exploring-curiosity/MLOps/blob/main/continous_X_pipeline/workflows/build-container-image.yaml) will be triggered automatically, which downloads the code for the model wrapper from git, downloads the staging model from MLFlow, bundles both of them together and makes it avialable in the canary environment. \n",
    "\n",
    "So now if we go to http://A.B.C.D/8080 we would be accessing the latest model from the canary environment. \n",
    "\n",
    "We can follow the same approach to promote the model from canary to production. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
