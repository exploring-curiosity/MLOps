{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b55a36-61ea-4499-87dd-596f226ac84c",
   "metadata": {},
   "source": [
    "## Setup Nvidia Toolkit and Install nvtop\n",
    "\n",
    "``` bash\n",
    "curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \\\n",
    "  && curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n",
    "    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n",
    "    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n",
    "```\n",
    "``` bash\n",
    "sudo apt update\n",
    "sudo apt-get install -y nvidia-container-toolkit\n",
    "sudo nvidia-ctk runtime configure --runtime=docker\n",
    "sudo jq 'if has(\"exec-opts\") then . else . + {\"exec-opts\": [\"native.cgroupdriver=cgroupfs\"]} end' \\\n",
    "  /etc/docker/daemon.json | sudo tee /etc/docker/daemon.json.tmp > /dev/null && \\\n",
    "  sudo mv /etc/docker/daemon.json.tmp /etc/docker/daemon.json\n",
    "sudo systemctl restart docker\n",
    "docker run --rm --gpus all ubuntu nvidia-smi\n",
    "```\n",
    "\n",
    "``` bash\n",
    "sudo apt update \n",
    "sudo apt -y install nvtop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeb881d-4aa3-460a-9490-e8642c3452f2",
   "metadata": {},
   "source": [
    "## Store All the keys and endpoint on start in the Terminal to use in Future\n",
    "\n",
    "``` bash\n",
    "# Run in node terminal\n",
    "export AWS_ACCESS_KEY_ID=<your-key>\n",
    "export AWS_SECRET_ACCESS_KEY=<your-seckret>\n",
    "export MINIO_ENDPOINT=<minio-endpoint>\n",
    "export MLFLOW_TRACKING_URI=<mlflow-endpoint>\n",
    "export RAY_ADDRESS=<ray-endpoint>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058be24-cc57-4031-ac2c-2d45f9c38adc",
   "metadata": {},
   "source": [
    "``` bash\n",
    "# OPTIONAL - If Planning to use Jupyter Notebook to do testing and training\n",
    "docker build -t jupyter-train -f MLOps/model_train/docker/Dockerfile.jupyter_cuda .\n",
    "\n",
    "# OPTIONAL - If Planning to host minio, mlflow, postgres in local\n",
    "docker compose -f MLOps/model_train/docker/docker-compose-infra.yaml up -d\n",
    "\n",
    "# COMPULSORY - Start Ray and FAST-API server\n",
    "docker compose -f MLOps/model_train/docker/docker-compose-model-train-setup.yaml up -d\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c979b14-c8ba-4658-b6f4-a41af54f9b00",
   "metadata": {},
   "source": [
    "### If Jupyter-train is built and is required to Run- execute below [OPTIONAL]\n",
    "\n",
    "``` bash\n",
    "docker run  -d --rm  -p 8888:8888 \\\n",
    "    --gpus all \\\n",
    "    --shm-size 16G \\\n",
    "    -v ~/MLOps:/home/jovyan/work/ \\\n",
    "    -v features_data:/home/jovyan/data/ \\\n",
    "    -e MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI} \\\n",
    "    -e AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\\n",
    "    -e AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\\n",
    "    -e RAY_ADDRESS=${RAY_ADDRESS} \\\n",
    "    -e AWS_ENDPOINT_URL=${MINIO_ENDPOINT} \\\n",
    "    -e BIRDCLEF_BASE_DIR=/home/jovyan/data/ \\\n",
    "    --mount type=bind,source=/mnt/object,target=/mnt/birdclef,readonly \\\n",
    "    --name jupyter \\\n",
    "    jupyter-train\n",
    "```\n",
    "\n",
    "``` bash\n",
    "docker logs jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b82b67-d8aa-4f93-b845-5258d5ec322c",
   "metadata": {},
   "source": [
    "### Sample Ray Train scheduling commands via jupyter-train\n",
    "\n",
    "``` bash\n",
    "# Run on Jupyter Notebook launched in docker\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 0.25 --entrypoint-num-cpus 8 --verbose --no-wait --working-dir . -- python trainPannsEmb.py --epochs 1\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 0.75 --entrypoint-num-cpus 16 --verbose --no-wait --working-dir . -- python trainResNet50.py --epochs 1\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 1 --entrypoint-num-cpus 16 --verbose --no-wait --working-dir . -- python trainEffNetB3.py --epochs 1\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 1 --entrypoint-num-cpus 16 --verbose --no-wait --working-dir . -- python trainRawCNN.py --epochs 1\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 0.25 --entrypoint-num-cpus 8 --verbose --no-wait --working-dir . -- python hyperParameterTunePannsEmb.py --epochs 3 --num_samples 5\n",
    "ray job submit --runtime-env runtime.json --entrypoint-num-gpus 0.25 --entrypoint-num-cpus 8 --verbose --no-wait --working-dir . -- python hyperParameterTuneEffNetB3.py --epochs 3 --num_samples 5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84970ea-87d9-4365-a7f8-c8c5c92d875b",
   "metadata": {},
   "source": [
    "``` bash\n",
    "docker run  -d --rm  -p 8888:8888 \\\n",
    "    --gpus all \\\n",
    "    --shm-size 16G \\\n",
    "    -v ~/MLOps:/home/jovyan/work/ \\\n",
    "    -e MLFLOW_TRACKING_URI=http://129.114.26.77:8000/ \\\n",
    "    -e FOOD11_DATA_DIR=/mnt/Food-11 \\\n",
    "    --mount type=bind,source=/mnt/object,target=/mnt/birdclef,readonly \\\n",
    "    --name jupyter \\\n",
    "    jupyter-mlflow\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aaad6-3676-4897-922b-f31c74f83e94",
   "metadata": {},
   "source": [
    "# [ADDITIONAL] - Keep Track of Experiment training status from bash\n",
    "\n",
    "## Pool MLFLOW\n",
    "\n",
    "``` bash\n",
    "RUN_ID=\"2767d8907bdf4b48a22909b525677f76\"\n",
    "\n",
    "# terminal states to stop polling on\n",
    "TERMINAL=\"FINISHED|FAILED|KILLED\"\n",
    "\n",
    "while true; do\n",
    "  status=$(curl -s \\\n",
    "    \"${MLFLOW_TRACKING_URI}/api/2.0/mlflow/runs/get?run_id=${RUN_ID}\" \\\n",
    "    | jq -r '.run.info.status')\n",
    "\n",
    "  echo \"$(date +%T) → run ${RUN_ID} status: ${status}\"\n",
    "\n",
    "  if [[ \"$status\" =~ ^(${TERMINAL})$ ]]; then\n",
    "    echo \"Run reached terminal state: $status\"\n",
    "    break\n",
    "  fi\n",
    "\n",
    "  sleep 10\n",
    "done\n",
    "```\n",
    "\n",
    "## Pool FastAPI- server with Ray JobID\n",
    "\n",
    "``` bash\n",
    "JOB_ID=\"$1\"\n",
    "STATUS_URL=\"http://192.5.87.49:9090/status?job_id=${JOB_ID}\"\n",
    "\n",
    "echo \"Tracking Ray job ${JOB_ID} at ${STATUS_URL}\"\n",
    "\n",
    "while true; do\n",
    "  # Fetch status JSON\n",
    "  RESP=$(curl -s \"$STATUS_URL\")\n",
    "  STATUS=$(echo \"$RESP\" | jq -r .status)\n",
    "\n",
    "  printf \"%s → job %s status: %s\\n\" \"$(date +'%T')\" \"$JOB_ID\" \"$STATUS\"\n",
    "\n",
    "  if [ \"$STATUS\" = \"SUCCEEDED\" ]; then\n",
    "    # Extract MLflow run ID if present\n",
    "    MLFLOW_ID=$(echo \"$RESP\" | jq -r '.mlflow_run_id // empty')\n",
    "    if [ -n \"$MLFLOW_ID\" ]; then\n",
    "      echo \"Job succeeded. MLflow run ID: $MLFLOW_ID\"\n",
    "    else\n",
    "      echo \"Job succeeded. (No MLflow run ID found in response.)\"\n",
    "    fi\n",
    "    exit 0\n",
    "\n",
    "  elif [[ \"$STATUS\" =~ ^(FAILED|STOPPED)$ ]]; then\n",
    "    echo \"Job ${JOB_ID} ended with status: $STATUS\"\n",
    "    exit 1\n",
    "  fi\n",
    "\n",
    "  sleep 10\n",
    "done\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
