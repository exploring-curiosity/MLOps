{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d4846-6311-41cd-a942-05357f9ccc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm                         # ← add tqdm import\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6790a6b2-e34a-4aa9-ac5f-7a65064bcd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "mlflow.set_experiment(\"PannsMLP\")\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    pass\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU info\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "        for cmd in [\"nvidia-smi\", \"rocm-smi\"]\n",
    "        if subprocess.run(f\"command -v {cmd}\", shell=True,\n",
    "                          capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def log_system_metrics_mlflow(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    mem = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", mem.percent, step=step)\n",
    "    gpu_util = nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "    mlflow.log_metric(\"system.gpu.0.utilization\", gpu_util, step=step)\n",
    "    gpu_mem = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.used\", gpu_mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.percent\",\n",
    "                      (gpu_mem.used / gpu_mem.total) * 100, step=step)\n",
    "    gpu_temp = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.0.temperature\", gpu_temp, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae864dcf-4efe-4b67-ad54-20843a4e0b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, manifest_csv: str, metadata_csv: str, embeddings_key=\"embedding\"):\n",
    "        \"\"\"\n",
    "        manifest_csv: path to manifest_train.csv or manifest_test.csv\n",
    "        metadata_csv: path to full train.csv (for secondary_labels)\n",
    "        \"\"\"\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        meta = pd.read_csv(metadata_csv, usecols=[\"filename\", \"secondary_labels\"])\n",
    "        meta[\"recording_id\"] = meta.filename.str.replace(r\"\\.ogg$\", \"\", regex=True)\n",
    "        meta[\"secondary_list\"] = meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.recording_id, meta.secondary_list))\n",
    "\n",
    "        self.rows = []\n",
    "        all_labels = set()\n",
    "        # wrap iteration in tqdm to show loading progress\n",
    "        for _, row in tqdm(m_df.iterrows(),\n",
    "                            desc=f\"Building EmbeddingDataset ({os.path.basename(manifest_csv)})\",\n",
    "                            total=len(m_df)):\n",
    "            rid = row.chunk_id.split(\"_chk\")[0]\n",
    "            prim = row.primary_label\n",
    "            secs = sec_map.get(rid, [])\n",
    "            labels = [prim] + secs\n",
    "            all_labels.update(labels)\n",
    "            self.rows.append({\n",
    "                \"emb_path\": row.emb_path,\n",
    "                \"labels\": labels\n",
    "            })\n",
    "\n",
    "        self.classes = sorted(all_labels)\n",
    "        self.label2idx = {lab: i for i, lab in enumerate(self.classes)}\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.embeddings_key = embeddings_key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rows[idx]\n",
    "        arr = np.load(r[\"emb_path\"])[self.embeddings_key]  # (n_windows, emb_dim)\n",
    "        x = arr.mean(axis=0).astype(np.float32)            # (emb_dim,)\n",
    "        y = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        for lab in r[\"labels\"]:\n",
    "            y[self.label2idx[lab]] = 1.0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701ee26-3f0d-4ca0-afa4-54de061b071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(self, emb_dim, num_classes, hidden_dims=[512,256], dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(emb_dim, hidden_dims[0])\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dims[0])\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dims[1])\n",
    "        self.drop2 = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(hidden_dims[1], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.drop2(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ef36c-e086-4faf-8712-7b2ea7b28fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MANIFEST = \"/home/jovyan/Features/manifest_train.csv\"\n",
    "TEST_MANIFEST  = \"/home/jovyan/Features/manifest_test.csv\"\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "\n",
    "BATCH_SIZE  = 32\n",
    "LR          = 1e-3\n",
    "EPOCHS      = 20\n",
    "HIDDEN_DIMS = [512, 256]\n",
    "DROPOUT     = 0.3\n",
    "\n",
    "train_ds = EmbeddingDataset(TRAIN_MANIFEST, TRAIN_CSV)\n",
    "test_ds  = EmbeddingDataset(TEST_MANIFEST,  TRAIN_CSV)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "emb_dim = np.load(train_ds.rows[0][\"emb_path\"])[train_ds.embeddings_key].shape[1]\n",
    "model   = EmbeddingClassifier(emb_dim, train_ds.num_classes, HIDDEN_DIMS, DROPOUT).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"input_dim\": emb_dim,\n",
    "    \"hidden_dims\": HIDDEN_DIMS,\n",
    "    \"dropout\": DROPOUT,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"lr\": LR,\n",
    "    \"epochs\": EPOCHS\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3dd16e-d40b-4818-854c-5b5bb8804f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc = 0.0\n",
    "best_ckpt     = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", unit=\"batch\")\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == yb).all(dim=1).sum().item()\n",
    "        total   += xb.size(0)\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"batch_loss\": f\"{loss.item():.4f}\",\n",
    "            \"acc\":         f\"{correct/total:.4f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = running_loss / total\n",
    "    train_acc  = correct / total\n",
    "\n",
    "    # — Test —\n",
    "    model.eval()\n",
    "    test_bar = tqdm(test_loader, desc=f\"Epoch {epoch} Test \", unit=\"batch\")\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_bar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            correct += (preds == yb).all(dim=1).sum().item()\n",
    "            total   += xb.size(0)\n",
    "\n",
    "            test_bar.set_postfix({\n",
    "                \"batch_loss\": f\"{loss.item():.4f}\",\n",
    "                \"acc\":         f\"{correct/total:.4f}\"\n",
    "            })\n",
    "\n",
    "    test_loss /= total\n",
    "    test_acc   = correct / total\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt = f\"ckpt_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"train_loss\": train_loss,\n",
    "        \"test_loss\": test_loss\n",
    "    }, ckpt)\n",
    "\n",
    "    # MLflow logging\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_acc\n",
    "    }, step=epoch)\n",
    "    log_system_metrics_mlflow(step=epoch)\n",
    "    mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_ckpt     = ckpt\n",
    "\n",
    "    print(f\"→ Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} │ \"\n",
    "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468bc3b1-bada-4248-8244-87b24eff8c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"best_test_accuracy\", best_test_acc)\n",
    "mlflow.log_artifact(best_ckpt, artifact_path=\"model\")\n",
    "mlflow.pytorch.log_model(model, \"panns_mlp_model\")\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
