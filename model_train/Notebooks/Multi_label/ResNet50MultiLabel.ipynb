{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4b9f0a-13e8-48a6-b4d2-109a8087af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63089a06-2ef0-4075-9a9d-142606b419c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 02:23:34 INFO mlflow.tracking.fluent: Experiment with name 'ResNet50_MelAug' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 02:23:34 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "mlflow.set_experiment(\"ResNet50_MelAug\")\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    pass\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU info\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "        for cmd in [\"nvidia‑smi\", \"rocm‑smi\"]\n",
    "        if subprocess.run(f\"command ‑v {cmd}\", shell=True, capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def log_system_metrics_mlflow(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    mem = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", mem.percent, step=step)\n",
    "    gpu_util = nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "    mlflow.log_metric(\"system.gpu.0.utilization\", gpu_util, step=step)\n",
    "    gpu_mem = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.used\", gpu_mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.percent\",\n",
    "                      (gpu_mem.used / gpu_mem.total) * 100, step=step)\n",
    "    gpu_temp = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.0.temperature\", gpu_temp, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec489e51-1e7f-4764-be04-b56c821626bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_df      = pd.read_csv(\"/home/jovyan/Data/birdclef-2025/taxonomy.csv\")\n",
    "classes     = sorted(tax_df['primary_label'].astype(str).tolist())\n",
    "num_classes = len(classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26f0296-a826-4002-96f8-762dd330d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelAugDataset(Dataset):\n",
    "    def __init__(self, manifest_csv: str, metadata_csv: str,\n",
    "                 feature_base: str, classes: list, mel_key=\"mel\"):\n",
    "        \"\"\"\n",
    "        manifest_csv: path to manifest_train.csv or manifest_test.csv\n",
    "        metadata_csv: path to train.csv for secondary_labels\n",
    "        feature_base: root path of Features, e.g. \"/home/jovyan/Features\"\n",
    "        classes: global sorted list of all primary_label codes\n",
    "        \"\"\"\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        # build full path under Features/mel_aug/\n",
    "        m_df[\"mel_path\"] = (\n",
    "            m_df[\"mel_aug_path\"].astype(str)\n",
    "                .str.lstrip(os.sep)\n",
    "                .apply(lambda p: os.path.join(feature_base, \"mel_aug\", p))\n",
    "        )\n",
    "\n",
    "        # load secondary_labels\n",
    "        meta = pd.read_csv(metadata_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"recording_id\"]   = meta.filename.str.replace(r\"\\.ogg$\", \"\", regex=True)\n",
    "        meta[\"sec_list\"]       = meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.recording_id, meta.sec_list))\n",
    "\n",
    "        self.rows = []\n",
    "        self.classes     = classes\n",
    "        self.label2idx   = {lab:i for i, lab in enumerate(self.classes)}\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.mel_key     = mel_key\n",
    "\n",
    "        for _, row in tqdm(m_df.iterrows(),\n",
    "                          total=len(m_df),\n",
    "                          desc=f\"Building {os.path.basename(manifest_csv)}\"):\n",
    "            rid  = row.chunk_id.split(\"_chk\")[0]\n",
    "            labs = [row.primary_label] + sec_map.get(rid, [])\n",
    "            # filter out any labels not in taxonomy\n",
    "            labs = [l for l in labs if l in self.label2idx]\n",
    "            self.rows.append({\n",
    "                \"mel_path\": row.mel_path,\n",
    "                \"labels\":   labs\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r   = self.rows[idx]\n",
    "        npz = np.load(r[\"mel_path\"])\n",
    "        arr = npz[self.mel_key]             # (n_mels, n_frames)\n",
    "        x   = torch.from_numpy(arr).unsqueeze(0).float()  # (1, n_mels, n_frames)\n",
    "        y   = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for lab in r[\"labels\"]:\n",
    "            y[self.label2idx[lab]] = 1.0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "606ed890-ddc8-48da-9198-4ae0ca3dc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_multilabel(num_classes: int):\n",
    "    model = resnet50(weights=None)\n",
    "    # adapt stem conv to 1‑channel\n",
    "    model.conv1 = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=model.conv1.out_channels,\n",
    "        kernel_size=model.conv1.kernel_size,\n",
    "        stride=model.conv1.stride,\n",
    "        padding=model.conv1.padding,\n",
    "        bias=False\n",
    "    )\n",
    "    # replace final FC\n",
    "    in_feat = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_feat, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a586c8-63c4-4731-9c6f-b21bed841ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building manifest_train.csv: 100%|██████████| 108451/108451 [00:04<00:00, 22915.81it/s]\n",
      "Building manifest_test.csv: 100%|██████████| 11022/11022 [00:00<00:00, 24107.85it/s]\n"
     ]
    }
   ],
   "source": [
    "FEATURE_BASE   = \"/home/jovyan/Features\"\n",
    "TRAIN_MANIFEST = os.path.join(FEATURE_BASE, \"manifest_train.csv\")\n",
    "TEST_MANIFEST  = os.path.join(FEATURE_BASE, \"manifest_test.csv\")\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR         = 1e-4\n",
    "EPOCHS     = 1\n",
    "\n",
    "train_ds = MelAugDataset(TRAIN_MANIFEST, TRAIN_CSV, FEATURE_BASE, classes)\n",
    "test_ds  = MelAugDataset(TEST_MANIFEST,  TRAIN_CSV, FEATURE_BASE, classes)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model     = get_resnet50_multilabel(num_classes).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":        \"resnet50_scratch\",\n",
    "    \"input\":        \"mel_aug\",\n",
    "    \"num_classes\":  num_classes,\n",
    "    \"batch_size\":   BATCH_SIZE,\n",
    "    \"lr\":           LR,\n",
    "    \"epochs\":       EPOCHS\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "275e9356-e2b0-4e75-8ff6-d78699ac7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|██████████| 6779/6779 [04:51<00:00, 23.25batch/s, loss=0.0194, acc=0.1991]\n",
      "Epoch 1 Test : 100%|██████████| 689/689 [00:07<00:00, 92.76batch/s, loss=0.0170, acc=0.3139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 1/1  Train loss=0.0194, acc=0.1991 │ Test loss=0.0170, acc=0.3139\n"
     ]
    }
   ],
   "source": [
    "best_test_acc, best_ckpt = 0.0, None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", unit=\"batch\")\n",
    "    run_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "        preds    = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct  += (preds == yb).all(dim=1).sum().item()\n",
    "        total    += xb.size(0)\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"loss\": f\"{run_loss/total:.4f}\",\n",
    "            \"acc\":  f\"{correct/total:.4f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = run_loss / total\n",
    "    train_acc  = correct / total\n",
    "\n",
    "    # — Test —\n",
    "    model.eval()\n",
    "    test_bar = tqdm(test_loader, desc=f\"Epoch {epoch} Test \", unit=\"batch\")\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_bar:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            preds     = (torch.sigmoid(logits) > 0.5).float()\n",
    "            correct   += (preds == yb).all(dim=1).sum().item()\n",
    "            total     += xb.size(0)\n",
    "\n",
    "            test_bar.set_postfix({\n",
    "                \"loss\": f\"{test_loss/total:.4f}\",\n",
    "                \"acc\":  f\"{correct/total:.4f}\"\n",
    "            })\n",
    "\n",
    "    test_loss /= total\n",
    "    test_acc   = correct / total\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt = f\"resnet50_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\":       epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"train_loss\":  train_loss,\n",
    "        \"test_loss\":   test_loss\n",
    "    }, ckpt)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\":    train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_loss\":     test_loss,\n",
    "        \"test_accuracy\": test_acc\n",
    "    }, step=epoch)\n",
    "    log_system_metrics_mlflow(step=epoch)\n",
    "    mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc, best_ckpt = test_acc, ckpt\n",
    "\n",
    "    print(f\"→ Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} │ \"\n",
    "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b312dd2c-47db-47ed-8782-8fe0077b76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 02:31:57 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/05/07 02:31:57 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run crawling-quail-65 at: http://192.5.87.49:8000/#/experiments/2/runs/ffd8bef648eb4cbc9eca50b8b4842c89\n",
      "🧪 View experiment at: http://192.5.87.49:8000/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "mlflow.log_metric(\"best_test_accuracy\", best_test_acc)\n",
    "mlflow.log_artifact(best_ckpt, artifact_path=\"model\")\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
