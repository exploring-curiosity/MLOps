{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4b9f0a-13e8-48a6-b4d2-109a8087af86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50\n",
    "from tqdm import tqdm\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "from torch.amp import autocast, GradScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63089a06-2ef0-4075-9a9d-142606b419c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 16:26:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "mlflow.set_experiment(\"ResNet50_MelAug\")\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU/CPU info once\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "        for cmd in [\"nvidia-smi\",\"rocm-smi\"]\n",
    "        if subprocess.run(f\"command -v {cmd}\", shell=True, capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "def log_sys(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    m = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", m.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", m.percent, step=step)\n",
    "    u = nvmlDeviceGetUtilizationRates(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.utilization\", u.gpu, step=step)\n",
    "    gm = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.mem.used\", gm.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.mem.percent\", (gm.used/gm.total)*100, step=step)\n",
    "    t = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.temperature\", t, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec489e51-1e7f-4764-be04-b56c821626bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 64\n",
    "LR             = 1e-4\n",
    "WEIGHT_DECAY   = 1e-4\n",
    "EPOCHS         = 20\n",
    "SAVE_EPOCH_CK  = False\n",
    "BEST_CKPT      = \"best_resnet50.pt\"\n",
    "\n",
    "TAXONOMY_CSV   = \"/home/jovyan/Data/birdclef-2025/taxonomy.csv\"\n",
    "TRAIN_MANIFEST = \"/home/jovyan/Features/manifest_train.csv\"\n",
    "TEST_MANIFEST  = \"/home/jovyan/Features/manifest_test.csv\"\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "FEATURE_BASE   = \"/home/jovyan/Features\"\n",
    "\n",
    "tax_df     = pd.read_csv(TAXONOMY_CSV)\n",
    "CLASSES    = sorted(tax_df[\"primary_label\"].astype(str).tolist())\n",
    "NUM_CLASSES= len(CLASSES)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":         \"resnet50_scratch\",\n",
    "    \"input\":         \"mel_aug\",\n",
    "    \"num_classes\":   NUM_CLASSES,\n",
    "    \"batch_size\":    BATCH_SIZE,\n",
    "    \"lr\":            LR,\n",
    "    \"weight_decay\":  WEIGHT_DECAY,\n",
    "    \"epochs\":        EPOCHS,\n",
    "    \"save_epoch_ck\": SAVE_EPOCH_CK\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26f0296-a826-4002-96f8-762dd330d657",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelAugDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, meta_csv, feature_base, classes, key=\"mel\"):\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        m_df[\"mel_path\"] = (\n",
    "            m_df[\"mel_aug_path\"].astype(str)\n",
    "                .str.lstrip(os.sep)\n",
    "                .apply(lambda p: os.path.join(feature_base, \"mel_aug\", p))\n",
    "        )\n",
    "        meta = pd.read_csv(meta_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"rid\"]     = meta.filename.str.replace(r\"\\.ogg$\",\"\",regex=True)\n",
    "        meta[\"sec_list\"]= meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.rid, meta.sec_list))\n",
    "\n",
    "        self.rows = []\n",
    "        self.idx_map   = {c:i for i,c in enumerate(classes)}\n",
    "        self.num_cls   = len(classes)\n",
    "        self.key       = key\n",
    "\n",
    "        for _, row in tqdm(m_df.iterrows(), total=len(m_df), desc=\"Building dataset\"):\n",
    "            rid  = row.chunk_id.split(\"_chk\")[0]\n",
    "            labs = [row.primary_label] + sec_map.get(rid, [])\n",
    "            labs = [l for l in labs if l in self.idx_map]\n",
    "            prim_idx = self.idx_map[row.primary_label]\n",
    "            self.rows.append((row.mel_path, labs, prim_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, labs, prim_idx = self.rows[i]\n",
    "        npz  = np.load(path)\n",
    "        arr  = npz[self.key]                   # [n_mels, n_frames]\n",
    "        x    = torch.from_numpy(arr).unsqueeze(0).float()  # [1,n_mels,n_frames]\n",
    "        y    = torch.zeros(self.num_cls, dtype=torch.float32)\n",
    "        for l in labs:\n",
    "            y[self.idx_map[l]] = 1.0\n",
    "        return x, y, prim_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917663c9-54f6-4f43-9aba-6962004d17a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset: 100%|██████████| 108451/108451 [00:05<00:00, 21636.70it/s]\n",
      "Building dataset: 100%|██████████| 11022/11022 [00:00<00:00, 22590.69it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = MelAugDataset(TRAIN_MANIFEST, TRAIN_CSV, FEATURE_BASE, CLASSES)\n",
    "test_ds  = MelAugDataset(TEST_MANIFEST,  TRAIN_CSV, FEATURE_BASE, CLASSES)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "606ed890-ddc8-48da-9198-4ae0ca3dc814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_multilabel(num_classes):\n",
    "    m = resnet50(weights=None)\n",
    "    # adapt 1‐channel\n",
    "    m.conv1 = nn.Conv2d(1, m.conv1.out_channels,\n",
    "                        kernel_size=m.conv1.kernel_size,\n",
    "                        stride=m.conv1.stride,\n",
    "                        padding=m.conv1.padding,\n",
    "                        bias=False)\n",
    "    m.fc    = nn.Linear(m.fc.in_features, num_classes)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a586c8-63c4-4731-9c6f-b21bed841ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model     = get_resnet50_multilabel(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LR,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS,\n",
    "    pct_start=0.1,\n",
    "    div_factor=10\n",
    ")\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275e9356-e2b0-4e75-8ff6-d78699ac7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Train: 100%|██████████| 1695/1695 [01:30<00:00, 18.82batch/s, loss=0.0504]\n",
      "Epoch 1/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 1/20  F1=0.0535  AP=0.1047  PrimAcc=0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.65batch/s, loss=0.0184]\n",
      "Epoch 2/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.69batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 2/20  F1=0.2603  AP=0.3726  PrimAcc=0.3760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.69batch/s, loss=0.0128]\n",
      "Epoch 3/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 3/20  F1=0.3069  AP=0.4549  PrimAcc=0.4494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.56batch/s, loss=0.0100]\n",
      "Epoch 4/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 4/20  F1=0.4174  AP=0.5306  PrimAcc=0.5170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.54batch/s, loss=0.0081]\n",
      "Epoch 5/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.67batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 5/20  F1=0.3718  AP=0.5717  PrimAcc=0.5425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.67batch/s, loss=0.0066]\n",
      "Epoch 6/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 6/20  F1=0.4272  AP=0.5839  PrimAcc=0.5644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.66batch/s, loss=0.0053]\n",
      "Epoch 7/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.89batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 7/20  F1=0.3207  AP=0.5996  PrimAcc=0.5727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.50batch/s, loss=0.0041]\n",
      "Epoch 8/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.27batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 8/20  F1=0.4756  AP=0.5994  PrimAcc=0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 Train: 100%|██████████| 1695/1695 [01:32<00:00, 18.24batch/s, loss=0.0030]\n",
      "Epoch 9/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 9/20  F1=0.4330  AP=0.6027  PrimAcc=0.5808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 Train: 100%|██████████| 1695/1695 [01:28<00:00, 19.07batch/s, loss=0.0021]\n",
      "Epoch 10/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 10/20  F1=0.3611  AP=0.5995  PrimAcc=0.5837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 Train: 100%|██████████| 1695/1695 [01:27<00:00, 19.48batch/s, loss=0.0015]\n",
      "Epoch 11/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 11/20  F1=0.3504  AP=0.6054  PrimAcc=0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.61batch/s, loss=0.0011]\n",
      "Epoch 12/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 12/20  F1=0.3531  AP=0.5991  PrimAcc=0.5867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.61batch/s, loss=0.0009]\n",
      "Epoch 13/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 13/20  F1=0.3708  AP=0.6114  PrimAcc=0.5957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.57batch/s, loss=0.0007]\n",
      "Epoch 14/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 14/20  F1=0.3766  AP=0.6080  PrimAcc=0.5940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.57batch/s, loss=0.0006]\n",
      "Epoch 15/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.30batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 15/20  F1=0.3972  AP=0.6192  PrimAcc=0.6027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.63batch/s, loss=0.0006]\n",
      "Epoch 16/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 16/20  F1=0.3958  AP=0.6162  PrimAcc=0.5998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 Train: 100%|██████████| 1695/1695 [01:27<00:00, 19.48batch/s, loss=0.0005]\n",
      "Epoch 17/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.35batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 17/20  F1=0.4002  AP=0.6222  PrimAcc=0.6064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.49batch/s, loss=0.0005]\n",
      "Epoch 18/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 18/20  F1=0.4061  AP=0.6252  PrimAcc=0.6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 Train: 100%|██████████| 1695/1695 [01:26<00:00, 19.62batch/s, loss=0.0005]\n",
      "Epoch 19/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 59.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 19/20  F1=0.3985  AP=0.6254  PrimAcc=0.6049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 Train: 100%|██████████| 1695/1695 [01:27<00:00, 19.46batch/s, loss=0.0005]\n",
      "Epoch 20/20 Eval: 100%|██████████| 173/173 [00:02<00:00, 60.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Epoch 20/20  F1=0.3996  AP=0.6262  PrimAcc=0.6049\n"
     ]
    }
   ],
   "source": [
    "best_f1, best_ap, best_acc = 0.0, 0.0, 0.0\n",
    "thresholds = np.full(NUM_CLASSES, 0.5, dtype=np.float32)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    run_loss, total = 0.0, 0\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} Train\", unit=\"batch\")\n",
    "    for xb, yb, _ in train_bar:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        run_loss += loss.item()*bs\n",
    "        total    += bs\n",
    "        train_bar.set_postfix({\"loss\": f\"{run_loss/total:.4f}\"})\n",
    "    train_loss = run_loss/total\n",
    "\n",
    "    # — Eval —\n",
    "    model.eval()\n",
    "    all_scores, all_tgts, all_prims = [], [], []\n",
    "    val_loss, total = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, prim_idx in tqdm(test_loader, desc=f\"Epoch {epoch}/{EPOCHS} Eval\", unit=\"batch\"):\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                logits = model(xb)\n",
    "                val_loss += criterion(logits, yb).item()*xb.size(0)\n",
    "                scores   = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_scores.append(scores)\n",
    "            all_tgts.append(yb.cpu().numpy())\n",
    "            all_prims.extend(prim_idx.tolist())\n",
    "            total += xb.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    scores = np.vstack(all_scores)\n",
    "    tgts   = np.vstack(all_tgts)\n",
    "    prims  = np.array(all_prims, dtype=int)\n",
    "\n",
    "    # fast threshold calibration\n",
    "    for i in range(NUM_CLASSES):\n",
    "        y_true = tgts[:, i]\n",
    "        if 0 < y_true.sum() < len(y_true):\n",
    "            prec, rec, th = precision_recall_curve(y_true, scores[:, i])\n",
    "            f1_vals = 2*prec*rec/(prec+rec+1e-8)\n",
    "            best    = np.nanargmax(f1_vals[:-1])\n",
    "            thresholds[i] = th[best]\n",
    "\n",
    "    preds      = (scores >= thresholds).astype(int)\n",
    "    micro_f1   = f1_score(tgts, preds, average=\"micro\", zero_division=0)\n",
    "    micro_ap   = average_precision_score(tgts, scores, average=\"micro\")\n",
    "    top1       = scores.argmax(axis=1)\n",
    "    primary_acc= (top1 == prims).mean()\n",
    "\n",
    "    # checkpoint best\n",
    "    if micro_f1 > best_f1:\n",
    "        best_f1, best_ap, best_acc = micro_f1, micro_ap, primary_acc\n",
    "        torch.save(model.state_dict(), BEST_CKPT)\n",
    "        mlflow.log_artifact(BEST_CKPT, artifact_path=\"model\")\n",
    "\n",
    "    # log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\":     train_loss,\n",
    "        \"val_loss\":       val_loss,\n",
    "        \"micro_f1\":       micro_f1,\n",
    "        \"micro_ap\":       micro_ap,\n",
    "        \"primary_acc\":    primary_acc\n",
    "    }, step=epoch)\n",
    "    log_sys(step=epoch)\n",
    "\n",
    "    print(f\"→ Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"F1={micro_f1:.4f}  AP={micro_ap:.4f}  PrimAcc={primary_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b312dd2c-47db-47ed-8782-8fe0077b76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 16:57:13 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/05/07 16:57:13 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run carefree-dove-950 at: http://192.5.87.49:8000/#/experiments/6/runs/a0716a5a62cb4a3f8285f7875126e57e\n",
      "🧪 View experiment at: http://192.5.87.49:8000/#/experiments/6\n"
     ]
    }
   ],
   "source": [
    "mlflow.log_metric(\"best_micro_f1\", best_f1)\n",
    "mlflow.log_metric(\"best_micro_ap\", best_ap)\n",
    "mlflow.log_metric(\"best_primary_acc\", best_acc)\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
