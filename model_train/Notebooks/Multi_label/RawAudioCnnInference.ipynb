{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "718e0325-187b-4f3d-9fd2-69ca77c6737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f36f89a7-e078-40fb-99d5-5a6e948db6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FEATURE_BASE  = \"/home/jovyan/Features\"\n",
    "TEST_MAN      = os.path.join(FEATURE_BASE, \"manifest_test.csv\")\n",
    "TAXONOMY_CSV  = \"/home/jovyan/Data/birdclef-2025/taxonomy.csv\"\n",
    "CHECKPOINT    = \"best_rawcnn.pt\"    # your saved weights\n",
    "THRESHOLD     = 0.5                 # or load a per-class array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32126e09-0088-43da-b441-278fb357de3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawAudioCNN(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv1d(1,16,15,stride=4,padding=7)\n",
    "        self.bn1   = torch.nn.BatchNorm1d(16)\n",
    "        self.pool  = torch.nn.MaxPool1d(4)\n",
    "        self.conv2 = torch.nn.Conv1d(16,32,15,stride=2,padding=7)\n",
    "        self.bn2   = torch.nn.BatchNorm1d(32)\n",
    "        self.conv3 = torch.nn.Conv1d(32,64,15,stride=2,padding=7)\n",
    "        self.bn3   = torch.nn.BatchNorm1d(64)\n",
    "        self.conv4 = torch.nn.Conv1d(64,128,15,stride=2,padding=7)\n",
    "        self.bn4   = torch.nn.BatchNorm1d(128)\n",
    "        self.gpool = torch.nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc    = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)               # [B,1,T]\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.gpool(x).squeeze(-1)    # [B,128]\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d86b905-5e10-4ede-ae5f-ee3b24463180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_df      = pd.read_csv(TAXONOMY_CSV)\n",
    "classes     = sorted(tax_df[\"primary_label\"].astype(str).tolist())\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c416b7-fb33-49a4-b007-86605a285063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on chunk: XC166627_chk0\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(TEST_MAN)\n",
    "sample  = test_df.sample(1).iloc[0]\n",
    "print(\"Running inference on chunk:\", sample.chunk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14207820-fe98-4263-a07e-da67da5ec291",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = os.path.join(FEATURE_BASE, \"denoised\", sample.audio_path.lstrip(os.sep))\n",
    "wav, sr  = torchaudio.load(wav_path)  # [1, T]\n",
    "wav       = wav.squeeze(0)            # [T]\n",
    "target_len = 32000 * 10\n",
    "if wav.size(0) < target_len:\n",
    "    wav = F.pad(wav, (0, target_len - wav.size(0)))\n",
    "else:\n",
    "    wav = wav[:target_len]\n",
    "wav = (wav - wav.mean()) / wav.std().clamp_min(1e-6)\n",
    "wav = wav.to(DEVICE).unsqueeze(0)     # [1, T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30e5edd8-a2fa-4eff-b8d7-01091e6b906e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RawAudioCNN(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(15,), stride=(4,), padding=(7,))\n",
       "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv1d(16, 32, kernel_size=(15,), stride=(2,), padding=(7,))\n",
       "  (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv1d(32, 64, kernel_size=(15,), stride=(2,), padding=(7,))\n",
       "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv1d(64, 128, kernel_size=(15,), stride=(2,), padding=(7,))\n",
       "  (bn4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (gpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=128, out_features=206, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RawAudioCNN(num_classes).to(DEVICE)\n",
    "state = torch.load(CHECKPOINT, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78c0e108-01b9-4b7b-a14c-f0bf5fe87a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(wav)               # [1, C]\n",
    "    probs  = torch.sigmoid(logits)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "121811fd-e5e0-43ea-8c28-31b0e81add6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi‑label predictions (prob ≥ 0.5):\n",
      "  • chbant1: 0.990\n"
     ]
    }
   ],
   "source": [
    "ml_preds = [\n",
    "    (classes[i], float(probs[i])) \n",
    "    for i in range(num_classes) \n",
    "    if probs[i] >= THRESHOLD\n",
    "]\n",
    "\n",
    "print(f\"\\nMulti‑label predictions (prob ≥ {THRESHOLD}):\")\n",
    "if ml_preds:\n",
    "    for label, score in ml_preds:\n",
    "        print(f\"  • {label}: {score:.3f}\")\n",
    "else:\n",
    "    print(\"  • <none>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5108ab7-152e-46d5-8f71-2f2722d1d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary‑label (top‑1) prediction:\n",
      "  → chbant1: 0.990\n"
     ]
    }
   ],
   "source": [
    "primary_idx   = int(probs.argmax())\n",
    "primary_pred  = classes[primary_idx]\n",
    "primary_score = float(probs[primary_idx])\n",
    "\n",
    "print(f\"\\nPrimary‑label (top‑1) prediction:\")\n",
    "print(f\"  → {primary_pred}: {primary_score:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
