{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b203798-8a39-42dc-92ed-d2d1026ac7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from torch.amp import autocast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcc4e43-6d9b-4ebb-801f-5caa20c37ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FEATURE_DIR   = \"/home/jovyan/Features\"\n",
    "MANIFEST_CSV  = os.path.join(FEATURE_DIR, \"manifest_test.csv\")\n",
    "TAXONOMY_CSV  = \"/home/jovyan/Data/birdclef-2025/taxonomy.csv\"\n",
    "CHECKPOINT    = \"best_effb3_lora.pt\"   # path to your saved best LoRA model\n",
    "MEL_KEY       = \"mel\"                  # key inside the .npz for mel\n",
    "THRESHOLD     = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b86fba1-6be2-4572-8955-7c4c9a0a99ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_df  = pd.read_csv(TAXONOMY_CSV)\n",
    "classes = sorted(tax_df[\"primary_label\"].astype(str).tolist())\n",
    "num_classes = len(classes)\n",
    "\n",
    "TARGET_MODULES  = [\"conv_pw\",\"conv_dw\",\"conv_pwl\",\"conv_head\"]\n",
    "MODULES_TO_SAVE = [\"classifier\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d12467f-5f4f-41a6-b02a-2aa58a7a9bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForFeatureExtraction(\n",
       "  (base_model): LoraModel(\n",
       "    (model): EfficientNet(\n",
       "      (conv_stem): Conv2d(1, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNormAct2d(\n",
       "        40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (blocks): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): DepthwiseSeparableConv(\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(40, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(40, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): DepthwiseSeparableConv(\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(24, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(24, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(144, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(144, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(32, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(96, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(576, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(136, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(136, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(136, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(136, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(136, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(816, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (2): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (3): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (4): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (5): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(232, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(1392, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "          (1): InvertedResidual(\n",
       "            (conv_pw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn1): BatchNormAct2d(\n",
       "              2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (conv_dw): lora.Conv2d(\n",
       "              (base_layer): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(2304, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn2): BatchNormAct2d(\n",
       "              2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (aa): Identity()\n",
       "            (se): SqueezeExcite(\n",
       "              (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (act1): SiLU(inplace=True)\n",
       "              (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (gate): Sigmoid()\n",
       "            )\n",
       "            (conv_pwl): lora.Conv2d(\n",
       "              (base_layer): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (default): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (default): Conv2d(2304, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (default): Conv2d(12, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (bn3): BatchNormAct2d(\n",
       "              384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "              (drop): Identity()\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conv_head): lora.Conv2d(\n",
       "        (base_layer): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (lora_dropout): ModuleDict(\n",
       "          (default): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (lora_A): ModuleDict(\n",
       "          (default): Conv2d(384, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (lora_B): ModuleDict(\n",
       "          (default): Conv2d(12, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (lora_embedding_A): ParameterDict()\n",
       "        (lora_embedding_B): ParameterDict()\n",
       "        (lora_magnitude_vector): ModuleDict()\n",
       "      )\n",
       "      (bn2): BatchNormAct2d(\n",
       "        1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "        (drop): Identity()\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=1536, out_features=206, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=1536, out_features=206, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_effb3_lora(num_classes):\n",
    "    base = timm.create_model(\"efficientnet_b3\", pretrained=True)\n",
    "\n",
    "    # patch forward to accept arbitrary kwargs\n",
    "    orig_fwd = base.forward\n",
    "    def forward_patch(*args, **kwargs):\n",
    "        if \"input_ids\" in kwargs:\n",
    "            x = kwargs.pop(\"input_ids\")\n",
    "        elif len(args)>0:\n",
    "            x = args[0]\n",
    "        else:\n",
    "            raise ValueError(\"No input tensor\")\n",
    "        # drop any other keys\n",
    "        return orig_fwd(x)\n",
    "    base.forward = forward_patch\n",
    "\n",
    "    # adapt to single-channel\n",
    "    stem = base.conv_stem\n",
    "    base.conv_stem = nn.Conv2d(\n",
    "        1, stem.out_channels,\n",
    "        kernel_size=stem.kernel_size,\n",
    "        stride=stem.stride,\n",
    "        padding=stem.padding,\n",
    "        bias=False\n",
    "    )\n",
    "    # replace head\n",
    "    in_f = base.classifier.in_features\n",
    "    base.classifier = nn.Linear(in_f, num_classes)\n",
    "\n",
    "    # attach LoRA\n",
    "    lora_cfg = LoraConfig(\n",
    "        r=12, lora_alpha=24, lora_dropout=0.1,\n",
    "        target_modules=TARGET_MODULES,\n",
    "        modules_to_save=MODULES_TO_SAVE,\n",
    "        bias=\"none\",\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=True\n",
    "    )\n",
    "    model = get_peft_model(base, lora_cfg)\n",
    "    return model\n",
    "\n",
    "model = build_effb3_lora(num_classes).to(DEVICE)\n",
    "state = torch.load(CHECKPOINT, map_location=DEVICE)\n",
    "model.load_state_dict(state)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6b98fc-6387-442b-b95d-14d804449af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on chunk: iNat329195_chk1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(MANIFEST_CSV)\n",
    "row = df.sample(1).iloc[0]\n",
    "chunk_id = row.chunk_id\n",
    "rel_path = row.mel_path.lstrip(os.sep)\n",
    "mel_path = os.path.join(FEATURE_DIR, \"mel\", rel_path)\n",
    "\n",
    "print(f\"Running inference on chunk: {chunk_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3527ba25-cc86-454f-b9e3-cff86120a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(mel_path)\n",
    "mel  = data[MEL_KEY]                         # [n_mels, n_frames]\n",
    "x    = torch.from_numpy(mel).unsqueeze(0).unsqueeze(0).float()  # [1,1,n_mels,n_frames]\n",
    "x    = x.to(DEVICE, non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0726167e-247c-4956-a0e0-0a9cb73bd99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), autocast(device_type=\"cuda\"):\n",
    "    logits = model(x)                       # [1, num_classes]\n",
    "    probs  = torch.sigmoid(logits)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcbb4ee6-8fa8-4339-b14f-c4519e5445bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Multi‑label predictions (prob ≥ 0.5):\n",
      "  • grbhaw1: 0.803\n"
     ]
    }
   ],
   "source": [
    "ml_preds = [(classes[i], float(probs[i]))\n",
    "            for i in range(num_classes) if probs[i] >= THRESHOLD]\n",
    "\n",
    "print(f\"\\nMulti‑label predictions (prob ≥ {THRESHOLD}):\")\n",
    "if ml_preds:\n",
    "    for lab, sc in ml_preds:\n",
    "        print(f\"  • {lab}: {sc:.3f}\")\n",
    "else:\n",
    "    print(\"  • <none>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403a9979-2748-4837-b17c-651ca7c8deef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary‑label (top‑1) prediction:\n",
      "  → grbhaw1: 0.803\n"
     ]
    }
   ],
   "source": [
    "idx = int(probs.argmax())\n",
    "print(f\"\\nPrimary‑label (top‑1) prediction:\")\n",
    "print(f\"  → {classes[idx]}: {probs[idx]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
