{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c22c7-ac80-4358-a7a8-f952ecf8d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8aec0c-a041-46eb-9f25-26e1061958b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "mlflow.set_experiment(\"Panns_CNN14_FineTune\")\n",
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    pass\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU info\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "        for cmd in [\"nvidia-smi\", \"rocm-smi\"]\n",
    "        if subprocess.run(f\"command -v {cmd}\", shell=True,\n",
    "                          capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def log_system_metrics_mlflow(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    mem = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", mem.percent, step=step)\n",
    "    gpu_util = nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "    mlflow.log_metric(\"system.gpu.0.utilization\", gpu_util, step=step)\n",
    "    gpu_mem = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.used\", gpu_mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.percent\",\n",
    "                      (gpu_mem.used / gpu_mem.total) * 100, step=step)\n",
    "    gpu_temp = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.0.temperature\", gpu_temp, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d64251-f022-4ad1-8aad-2ef4de4940c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, manifest_csv: str, metadata_csv: str,\n",
    "                 sr: int = 32000, duration: float = 10.0):\n",
    "        \"\"\"\n",
    "        manifest_csv: path to manifest_train.csv or manifest_test.csv\n",
    "        metadata_csv: path to full train.csv (for secondary_labels)\n",
    "        sr: sample rate to load audio\n",
    "        duration: length (s) to pad/truncate each file\n",
    "        \"\"\"\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        meta = pd.read_csv(metadata_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"recording_id\"] = meta.filename.str.replace(r\"\\.ogg$\", \"\", regex=True)\n",
    "        meta[\"sec_list\"]     = meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.recording_id, meta.sec_list))\n",
    "\n",
    "        self.rows = []\n",
    "        all_labels = set()\n",
    "        self.sr = sr\n",
    "        self.num_samples = int(sr * duration)\n",
    "\n",
    "        for _, row in tqdm(m_df.iterrows(),\n",
    "                            total=len(m_df),\n",
    "                            desc=f\"Building AudioDataset ({os.path.basename(manifest_csv)})\"):\n",
    "            rid    = row.chunk_id.split(\"_chk\")[0]\n",
    "            labs   = [row.primary_label] + sec_map.get(rid, [])\n",
    "            all_labels.update(labs)\n",
    "            self.rows.append({\n",
    "                \"audio_path\": row.audio_path,\n",
    "                \"labels\": labs\n",
    "            })\n",
    "\n",
    "        self.classes   = sorted(all_labels)\n",
    "        self.label2idx = {l:i for i,l in enumerate(self.classes)}\n",
    "        self.num_classes = len(self.classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rows[idx]\n",
    "        # load waveform\n",
    "        wav, _ = librosa.load(r[\"audio_path\"], sr=self.sr)\n",
    "        # pad or truncate\n",
    "        if len(wav) < self.num_samples:\n",
    "            pad = self.num_samples - len(wav)\n",
    "            wav = np.pad(wav, (0,pad), mode=\"constant\")\n",
    "        else:\n",
    "            wav = wav[:self.num_samples]\n",
    "        x = torch.from_numpy(wav).unsqueeze(0).float()  # (1, num_samples)\n",
    "\n",
    "        # multi‑hot target\n",
    "        y = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for l in r[\"labels\"]:\n",
    "            y[self.label2idx[l]] = 1.0\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c56378-ebf0-4351-a00f-b6f0c710c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "panns = torch.hub.load(\n",
    "    \"qiuqiangkong/audioset_tagging_cnn\", \"Cnn14\",\n",
    "    pretrained=True, \n",
    "    classes_num=None       # we'll override the head below\n",
    ")\n",
    "\n",
    "# replace audio-tagging head for our num_classes\n",
    "# original PANNs has attr 'fc2' or 'fc_audioset'; here we use fc2\n",
    "in_features = panns.fc2.in_features if hasattr(panns, \"fc2\") else panns.fc_audioset.in_features\n",
    "new_head = nn.Linear(in_features, None)  # placeholder\n",
    "# but since we want dynamic assignment, we'll assign after dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3cc1e6-fd97-4169-a665-d279e76cabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MANIFEST = \"/home/jovyan/Features/manifest_train.csv\"\n",
    "TEST_MANIFEST  = \"/home/jovyan/Features/manifest_test.csv\"\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "\n",
    "BATCH_SIZE = 8     # smaller batch for long audio\n",
    "LR         = 1e-4\n",
    "EPOCHS     = 20\n",
    "\n",
    "train_ds = AudioDataset(TRAIN_MANIFEST, TRAIN_CSV)\n",
    "test_ds  = AudioDataset(TEST_MANIFEST,  TRAIN_CSV)\n",
    "\n",
    "# now override PANNs head with correct num_classes\n",
    "num_classes = train_ds.num_classes\n",
    "if hasattr(panns, \"fc2\"):\n",
    "    panns.fc2 = nn.Linear(panns.fc2.in_features, num_classes)\n",
    "else:\n",
    "    panns.fc_audioset = nn.Linear(panns.fc_audioset.in_features, num_classes)\n",
    "model = panns.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":        \"PANNs_Cnn14_finetune\",\n",
    "    \"input\":        \"waveform\",\n",
    "    \"sr\":           train_ds.sr,\n",
    "    \"duration_s\":   train_ds.num_samples / train_ds.sr,\n",
    "    \"num_classes\":  num_classes,\n",
    "    \"batch_size\":   BATCH_SIZE,\n",
    "    \"lr\":           LR,\n",
    "    \"epochs\":       EPOCHS\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73625f10-55a6-4571-8bfa-cfad81a402e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc = 0.0\n",
    "best_ckpt     = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", unit=\"batch\")\n",
    "    run_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)         # [B, num_classes]\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "        preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "        correct += (preds == yb).all(dim=1).sum().item()\n",
    "        total   += xb.size(0)\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"loss\": f\"{run_loss/total:.4f}\",\n",
    "            \"acc\":  f\"{correct/total:.4f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = run_loss/total\n",
    "    train_acc  = correct/total\n",
    "\n",
    "    # — Test —\n",
    "    model.eval()\n",
    "    test_bar = tqdm(test_loader, desc=f\"Epoch {epoch} Test \", unit=\"batch\")\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_bar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "            correct += (preds == yb).all(dim=1).sum().item()\n",
    "            total   += xb.size(0)\n",
    "\n",
    "            test_bar.set_postfix({\n",
    "                \"loss\": f\"{test_loss/total:.4f}\",\n",
    "                \"acc\":  f\"{correct/total:.4f}\"\n",
    "            })\n",
    "\n",
    "    test_loss /= total\n",
    "    test_acc   = correct/total\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt = f\"panns_cnn14_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\":       epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"train_loss\":  train_loss,\n",
    "        \"test_loss\":   test_loss\n",
    "    }, ckpt)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\":     train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_loss\":      test_loss,\n",
    "        \"test_accuracy\":  test_acc\n",
    "    }, step=epoch)\n",
    "    log_system_metrics_mlflow(step=epoch)\n",
    "    mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_ckpt     = ckpt\n",
    "\n",
    "    print(f\"→ Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} │ \"\n",
    "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3ab94-6087-46df-993d-ab070c741e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"best_test_accuracy\", best_test_acc)\n",
    "mlflow.log_artifact(best_ckpt, artifact_path=\"model\")\n",
    "mlflow.pytorch.log_model(model, \"panns_cnn14_model\")\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
