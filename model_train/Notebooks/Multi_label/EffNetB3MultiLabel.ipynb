{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ba2d9b-ac8c-4e3f-81f3-36280fb8fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from peft import get_peft_model, LoraConfig\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
    "from torch.amp import autocast, GradScaler\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3632695b-4e73-412f-91b6-a9819609467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 17:05:27 INFO mlflow.tracking.fluent: Experiment with name 'EfficientNetB3_LoRA' does not exist. Creating a new experiment.\n",
      "2025/05/07 17:05:27 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "mlflow.set_experiment(\"EfficientNetB3_LoRA\")\n",
    "if mlflow.active_run(): \n",
    "    mlflow.end_run()\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU/CPU info\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "     for cmd in [\"nvidia-smi\",\"rocm-smi\"]\n",
    "     if subprocess.run(f\"command -v {cmd}\", shell=True, capture_output=True).returncode==0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "def log_sys(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    m = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", m.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", m.percent, step=step)\n",
    "    u = nvmlDeviceGetUtilizationRates(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.utilization\", u.gpu, step=step)\n",
    "    gm = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.mem.used\", gm.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.mem.percent\", (gm.used/gm.total)*100, step=step)\n",
    "    t = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.temperature\", t, step=step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b08352b-33f7-4686-b465-0e6ff0add88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE     = 64\n",
    "LR             = 1e-4\n",
    "WEIGHT_DECAY   = 1e-4\n",
    "EPOCHS         = 20\n",
    "SAVE_EPOCH_CK  = False\n",
    "BEST_CKPT      = \"best_effb3_lora.pt\"\n",
    "\n",
    "TAXONOMY_CSV   = \"/home/jovyan/Data/birdclef-2025/taxonomy.csv\"\n",
    "TRAIN_MAN      = \"/home/jovyan/Features/manifest_train.csv\"\n",
    "TEST_MAN       = \"/home/jovyan/Features/manifest_test.csv\"\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "FEATURE_BASE   = \"/home/jovyan/Features\"\n",
    "\n",
    "TARGET_MODULES  = [\"conv_pw\",\"conv_dw\",\"conv_pwl\",\"conv_head\"]\n",
    "MODULES_TO_SAVE = [\"classifier\"]\n",
    "\n",
    "tax_df     = pd.read_csv(TAXONOMY_CSV)\n",
    "CLASSES    = sorted(tax_df[\"primary_label\"].astype(str).tolist())\n",
    "NUM_CLASSES= len(CLASSES)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":           \"efficientnet_b3_lora\",\n",
    "    \"input\":           \"mel\",\n",
    "    \"num_classes\":     NUM_CLASSES,\n",
    "    \"batch_size\":      BATCH_SIZE,\n",
    "    \"lr\":              LR,\n",
    "    \"weight_decay\":    WEIGHT_DECAY,\n",
    "    \"epochs\":          EPOCHS,\n",
    "    \"save_epoch_ck\":   SAVE_EPOCH_CK,\n",
    "    \"lora_r\":          12,\n",
    "    \"lora_alpha\":      24,\n",
    "    \"lora_dropout\":    0.1,\n",
    "    \"target_modules\":  TARGET_MODULES\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0bf2ae9-98aa-43a3-a05b-d4cc6e3f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, meta_csv, base, classes, key=\"mel\"):\n",
    "        m = pd.read_csv(manifest_csv)\n",
    "        m[\"mel_path\"] = (\n",
    "            m[\"mel_path\"].astype(str)\n",
    "             .str.lstrip(os.sep)\n",
    "             .apply(lambda p: os.path.join(base,\"mel\",p))\n",
    "        )\n",
    "        meta = pd.read_csv(meta_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"rid\"]  = meta.filename.str.replace(r\"\\.ogg$\",\"\",regex=True)\n",
    "        meta[\"secs\"]= meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.rid, meta.secs))\n",
    "\n",
    "        self.rows     = []\n",
    "        self.idx_map  = {c:i for i,c in enumerate(classes)}\n",
    "        self.num_cls  = len(classes)\n",
    "        self.key      = key\n",
    "\n",
    "        for _, r in tqdm(m.iterrows(), total=len(m), desc=\"Building dataset\"):\n",
    "            rid     = r.chunk_id.split(\"_chk\")[0]\n",
    "            labs    = [r.primary_label] + sec_map.get(rid, [])\n",
    "            labs    = [l for l in labs if l in self.idx_map]\n",
    "            prim_idx= self.idx_map[r.primary_label]\n",
    "            self.rows.append((r.mel_path, labs, prim_idx))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path, labs, prim_idx = self.rows[i]\n",
    "        arr = np.load(path)[self.key]                # [n_mels,n_frames]\n",
    "        x   = torch.from_numpy(arr).unsqueeze(0).float()  # [1,n_mels,n_frames]\n",
    "        y   = torch.zeros(self.num_cls, dtype=torch.float32)\n",
    "        for c in labs:\n",
    "            y[self.idx_map[c]] = 1.0\n",
    "        return x, y, prim_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8327409-bd58-42fc-abd5-0d182bd75e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108451/108451 [00:05<00:00, 21684.08it/s]\n",
      "Building dataset: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11022/11022 [00:00<00:00, 22867.73it/s]\n"
     ]
    }
   ],
   "source": [
    "def mixup(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha,alpha) if alpha>0 else 1.0\n",
    "    idx = torch.randperm(x.size(0), device=x.device)\n",
    "    return lam*x + (1-lam)*x[idx], y, y[idx], lam\n",
    "\n",
    "train_ds = MelDataset(TRAIN_MAN, TRAIN_CSV, FEATURE_BASE, CLASSES)\n",
    "test_ds  = MelDataset(TEST_MAN,  TRAIN_CSV, FEATURE_BASE, CLASSES)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,  num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d934daf5-9428-414a-98c5-bec265a1bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnetb3_lora(num_classes):\n",
    "    base = timm.create_model(\"efficientnet_b3\", pretrained=True)\n",
    "    # patch forward\n",
    "    orig_forward = base.forward\n",
    "    def forward_patch(*args, **kwargs):\n",
    "        # Accept either positional input or named input_ids/inputs_embeds\n",
    "        if \"input_ids\" in kwargs:\n",
    "            x = kwargs.pop(\"input_ids\")\n",
    "        elif \"inputs_embeds\" in kwargs:\n",
    "            x = kwargs.pop(\"inputs_embeds\")\n",
    "        elif len(args) > 0:\n",
    "            x = args[0]\n",
    "        else:\n",
    "            raise ValueError(\"No input tensor found\")\n",
    "        # drop any other transformer‚Äêstyle kwargs silently\n",
    "        for k in list(kwargs.keys()):\n",
    "            kwargs.pop(k)\n",
    "        return orig_forward(x)\n",
    "    base.forward = forward_patch\n",
    "\n",
    "    # adapt to 1‚Äëchannel\n",
    "    stem = base.conv_stem\n",
    "    base.conv_stem = nn.Conv2d(1, stem.out_channels,\n",
    "                               kernel_size=stem.kernel_size,\n",
    "                               stride=stem.stride,\n",
    "                               padding=stem.padding,\n",
    "                               bias=False)\n",
    "    # replace head\n",
    "    in_f = base.classifier.in_features\n",
    "    base.classifier = nn.Linear(in_f, num_classes)\n",
    "    # apply LoRA\n",
    "    lora_cfg = LoraConfig(\n",
    "        r=12, lora_alpha=24,\n",
    "        target_modules=TARGET_MODULES,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        modules_to_save=MODULES_TO_SAVE,\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=False\n",
    "    )\n",
    "    model = get_peft_model(base, lora_cfg)\n",
    "    return model\n",
    "\n",
    "model     = build_efficientnetb3_lora(NUM_CLASSES).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LR,\n",
    "    steps_per_epoch=len(train_loader),\n",
    "    epochs=EPOCHS,\n",
    "    pct_start=0.1, div_factor=10\n",
    ")\n",
    "scaler    = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af6d6ed-6ecc-4793-a8ae-0d16c7317750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[1/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:23<00:00,  8.34batch/s, loss=0.1076]\n",
      "[1/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.12batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 1/20  F1=0.0197  AP=0.0146  PrimAcc=0.0312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:30<00:00,  8.03batch/s, loss=0.0272]\n",
      "[2/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 2/20  F1=0.0527  AP=0.1329  PrimAcc=0.1541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[3/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:27<00:00,  8.18batch/s, loss=0.0217]\n",
      "[3/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 3/20  F1=0.2380  AP=0.3856  PrimAcc=0.3759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[4/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:29<00:00,  8.09batch/s, loss=0.0180]\n",
      "[4/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 22.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 4/20  F1=0.4612  AP=0.5119  PrimAcc=0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[5/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:22<00:00,  8.37batch/s, loss=0.0160]\n",
      "[5/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 5/20  F1=0.5487  AP=0.5574  PrimAcc=0.5298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[6/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:24<00:00,  8.28batch/s, loss=0.0147]\n",
      "[6/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 6/20  F1=0.5665  AP=0.5846  PrimAcc=0.5567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[7/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:23<00:00,  8.35batch/s, loss=0.0140]\n",
      "[7/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 7/20  F1=0.6105  AP=0.6419  PrimAcc=0.6005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[8/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:39<00:00,  7.73batch/s, loss=0.0132]\n",
      "[8/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.83batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 8/20  F1=0.5767  AP=0.6502  PrimAcc=0.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[9/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:24<00:00,  8.28batch/s, loss=0.0125]\n",
      "[9/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.82batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 9/20  F1=0.6308  AP=0.6538  PrimAcc=0.6154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[10/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:30<00:00,  8.05batch/s, loss=0.0122]\n",
      "[10/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 10/20  F1=0.6029  AP=0.6678  PrimAcc=0.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[11/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:22<00:00,  8.36batch/s, loss=0.0118]\n",
      "[11/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 11/20  F1=0.6198  AP=0.6775  PrimAcc=0.6386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:23<00:00,  8.34batch/s, loss=0.0117]\n",
      "[12/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 12/20  F1=0.6009  AP=0.6801  PrimAcc=0.6428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:28<00:00,  8.14batch/s, loss=0.0111]\n",
      "[13/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.95batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 13/20  F1=0.6293  AP=0.6788  PrimAcc=0.6423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:24<00:00,  8.29batch/s, loss=0.0109]\n",
      "[14/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.61batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 14/20  F1=0.6094  AP=0.6841  PrimAcc=0.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:25<00:00,  8.25batch/s, loss=0.0106]\n",
      "[15/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 15/20  F1=0.6397  AP=0.6857  PrimAcc=0.6472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:29<00:00,  8.08batch/s, loss=0.0103]\n",
      "[16/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 16/20  F1=0.6403  AP=0.6865  PrimAcc=0.6503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:27<00:00,  8.16batch/s, loss=0.0106]\n",
      "[17/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 17/20  F1=0.6166  AP=0.6852  PrimAcc=0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[18/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:27<00:00,  8.17batch/s, loss=0.0102]\n",
      "[18/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 18/20  F1=0.6289  AP=0.6895  PrimAcc=0.6535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:27<00:00,  8.19batch/s, loss=0.0103]\n",
      "[19/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 24.01batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 19/20  F1=0.6390  AP=0.6887  PrimAcc=0.6550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20/20] Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [03:26<00:00,  8.19batch/s, loss=0.0102]\n",
      "[20/20] Eval : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:07<00:00, 23.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 20/20  F1=0.6463  AP=0.6906  PrimAcc=0.6553\n"
     ]
    }
   ],
   "source": [
    "best_f1, best_ap, best_acc = 0.0, 0.0, 0.0\n",
    "thresholds = np.full(NUM_CLASSES, 0.5, dtype=np.float32)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # ‚Äî Train ‚Äî\n",
    "    model.train()\n",
    "    run_loss, total = 0.0, 0\n",
    "    tbar = tqdm(train_loader, desc=f\"[{epoch}/{EPOCHS}] Train\", unit=\"batch\")\n",
    "    for xb, yb, _ in tbar:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        # optional mixup\n",
    "        xb_m, ya, yb_m, lam = mixup(xb, yb)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            logits = model(xb_m)\n",
    "            loss   = lam*criterion(logits, ya) + (1-lam)*criterion(logits, yb_m)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        bs = xb.size(0)\n",
    "        run_loss += loss.item()*bs\n",
    "        total    += bs\n",
    "        tbar.set_postfix({\"loss\": f\"{run_loss/total:.4f}\"})\n",
    "    train_loss = run_loss/total\n",
    "\n",
    "    # ‚Äî Eval ‚Äî\n",
    "    model.eval()\n",
    "    all_scores, all_tgts, all_prims = [], [], []\n",
    "    val_loss, total = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, prim_idx in tqdm(test_loader, desc=f\"[{epoch}/{EPOCHS}] Eval \", unit=\"batch\"):\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                logits = model(xb)\n",
    "                val_loss += criterion(logits, yb).item()*xb.size(0)\n",
    "                scores   = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_scores.append(scores)\n",
    "            all_tgts.append(yb.cpu().numpy())\n",
    "            all_prims.extend(prim_idx.tolist())\n",
    "            total += xb.size(0)\n",
    "\n",
    "    val_loss /= total\n",
    "    scores = np.vstack(all_scores)\n",
    "    tgts   = np.vstack(all_tgts)\n",
    "    prims  = np.array(all_prims, dtype=int)\n",
    "\n",
    "    # threshold calibration\n",
    "    for i in range(NUM_CLASSES):\n",
    "        y_true = tgts[:,i]\n",
    "        if 0 < y_true.sum() < len(y_true):\n",
    "            prec, rec, th = precision_recall_curve(y_true, scores[:,i])\n",
    "            f1_vals = 2*prec*rec/(prec+rec+1e-8)\n",
    "            best    = np.nanargmax(f1_vals[:-1])\n",
    "            thresholds[i] = th[best]\n",
    "\n",
    "    preds      = (scores >= thresholds).astype(int)\n",
    "    micro_f1   = f1_score(tgts, preds, average=\"micro\", zero_division=0)\n",
    "    micro_ap   = average_precision_score(tgts, scores, average=\"micro\")\n",
    "    top1       = scores.argmax(axis=1)\n",
    "    primary_acc= (top1 == prims).mean()\n",
    "\n",
    "    # checkpoint best only\n",
    "    if micro_f1 > best_f1:\n",
    "        best_f1, best_ap, best_acc = micro_f1, micro_ap, primary_acc\n",
    "        torch.save(model.state_dict(), BEST_CKPT)\n",
    "        mlflow.log_artifact(BEST_CKPT, artifact_path=\"model\")\n",
    "\n",
    "    # log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\":    train_loss,\n",
    "        \"val_loss\":      val_loss,\n",
    "        \"micro_f1\":      micro_f1,\n",
    "        \"micro_ap\":      micro_ap,\n",
    "        \"primary_acc\":   primary_acc\n",
    "    }, step=epoch)\n",
    "    log_sys(step=epoch)\n",
    "\n",
    "    print(f\"‚Üí Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"F1={micro_f1:.4f}  AP={micro_ap:.4f}  PrimAcc={primary_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ffc0c59-1978-4488-87e9-aca157ca6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 18:24:32 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/05/07 18:24:32 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run dapper-grouse-349 at: http://192.5.87.49:8000/#/experiments/7/runs/30fa06b0068143b2b0cae573e6581e87\n",
      "üß™ View experiment at: http://192.5.87.49:8000/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "mlflow.log_metric(\"best_micro_f1\", best_f1)\n",
    "mlflow.log_metric(\"best_micro_ap\", best_ap)\n",
    "mlflow.log_metric(\"best_primary_acc\", best_acc)\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
