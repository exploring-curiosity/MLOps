{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba2d9b-ac8c-4e3f-81f3-36280fb8fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632695b-4e73-412f-91b6-a9819609467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "mlflow.set_experiment(\"EfficientNetB3_LoRA\")\n",
    "try: mlflow.end_run()\n",
    "except: pass\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "# log GPU info\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "      for cmd in [\"nvidia-smi\", \"rocm-smi\"]\n",
    "      if subprocess.run(f\"command -v {cmd}\", shell=True,\n",
    "                        capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def log_system_metrics_mlflow(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    mem = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", mem.percent, step=step)\n",
    "    g = nvmlDeviceGetUtilizationRates(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.utilization\", g.gpu, step=step)\n",
    "    m = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.used\", m.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.percent\", (m.used/m.total)*100, step=step)\n",
    "    t = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.0.temperature\", t, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf2ae9-98aa-43a3-a05b-d4cc6e3f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, metadata_csv, mel_key=\"mel\"):\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        meta = pd.read_csv(metadata_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"recording_id\"] = meta.filename.str.replace(r\"\\.ogg$\",\"\",regex=True)\n",
    "        meta[\"sec_list\"]     = meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.recording_id, meta.sec_list))\n",
    "\n",
    "        self.rows = []\n",
    "        all_labels = set()\n",
    "        for _, row in tqdm(m_df.iterrows(),\n",
    "                            total=len(m_df),\n",
    "                            desc=f\"Building MelDataset ({os.path.basename(manifest_csv)})\"):\n",
    "            rid = row.chunk_id.split(\"_chk\")[0]\n",
    "            labs = [row.primary_label] + sec_map.get(rid, [])\n",
    "            all_labels.update(labs)\n",
    "            self.rows.append({\"mel_path\": row.mel_path, \"labels\": labs})\n",
    "\n",
    "        self.classes   = sorted(all_labels)\n",
    "        self.label2idx = {l:i for i,l in enumerate(self.classes)}\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.mel_key = mel_key\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.rows[idx]\n",
    "        arr = np.load(r[\"mel_path\"])[self.mel_key]    # (n_mels, n_frames)\n",
    "        x   = torch.from_numpy(arr).unsqueeze(0).float()  # (1,n_mels,n_frames)\n",
    "        y   = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for l in r[\"labels\"]:\n",
    "            y[self.label2idx[l]] = 1.0\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d934daf5-9428-414a-98c5-bec265a1bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnetb3_lora(num_classes):\n",
    "    # load backbone\n",
    "    model = timm.create_model(\"efficientnet_b3\", pretrained=True)\n",
    "    # adapt stem conv to 1‑channel\n",
    "    stem = model.conv_stem\n",
    "    model.conv_stem = nn.Conv2d(1, stem.out_channels,\n",
    "                                kernel_size=stem.kernel_size,\n",
    "                                stride=stem.stride,\n",
    "                                padding=stem.padding,\n",
    "                                bias=False)\n",
    "    # replace classifier head\n",
    "    in_f = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(in_f, num_classes)\n",
    "\n",
    "    # configure and wrap in LoRA\n",
    "    peft_cfg = LoraConfig(\n",
    "        task_type=TaskType.IMAGE_CLASSIFICATION,\n",
    "        inference_mode=False,\n",
    "        r=4,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"conv_stem\",\"classifier\"]\n",
    "    )\n",
    "    model = get_peft_model(model, peft_cfg)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6d6ed-6ecc-4793-a8ae-0d16c7317750",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MANIFEST = \"/home/jovyan/Features/manifest_train.csv\"\n",
    "TEST_MANIFEST  = \"/home/jovyan/Features/manifest_test.csv\"\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "LR         = 1e-4\n",
    "EPOCHS     = 30\n",
    "\n",
    "train_ds = MelDataset(TRAIN_MANIFEST, TRAIN_CSV)\n",
    "test_ds  = MelDataset(TEST_MANIFEST,  TRAIN_CSV)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = build_efficientnetb3_lora(train_ds.num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":        \"efficientnet_b3+lora\",\n",
    "    \"input\":        \"mel\",\n",
    "    \"num_classes\":  train_ds.num_classes,\n",
    "    \"batch_size\":   BATCH_SIZE,\n",
    "    \"lr\":           LR,\n",
    "    \"epochs\":       EPOCHS,\n",
    "    \"lora_r\":       4,\n",
    "    \"lora_alpha\":   16\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d00b77-8332-46a2-9448-c429f2051408",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_test_acc, best_ckpt = 0.0, None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # — Train —\n",
    "    model.train()\n",
    "    train_bar = tqdm(train_loader,\n",
    "                     desc=f\"Epoch {epoch} Train\",\n",
    "                     unit=\"batch\")\n",
    "    run_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for xb, yb in train_bar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item()*xb.size(0)\n",
    "        preds = (torch.sigmoid(logits)>0.5).float()\n",
    "        correct += (preds==yb).all(dim=1).sum().item()\n",
    "        total   += xb.size(0)\n",
    "\n",
    "        train_bar.set_postfix({\n",
    "            \"loss\": f\"{run_loss/total:.4f}\",\n",
    "            \"acc\":  f\"{correct/total:.4f}\"\n",
    "        })\n",
    "\n",
    "    train_loss = run_loss/total\n",
    "    train_acc  = correct/total\n",
    "\n",
    "    # — Test —\n",
    "    model.eval()\n",
    "    test_bar = tqdm(test_loader,\n",
    "                    desc=f\"Epoch {epoch} Test \",\n",
    "                    unit=\"batch\")\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_bar:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "            test_loss += loss.item()*xb.size(0)\n",
    "            preds = (torch.sigmoid(logits)>0.5).float()\n",
    "            correct += (preds==yb).all(dim=1).sum().item()\n",
    "            total   += xb.size(0)\n",
    "\n",
    "            test_bar.set_postfix({\n",
    "                \"loss\": f\"{test_loss/total:.4f}\",\n",
    "                \"acc\":  f\"{correct/total:.4f}\"\n",
    "            })\n",
    "\n",
    "    test_loss /= total\n",
    "    test_acc   = correct/total\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt = f\"effb3_lora_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\":       epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"train_loss\":  train_loss,\n",
    "        \"test_loss\":   test_loss\n",
    "    }, ckpt)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_accuracy\": test_acc\n",
    "    }, step=epoch)\n",
    "    log_system_metrics_mlflow(step=epoch)\n",
    "    mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc = test_acc\n",
    "        best_ckpt     = ckpt\n",
    "\n",
    "    print(f\"→ Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} │ \"\n",
    "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc0c59-1978-4488-87e9-aca157ca6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.log_metric(\"best_test_accuracy\", best_test_acc)\n",
    "mlflow.log_artifact(best_ckpt, artifact_path=\"model\")\n",
    "mlflow.pytorch.log_model(model, \"effb3_lora_model\")\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
