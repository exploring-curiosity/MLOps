{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ba2d9b-ac8c-4e3f-81f3-36280fb8fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import timm\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from types import SimpleNamespace\n",
    "from pynvml import (\n",
    "    nvmlInit, nvmlDeviceGetHandleByIndex,\n",
    "    nvmlDeviceGetUtilizationRates, nvmlDeviceGetMemoryInfo,\n",
    "    nvmlDeviceGetTemperature, NVML_TEMPERATURE_GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3632695b-4e73-412f-91b6-a9819609467a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 03:38:41 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "mlflow.set_experiment(\"EfficientNetB3_LoRA\")\n",
    "try: mlflow.end_run()\n",
    "except: pass\n",
    "mlflow.start_run(log_system_metrics=True)\n",
    "\n",
    "gpu_info = next(\n",
    "    (subprocess.run(cmd, capture_output=True, text=True).stdout\n",
    "     for cmd in [\"nvidia-smi\", \"rocm-smi\"]\n",
    "     if subprocess.run(f\"command -v {cmd}\", shell=True, capture_output=True).returncode == 0),\n",
    "    \"No GPU found.\"\n",
    ")\n",
    "mlflow.log_text(gpu_info, \"gpu-info.txt\")\n",
    "\n",
    "nvmlInit()\n",
    "gpu_handle = nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "def log_system_metrics_mlflow(step=None):\n",
    "    mlflow.log_metric(\"system.cpu.utilization\", psutil.cpu_percent(), step=step)\n",
    "    mem = psutil.virtual_memory()\n",
    "    mlflow.log_metric(\"system.memory.used\", mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.memory.percent\", mem.percent, step=step)\n",
    "    gpu_util = nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "    mlflow.log_metric(\"system.gpu.0.utilization\", gpu_util, step=step)\n",
    "    gpu_mem = nvmlDeviceGetMemoryInfo(gpu_handle)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.used\", gpu_mem.used, step=step)\n",
    "    mlflow.log_metric(\"system.gpu.0.memory.percent\",\n",
    "                      (gpu_mem.used / gpu_mem.total) * 100, step=step)\n",
    "    gpu_temp = nvmlDeviceGetTemperature(gpu_handle, NVML_TEMPERATURE_GPU)\n",
    "    mlflow.log_metric(\"system.gpu.0.temperature\", gpu_temp, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b08352b-33f7-4686-b465-0e6ff0add88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_df      = pd.read_csv(\"/home/jovyan/Data/birdclef-2025/taxonomy.csv\")\n",
    "classes     = sorted(tax_df['primary_label'].astype(str).tolist())\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0bf2ae9-98aa-43a3-a05b-d4cc6e3f6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelDataset(Dataset):\n",
    "    def __init__(self, manifest_csv, metadata_csv, feature_base, classes, mel_key=\"mel\"):\n",
    "        m_df = pd.read_csv(manifest_csv)\n",
    "        # build full mel npz paths\n",
    "        m_df[\"mel_path\"] = (\n",
    "            m_df[\"mel_path\"].astype(str)\n",
    "                .str.lstrip(os.sep)\n",
    "                .apply(lambda p: os.path.join(feature_base, \"mel\", p))\n",
    "        )\n",
    "        # load secondary labels\n",
    "        meta = pd.read_csv(metadata_csv, usecols=[\"filename\",\"secondary_labels\"])\n",
    "        meta[\"recording_id\"]   = meta.filename.str.replace(r\"\\.ogg$\",\"\",regex=True)\n",
    "        meta[\"secondary_list\"] = meta.secondary_labels.fillna(\"\").str.split()\n",
    "        sec_map = dict(zip(meta.recording_id, meta.secondary_list))\n",
    "\n",
    "        self.rows       = []\n",
    "        self.label2idx  = {lab:i for i, lab in enumerate(classes)}\n",
    "        self.num_classes= len(classes)\n",
    "        self.mel_key    = mel_key\n",
    "\n",
    "        for _, row in tqdm(m_df.iterrows(), total=len(m_df),\n",
    "                          desc=f\"Building {os.path.basename(manifest_csv)}\"):\n",
    "            rid  = row.chunk_id.split(\"_chk\")[0]\n",
    "            labs = [row.primary_label] + sec_map.get(rid, [])\n",
    "            # filter to only known classes\n",
    "            labs = [l for l in labs if l in self.label2idx]\n",
    "            self.rows.append({\"mel_path\": row.mel_path, \"labels\": labs})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rows)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        r   = self.rows[idx]\n",
    "        arr = np.load(r[\"mel_path\"])[self.mel_key]          # (n_mels, n_frames)\n",
    "        x   = torch.from_numpy(arr).unsqueeze(0).float()     # (1, n_mels, n_frames)\n",
    "        y   = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        for lab in r[\"labels\"]:\n",
    "            y[self.label2idx[lab]] = 1.0\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d934daf5-9428-414a-98c5-bec265a1bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnetb3_lora(num_classes):\n",
    "    base = timm.create_model(\"efficientnet_b3\", pretrained=True)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ Monkey‚Äëpatch forward to swallow input_ids / kwargs ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    orig_forward = base.forward\n",
    "    def forward_patch(*args, input_ids=None, **kwargs):\n",
    "        # PEFT wrapper will call this with input_ids=xb (our tensor)\n",
    "        x = input_ids if input_ids is not None else args[0]\n",
    "        return orig_forward(x)\n",
    "    base.forward = forward_patch\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ Adapt to 1‚Äëchannel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    stem = base.conv_stem\n",
    "    base.conv_stem = nn.Conv2d(\n",
    "        in_channels=1,\n",
    "        out_channels=stem.out_channels,\n",
    "        kernel_size=stem.kernel_size,\n",
    "        stride=stem.stride,\n",
    "        padding=stem.padding,\n",
    "        bias=False\n",
    "    )\n",
    "    # ‚îÄ‚îÄ‚îÄ Replace the classifier head ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    in_feat = base.classifier.in_features\n",
    "    base.classifier = nn.Linear(in_feat, num_classes)\n",
    "\n",
    "    lora_config = LoraConfig(\n",
    "        r=12,\n",
    "        lora_alpha=24,\n",
    "        target_modules=TARGET_MODULES,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        modules_to_save=MODULES_TO_SAVE,\n",
    "        task_type=\"FEATURE_EXTRACTION\",\n",
    "        inference_mode=False\n",
    "    )\n",
    "    model = get_peft_model(base, lora_config)\n",
    "    model.print_trainable_parameters()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5af6d6ed-6ecc-4793-a8ae-0d16c7317750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building manifest_train.csv: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 108451/108451 [00:04<00:00, 22855.52it/s]\n",
      "Building manifest_test.csv: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11022/11022 [00:00<00:00, 23751.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 5,572,334 || all params: 16,584,468 || trainable%: 33.5997\n"
     ]
    }
   ],
   "source": [
    "FEATURE_BASE   = \"/home/jovyan/Features\"\n",
    "TRAIN_MANIFEST = os.path.join(FEATURE_BASE, \"manifest_train.csv\")\n",
    "TEST_MANIFEST  = os.path.join(FEATURE_BASE, \"manifest_test.csv\")\n",
    "TRAIN_CSV      = \"/home/jovyan/Data/birdclef-2025/train.csv\"\n",
    "\n",
    "TARGET_MODULES  = [\"conv_pw\", \"conv_dw\", \"conv_pwl\", \"conv_head\"]\n",
    "MODULES_TO_SAVE = [\"classifier\"]\n",
    "\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LR         = 1e-4\n",
    "EPOCHS     = 1\n",
    "\n",
    "train_ds = MelDataset(TRAIN_MANIFEST, TRAIN_CSV, FEATURE_BASE, classes)\n",
    "test_ds  = MelDataset(TEST_MANIFEST,  TRAIN_CSV, FEATURE_BASE, classes)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE,\n",
    "                          shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model     = build_efficientnetb3_lora(num_classes).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "mlflow.log_params({\n",
    "    \"model\":           \"efficientnet_b3_lora\",\n",
    "    \"input\":           \"mel\",\n",
    "    \"num_classes\":     num_classes,\n",
    "    \"batch_size\":      BATCH_SIZE,\n",
    "    \"lr\":              LR,\n",
    "    \"epochs\":          EPOCHS,\n",
    "    \"lora_r\":          12,\n",
    "    \"lora_alpha\":      24,\n",
    "    \"lora_dropout\":    0.1,\n",
    "    \"target_modules\":  TARGET_MODULES\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7d00b77-8332-46a2-9448-c429f2051408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1695/1695 [05:36<00:00,  5.04batch/s, loss=0.0363, acc=0.0158]\n",
      "Epoch 1 Test : 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 173/173 [00:12<00:00, 14.19batch/s, loss=0.0241, acc=0.0351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Üí Epoch 1/1  Train loss=0.0363, acc=0.0158 ‚îÇ Test loss=0.0241, acc=0.0351\n"
     ]
    }
   ],
   "source": [
    "best_test_acc, best_ckpt = 0.0, None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # ‚Äî Train ‚Äî\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} Train\", unit=\"batch\")\n",
    "    run_loss, correct, total = 0.0, 0, 0\n",
    "    for xb, yb in pbar:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss   = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        run_loss += loss.item() * xb.size(0)\n",
    "        preds    = (torch.sigmoid(logits)>0.5).float()\n",
    "        correct  += (preds==yb).all(dim=1).sum().item()\n",
    "        total    += xb.size(0)\n",
    "        pbar.set_postfix({\"loss\":f\"{run_loss/total:.4f}\",\n",
    "                          \"acc\": f\"{correct/total:.4f}\"})\n",
    "\n",
    "    train_loss, train_acc = run_loss/total, correct/total\n",
    "\n",
    "    # ‚Äî Test ‚Äî\n",
    "    model.eval()\n",
    "    pbar = tqdm(test_loader, desc=f\"Epoch {epoch} Test \", unit=\"batch\")\n",
    "    test_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in pbar:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss   = criterion(logits, yb)\n",
    "\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            preds      = (torch.sigmoid(logits)>0.5).float()\n",
    "            correct   += (preds==yb).all(dim=1).sum().item()\n",
    "            total     += xb.size(0)\n",
    "            pbar.set_postfix({\"loss\":f\"{test_loss/total:.4f}\",\n",
    "                              \"acc\": f\"{correct/total:.4f}\"})\n",
    "\n",
    "    test_loss, test_acc = test_loss/total, correct/total\n",
    "\n",
    "    # ‚Äî Checkpoint ‚Äî\n",
    "    ckpt = f\"effb3_lora_epoch_{epoch}.pt\"\n",
    "    torch.save({\n",
    "        \"epoch\":       epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"train_loss\":  train_loss,\n",
    "        \"test_loss\":   test_loss\n",
    "    }, ckpt)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"train_loss\":     train_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_loss\":      test_loss,\n",
    "        \"test_accuracy\":  test_acc\n",
    "    }, step=epoch)\n",
    "    log_system_metrics_mlflow(step=epoch)\n",
    "    mlflow.log_artifact(ckpt, artifact_path=\"checkpoints\")\n",
    "\n",
    "    if test_acc > best_test_acc:\n",
    "        best_test_acc, best_ckpt = test_acc, ckpt\n",
    "\n",
    "    print(f\"‚Üí Epoch {epoch}/{EPOCHS}  \"\n",
    "          f\"Train loss={train_loss:.4f}, acc={train_acc:.4f} ‚îÇ \"\n",
    "          f\"Test loss={test_loss:.4f}, acc={test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ffc0c59-1978-4488-87e9-aca157ca6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/07 03:44:57 WARNING mlflow.utils.requirements_utils: Found torch version (2.7.0+cu128) contains a local version label (+cu128). MLflow logged a pip requirement for this package as 'torch==2.7.0' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/07 03:45:08 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/05/07 03:45:08 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run funny-colt-568 at: http://192.5.87.49:8000/#/experiments/3/runs/7e2c3350dc09484ca4221d28b614e35c\n",
      "üß™ View experiment at: http://192.5.87.49:8000/#/experiments/3\n"
     ]
    }
   ],
   "source": [
    "mlflow.log_metric(\"best_test_accuracy\", best_test_acc)\n",
    "\n",
    "LOCAL_MODEL_DIR = \"effb3_lora_local\"\n",
    "mlflow.pytorch.save_model(model, LOCAL_MODEL_DIR)\n",
    "mlflow.log_artifacts(LOCAL_MODEL_DIR, artifact_path=\"effb3_lora_model\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
