{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1035966-8a7e-4fe8-98b1-0348e213826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import torch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.signal import butter, filtfilt\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "DATA_ROOT        = '/home/jovyan/Data/birdclef-2025'\n",
    "AUDIO_DIR        = os.path.join(DATA_ROOT, 'train_audio')\n",
    "CSV_PATH         = os.path.join(DATA_ROOT, 'train.csv')\n",
    "\n",
    "DEN_DIR          = '/home/jovyan/Features/denoised'\n",
    "MEL_DIR          = '/home/jovyan/Features/mel'\n",
    "EMB_DIR          = '/home/jovyan/Features/embeddings'\n",
    "MEL_AUG_DIR      = '/home/jovyan/Features/mel_aug'\n",
    "\n",
    "for d in (DEN_DIR, MEL_DIR, EMB_DIR, MEL_AUG_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "PANNS_SR         = 32000\n",
    "CHUNK_SEC        = 10\n",
    "CHUNK_SAMPLES    = PANNS_SR * CHUNK_SEC\n",
    "\n",
    "N_FFT            = 2048\n",
    "HOP_LENGTH       = 1024\n",
    "N_MELS           = 64\n",
    "\n",
    "SAMPLE_FRAC      = 1.0\n",
    "\n",
    "# PANNs & augmentation params\n",
    "BIRD_CLASS_IDXS  = [\n",
    "    14,22,27,28,33,34,35,37,40,\n",
    "    72,73,80,84,\n",
    "    *range(98,107),108,\n",
    "    *range(111,122),\n",
    "    *range(126,133),\n",
    "    137,361,442,503\n",
    "]\n",
    "THRESH           = 0.5\n",
    "\n",
    "# band‑pass augmentation constants\n",
    "LOWCUT           = 2000     # Hz\n",
    "HIGHCUT          = 8000     # Hz\n",
    "BAND_ALPHA       = 2.0      # boost factor\n",
    "WINDOW_SEC       = 1.0\n",
    "\n",
    "PROP_DECREASE    = 0.9\n",
    "STATIONARY_NOISE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f325b11-e71b-460a-acc6-7f986e50df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mel_spectrogram(wave, sr=PANNS_SR):\n",
    "    m = librosa.feature.melspectrogram(\n",
    "        y=wave, sr=sr,\n",
    "        n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS\n",
    "    )\n",
    "    return librosa.power_to_db(m, ref=np.max)\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def augment_waveform_with_filter(wave, mask, sr,\n",
    "                                 lowcut=LOWCUT, highcut=HIGHCUT,\n",
    "                                 alpha=BAND_ALPHA):\n",
    "    \"\"\"\n",
    "    For each 1s window where mask==True, add a boosted\n",
    "    band‑pass filtered copy of wave in [lowcut,highcut].\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, sr, order=4)\n",
    "    wave_band = filtfilt(b, a, wave)\n",
    "    wave_aug  = wave.copy()\n",
    "    win_len   = int(WINDOW_SEC * sr)\n",
    "    for i, m in enumerate(mask):\n",
    "        if m:\n",
    "            start = i * win_len\n",
    "            end   = min((i+1) * win_len, len(wave))\n",
    "            wave_aug[start:end] = wave[start:end] + alpha * wave_band[start:end]\n",
    "    peak = np.max(np.abs(wave_aug))\n",
    "    if peak > 1.0:\n",
    "        wave_aug /= peak\n",
    "    return wave_aug\n",
    "\n",
    "def get_per_second_embeddings_and_mask(wave, model, device):\n",
    "    \"\"\"\n",
    "    Returns per-second embeddings and a bird_presence mask.\n",
    "    \"\"\"\n",
    "    win_len   = PANNS_SR\n",
    "    n_windows = math.ceil(len(wave) / win_len)\n",
    "    embs, mask = [], []\n",
    "    for w in range(n_windows):\n",
    "        seg = wave[w*win_len:(w+1)*win_len]\n",
    "        if len(seg) < win_len:\n",
    "            seg = np.pad(seg, (0, win_len-len(seg)), mode='constant')\n",
    "        inp = torch.from_numpy(seg).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            clipwise, emb = model.inference(inp)\n",
    "        probs  = clipwise.squeeze(0).cpu().numpy() if torch.is_tensor(clipwise) else np.squeeze(clipwise,0)\n",
    "        emb_np = emb.squeeze(0).cpu().numpy()      if torch.is_tensor(emb)      else np.squeeze(emb,0)\n",
    "        embs.append(emb_np)\n",
    "        score = probs[BIRD_CLASS_IDXS].max()\n",
    "        present = score > THRESH or int(np.argmax(probs)) in BIRD_CLASS_IDXS\n",
    "        mask.append(present)\n",
    "    return np.stack(embs), np.array(mask, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78bc5901-90f5-42e6-b5a5-05da6eb3feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── READ & SAMPLE METADATA ───────────────────────────────────────────────────\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "sampled = []\n",
    "for label, grp in meta.groupby('primary_label'):\n",
    "    n = max(1, int(len(grp) * SAMPLE_FRAC))\n",
    "    sampled.append(grp.sample(n=n, random_state=42))\n",
    "meta = pd.concat(sampled, ignore_index=True)\n",
    "\n",
    "# ─── CREATE SUBFOLDERS ────────────────────────────────────────────────────────\n",
    "subdirs = {os.path.dirname(f) for f in meta['filename']}\n",
    "for sub in subdirs:\n",
    "    if sub:\n",
    "        for base in (DEN_DIR, MEL_DIR, EMB_DIR, MEL_AUG_DIR):\n",
    "            os.makedirs(os.path.join(base, sub), exist_ok=True)\n",
    "\n",
    "# ─── PHASE 1: DENOISE & MEL ────────────────────────────────────────────────────\n",
    "den_manifest = []\n",
    "mel_manifest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1f634-bd84-4c1c-94ce-8a8e34fdb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phase1(record):\n",
    "    fname = record['filename']; label = record['primary_label']\n",
    "    src_fp = os.path.join(AUDIO_DIR, fname)\n",
    "    y, sr = sf.read(src_fp, dtype='float32')\n",
    "    if y.ndim>1: y=y.mean(1)\n",
    "    if sr!=PANNS_SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR); sr=PANNS_SR\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(fname))[0]\n",
    "    n_chunks = math.ceil(len(y)/CHUNK_SAMPLES)\n",
    "    for ci in range(n_chunks):\n",
    "        seg = y[ci*CHUNK_SAMPLES:(ci+1)*CHUNK_SAMPLES]\n",
    "        if len(seg)<CHUNK_SAMPLES:\n",
    "            seg = np.pad(seg,(0,CHUNK_SAMPLES-len(seg)),'constant')\n",
    "        # denoise\n",
    "        den = nr.reduce_noise(y=seg, sr=sr, stationary=False, prop_decrease=PROP_DECREASE)\n",
    "        den /= (np.max(np.abs(den))+1e-9)\n",
    "\n",
    "        chunk_id = f\"{base}_chk{ci}\"\n",
    "        # save denoised audio\n",
    "        rel_audio = f\"/{label}/{chunk_id}.ogg\"\n",
    "        sf.write(os.path.join(DEN_DIR,label,chunk_id+'.ogg'), den, sr, format='OGG', subtype='VORBIS')\n",
    "        den_manifest.append({'chunk_id':chunk_id,'audio_path':rel_audio,'primary_label':label})\n",
    "        # save mel\n",
    "        mel = calculate_mel_spectrogram(den, sr)\n",
    "        rel_mel = f\"/{label}/{chunk_id}.npz\"\n",
    "        np.savez_compressed(os.path.join(MEL_DIR,label,chunk_id+'.npz'),\n",
    "                            mel=mel.astype(np.float16), primary_label=label)\n",
    "        mel_manifest.append({'chunk_id':chunk_id,'mel_path':rel_mel,'primary_label':label})\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca5f3b-da0e-48a3-978a-b2470f82aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e20884ae8042a4a48a0475ecc0cc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoise & MEL by species:   0%|          | 0/28564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m records = meta[[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mprimary_label\u001b[39m\u001b[33m'\u001b[39m]].to_dict(\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(os.cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDenoise & MEL by species\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "records = meta[['filename','primary_label']].to_dict('records')\n",
    "with ThreadPool(os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap_unordered(process_phase1, records),\n",
    "              total=len(records), desc=\"Phase 1: denoise & mel\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104faf4-fc73-425b-919c-e8d9c3bd245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(den_manifest).to_csv(os.path.join(DEN_DIR,'manifest.csv'), index=False)\n",
    "pd.DataFrame(mel_manifest).to_csv(os.path.join(MEL_DIR,'manifest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7d10f6c-d426-4fc2-8e92-b38d9d27a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/jovyan/panns_data/Cnn14_mAP=0.431.pth\n",
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "panns_model = AudioTagging(checkpoint_path=None, device=device)\n",
    "panns_model.model.eval()\n",
    "\n",
    "emb_manifest     = []\n",
    "mel_aug_manifest = []\n",
    "\n",
    "# Gather denoised audio paths\n",
    "den_paths = []\n",
    "for root, _, files in os.walk(DEN_DIR):\n",
    "    for fname in files:\n",
    "        if fname.endswith('.ogg'):\n",
    "            den_paths.append(os.path.join(root, fname))\n",
    "den_paths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7491f3ae-7e80-4c4b-b2ef-ee867f55eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phase2(full_path):\n",
    "    # 1) load denoised audio\n",
    "    y, sr = sf.read(full_path, dtype='float32')\n",
    "    if sr != PANNS_SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR)\n",
    "        sr = PANNS_SR\n",
    "\n",
    "    # 2) per‑second embeddings & mask\n",
    "    embs, mask = get_per_second_embeddings_and_mask(y, panns_model, device)\n",
    "\n",
    "    # 3) save embeddings\n",
    "    rel = os.path.relpath(full_path, DEN_DIR)\n",
    "    subdir, fname = os.path.split(rel)\n",
    "    chunk_id = os.path.splitext(fname)[0]\n",
    "    out_emb_dir = os.path.join(EMB_DIR, subdir)\n",
    "    os.makedirs(out_emb_dir, exist_ok=True)\n",
    "    emb_path = os.path.join(out_emb_dir, f\"{chunk_id}_emb.npz\")\n",
    "    np.savez_compressed(emb_path,\n",
    "                        embedding=embs.astype(np.float32),\n",
    "                        mask=mask,\n",
    "                        primary_label=subdir)\n",
    "    emb_manifest.append({\n",
    "        'chunk_id':      chunk_id,\n",
    "        'emb_path':      f\"/{subdir}/{chunk_id}_emb.npz\",\n",
    "        'primary_label': subdir\n",
    "    })\n",
    "\n",
    "    # 4) filter‑based augmentation\n",
    "    y_aug = augment_waveform_with_filter(y, mask, sr)\n",
    "\n",
    "    # 5) re‑denoise\n",
    "    y_aug_dn = nr.reduce_noise(\n",
    "        y=y_aug, sr=sr,\n",
    "        stationary=STATIONARY_NOISE,\n",
    "        prop_decrease=PROP_DECREASE\n",
    "    )\n",
    "\n",
    "    # 6) compute augmented MEL\n",
    "    mel_aug = calculate_mel_spectrogram(y_aug_dn, sr)\n",
    "\n",
    "    # 7) save augmented MEL\n",
    "    out_mel_dir = os.path.join(MEL_AUG_DIR, subdir)\n",
    "    os.makedirs(out_mel_dir, exist_ok=True)\n",
    "    mel_aug_path = os.path.join(out_mel_dir, f\"{chunk_id}.npz\")\n",
    "    np.savez_compressed(mel_aug_path,\n",
    "                        mel=mel_aug.astype(np.float16),\n",
    "                        primary_label=subdir)\n",
    "    mel_aug_manifest.append({\n",
    "        'chunk_id':      chunk_id,\n",
    "        'mel_aug_path':  f\"/{subdir}/{chunk_id}.npz\",\n",
    "        'primary_label': subdir\n",
    "    })\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e37934-607f-457b-909a-4deee5e8468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52503d84465f42db8c0cb12fcde595b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase 2: embed & augment:   0%|          | 0/115357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with ThreadPool(os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap_unordered(process_phase2, den_paths),\n",
    "              total=len(den_paths),\n",
    "              desc=\"Phase 2: embed & augment\"))\n",
    "\n",
    "# ─── Write manifests ─────────────────────────────────────────────────────────\n",
    "pd.DataFrame(emb_manifest).to_csv(\n",
    "    os.path.join(EMB_DIR, 'manifest.csv'),\n",
    "    index=False\n",
    ")\n",
    "pd.DataFrame(mel_aug_manifest).to_csv(\n",
    "    os.path.join(MEL_AUG_DIR, 'manifest.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdcce1d-4fa3-4ce2-8dc3-0396b2f31c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/features.zip'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# will create /home/jovyan/features.zip containing everything under /home/jovyan/Features\n",
    "shutil.make_archive('/home/jovyan/features', 'zip', '/home/jovyan/Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0095d1a-a341-4e4f-9bb2-1700f56a103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ── CONFIGURE PATHS ───────────────────────────────────────────────────────────\n",
    "BASE_FEAT    = '/home/jovyan/Features'\n",
    "DEN_MANIFEST = os.path.join(BASE_FEAT, 'denoised',   'manifest.csv')\n",
    "MEL_MANIFEST = os.path.join(BASE_FEAT, 'mel',        'manifest.csv')\n",
    "EMB_MANIFEST = os.path.join(BASE_FEAT, 'embeddings', 'manifest.csv')\n",
    "\n",
    "OUT_DIR      = BASE_FEAT  # where we'll write manifest_train/test/reserve.csv\n",
    "\n",
    "# ── 1) LOAD & MERGE ALL FEATURE MANIFESTS ─────────────────────────────────────\n",
    "den_df = pd.read_csv(DEN_MANIFEST)[['chunk_id','audio_path','primary_label']]\n",
    "mel_df = pd.read_csv(MEL_MANIFEST)[['chunk_id','mel_path']]\n",
    "emb_df = pd.read_csv(EMB_MANIFEST)[['chunk_id','emb_path']]\n",
    "\n",
    "df = (\n",
    "    den_df\n",
    "    .merge(mel_df, on='chunk_id')\n",
    "    .merge(emb_df, on='chunk_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e5e235-515f-4f51-8f1d-858f1482b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['file_id'] = df['chunk_id'].str.rsplit('_chk', n=1).str[0]\n",
    "\n",
    "# ── 3) BUILD file‑level DataFrame for stratified splitting ─────────────────────\n",
    "files_df = df[['file_id','primary_label']].drop_duplicates().reset_index(drop=True)\n",
    "file_ids = files_df['file_id']\n",
    "file_labels = files_df['primary_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34ea8146-ee2d-46ff-924b-94ef72bf3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, temp_files, train_lbls, temp_lbls = train_test_split(\n",
    "    file_ids, file_labels,\n",
    "    train_size=0.6,\n",
    "    stratify=file_labels,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# From temp (40%), 25%→test (10% total), 75%→reserve (30% total)\n",
    "try:\n",
    "    test_files, reserve_files, _, _ = train_test_split(\n",
    "        temp_files, temp_lbls,\n",
    "        train_size=0.25,\n",
    "        stratify=temp_lbls,\n",
    "        random_state=42\n",
    "    )\n",
    "except ValueError:\n",
    "    # fallback if some file_ids have only one sample\n",
    "    test_files, reserve_files, _, _ = train_test_split(\n",
    "        temp_files, temp_lbls,\n",
    "        train_size=0.25,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "split_map = {}\n",
    "for fid in train_files:   split_map[fid] = 'train'\n",
    "for fid in test_files:    split_map[fid] = 'test'\n",
    "for fid in reserve_files: split_map[fid] = 'reserve'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c41759a-a340-4565-b2aa-e824cf363dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 69676 rows to /home/jovyan/Features/manifest_train.csv\n",
      "Wrote 11474 rows to /home/jovyan/Features/manifest_test.csv\n",
      "Wrote 34603 rows to /home/jovyan/Features/manifest_reserve.csv\n"
     ]
    }
   ],
   "source": [
    "df['split'] = df['file_id'].map(split_map)\n",
    "\n",
    "# ── 6) WRITE OUT chunk‑level manifests for each split ─────────────────────────\n",
    "for split in ['train','test','reserve']:\n",
    "    out_df = df[df['split']==split].drop(columns=['file_id','split'])\n",
    "    out_fp = os.path.join(OUT_DIR, f'manifest_{split}.csv')\n",
    "    out_df.to_csv(out_fp, index=False)\n",
    "    print(f\"Wrote {len(out_df)} rows to {out_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
