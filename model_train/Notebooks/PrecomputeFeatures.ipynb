{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1035966-8a7e-4fe8-98b1-0348e213826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, numpy as np, pandas as pd, soundfile as sf, librosa, noisereduce as nr\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "# Force spawn for multiprocessing (needed for CUDA-safe workers)\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# ─────── Hyperparameters, Paths & Subfolder Creation ───────\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT     = '/home/jovyan/Data/birdclef-2025'\n",
    "AUDIO_DIR     = os.path.join(DATA_ROOT, 'train_audio')\n",
    "CSV_PATH      = os.path.join(DATA_ROOT, 'train.csv')\n",
    "\n",
    "DEN_DIR       = '/home/jovyan/Features/denoised'\n",
    "MEL_DIR       = '/home/jovyan/Features/mel'\n",
    "EMB_DIR       = '/home/jovyan/Features/embeddings'\n",
    "os.makedirs(DEN_DIR, exist_ok=True)\n",
    "os.makedirs(MEL_DIR, exist_ok=True)\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "PANNS_SR      = 32000        # audio sample rate\n",
    "CHUNK_SEC     = 10\n",
    "CHUNK_SAMPLES = PANNS_SR * CHUNK_SEC\n",
    "\n",
    "\n",
    "# mel params (reduced)\n",
    "N_FFT        = 2048\n",
    "HOP_LENGTH   = 1024           # double to halve time‑frames\n",
    "N_MELS       = 64             # halve mel‑bins\n",
    "\n",
    "SAMPLE_FRAC   = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f325b11-e71b-460a-acc6-7f986e50df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mel_spectrogram(wave_np, sr=PANNS_SR,\n",
    "                              n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "                              n_mels=N_MELS):\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wave_np, sr=sr,\n",
    "        n_fft=n_fft, hop_length=hop_length,\n",
    "        n_mels=n_mels\n",
    "    )\n",
    "    return librosa.power_to_db(mel, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bc5901-90f5-42e6-b5a5-05da6eb3feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared base dirs and 206 nested subfolders under DEN_DIR and EMB_DIR.\n",
      "Processing 28564 files (100% of dataset)\n",
      "206\n"
     ]
    }
   ],
   "source": [
    "# ─── Read & Sample Metadata ───\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "sampled = []\n",
    "for label, grp in meta.groupby('primary_label'):\n",
    "    # target = 10% of this class, but at least 1, and never more than group size\n",
    "    n = max(1, int(len(grp) * SAMPLE_FRAC))\n",
    "    n = min(n, len(grp))\n",
    "    sampled.append(grp.sample(n=n, random_state=42))\n",
    "\n",
    "meta = pd.concat(sampled, ignore_index=True)\n",
    "\n",
    "# ─── Create matching subfolders in DEN_DIR & EMB_DIR ───\n",
    "subdirs = set(os.path.dirname(f) for f in meta['filename'])\n",
    "for sub in subdirs:\n",
    "    if not sub:\n",
    "        continue\n",
    "    os.makedirs(os.path.join(DEN_DIR, sub), exist_ok=True)\n",
    "    os.makedirs(os.path.join(MEL_DIR, sub), exist_ok=True)\n",
    "    os.makedirs(os.path.join(EMB_DIR, sub), exist_ok=True)\n",
    "\n",
    "print(f\"Prepared base dirs and {len(subdirs)} nested subfolders under DEN_DIR and EMB_DIR.\")\n",
    "\n",
    "labels    = sorted(meta['primary_label'].unique())\n",
    "\n",
    "den_manifest = []\n",
    "mel_manifest = []\n",
    "print(f\"Processing {len(meta)} files ({SAMPLE_FRAC*100:.0f}% of dataset)\")\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1f634-bd84-4c1c-94ce-8a8e34fdb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(record):\n",
    "    fname         = record['filename']\n",
    "    primary_label = record['primary_label']\n",
    "    src_fp        = os.path.join(AUDIO_DIR, fname)\n",
    "\n",
    "    # load + mono\n",
    "    y, sr = sf.read(src_fp, dtype='float32')\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "\n",
    "    # resample if needed\n",
    "    if sr != PANNS_SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR)\n",
    "        sr = PANNS_SR\n",
    "\n",
    "    base      = os.path.splitext(os.path.basename(fname))[0]\n",
    "    n_chunks  = math.ceil(len(y) / CHUNK_SAMPLES)\n",
    "\n",
    "    for ci in range(n_chunks):\n",
    "        seg = y[ci*CHUNK_SAMPLES:(ci+1)*CHUNK_SAMPLES]\n",
    "        if len(seg) < CHUNK_SAMPLES:\n",
    "            seg = np.pad(seg, (0, CHUNK_SAMPLES - len(seg)), mode='constant')\n",
    "\n",
    "        # denoise\n",
    "        den = nr.reduce_noise(y=seg, sr=sr, stationary=False)\n",
    "        den = den / (np.max(np.abs(den)) + 1e-9)\n",
    "\n",
    "        chunk_id = f\"{base}_chk{ci}\"\n",
    "\n",
    "        # ── WRITE DENOISED OGG ───────────────────────────────────────\n",
    "        rel_audio_path = f\"/{primary_label}/{chunk_id}.ogg\"\n",
    "        out_audio = os.path.join(DEN_DIR, primary_label, chunk_id + '.ogg')\n",
    "        sf.write(out_audio, den, sr, format='OGG', subtype='VORBIS')\n",
    "        den_manifest.append({\n",
    "            'chunk_id':     chunk_id,\n",
    "            'audio_path':   rel_audio_path,\n",
    "            'primary_label': primary_label\n",
    "        })\n",
    "\n",
    "        # ── COMPUTE + WRITE MEL ──────────────────────────────────────\n",
    "        mel = calculate_mel_spectrogram(den, sr)\n",
    "        rel_mel_path = f\"/{primary_label}/{chunk_id}.npz\"\n",
    "        out_mel = os.path.join(MEL_DIR, primary_label, chunk_id + '.npz')\n",
    "        np.savez_compressed(out_mel,\n",
    "                            mel=mel.astype(np.float16),\n",
    "                            primary_label=primary_label)\n",
    "        mel_manifest.append({\n",
    "            'chunk_id':      chunk_id,\n",
    "            'mel_path':      rel_mel_path,\n",
    "            'primary_label': primary_label\n",
    "        })\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca5f3b-da0e-48a3-978a-b2470f82aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e20884ae8042a4a48a0475ecc0cc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoise & MEL by species:   0%|          | 0/28564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m records = meta[[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mprimary_label\u001b[39m\u001b[33m'\u001b[39m]].to_dict(\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(os.cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDenoise & MEL by species\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "records = meta[['filename','primary_label']].to_dict('records')\n",
    "with ThreadPool(os.cpu_count()) as pool:\n",
    "    for _ in tqdm(pool.imap_unordered(process_record, records),\n",
    "                  total=len(records), desc=\"Denoise & MEL by species\"):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104faf4-fc73-425b-919c-e8d9c3bd245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(den_manifest).to_csv(\n",
    "    os.path.join(DEN_DIR, 'manifest.csv'), index=False\n",
    ")\n",
    "pd.DataFrame(mel_manifest).to_csv(\n",
    "    os.path.join(MEL_DIR, 'manifest.csv'), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d10f6c-d426-4fc2-8e92-b38d9d27a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/jovyan/panns_data/Cnn14_mAP=0.431.pth\n",
      "Using CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3d2b2905b047bdb2433e3db2790b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase 2: embed:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "panns_model = AudioTagging(checkpoint_path=None, device=device)\n",
    "panns_model.model.eval()\n",
    "\n",
    "# 1) Gather all .npz paths under DEN_DIR (skip any directories)\n",
    "den_paths = []\n",
    "for root, _, files in os.walk(DEN_DIR):\n",
    "    for fname in files:\n",
    "        if fname.endswith('.ogg'):\n",
    "            den_paths.append(os.path.join(root, fname))\n",
    "den_paths.sort()\n",
    "\n",
    "BATCH_SIZE  = 512\n",
    "TARGET_SR = PANNS_SR\n",
    "emb_manifest = []\n",
    "for i in tqdm(range(0, len(den_paths), BATCH_SIZE), desc=\"Phase 2: embed\"):\n",
    "    batch = den_paths[i : i + BATCH_SIZE]\n",
    "    waves, rels, labels = [], [], []\n",
    "\n",
    "    # Load & optionally resample\n",
    "    for full_path in batch:\n",
    "        y, sr = sf.read(full_path, dtype='float32')\n",
    "        if sr != TARGET_SR:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=TARGET_SR)\n",
    "        waves.append(y)\n",
    "\n",
    "        rel = os.path.relpath(full_path, DEN_DIR)  # e.g. \"smbani/XC461360_chk0.ogg\"\n",
    "        rels.append(rel)\n",
    "        labels.append(rel.split(os.sep)[0])       # primary_label\n",
    "\n",
    "    # Batch to GPU\n",
    "    waves_t = torch.from_numpy(np.stack(waves)).to(device)  # [B, samples]\n",
    "\n",
    "    # PANNs inference\n",
    "    with torch.no_grad():\n",
    "        _, emb_out = panns_model.inference(waves_t)\n",
    "\n",
    "    # Convert to NumPy array if needed\n",
    "    if isinstance(emb_out, torch.Tensor):\n",
    "        embs_np = emb_out.cpu().numpy()\n",
    "    else:\n",
    "        embs_np = emb_out  # already a NumPy array\n",
    "\n",
    "    # Save embeddings + record manifest\n",
    "    for rel, emb_arr, lbl in zip(rels, embs_np, labels):\n",
    "        subdir, fname = os.path.split(rel)\n",
    "        chunk_id      = os.path.splitext(fname)[0]\n",
    "        emb_name      = f\"{chunk_id}_emb.npz\"\n",
    "        out_dir       = os.path.join(EMB_DIR, subdir)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path      = os.path.join(out_dir, emb_name)\n",
    "\n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            embedding=emb_arr.astype(np.float32),\n",
    "            primary_label=lbl\n",
    "        )\n",
    "\n",
    "        emb_manifest.append({\n",
    "            'chunk_id':      chunk_id,\n",
    "            'emb_path':      f\"/{subdir}/{emb_name}\",\n",
    "            'primary_label': lbl\n",
    "        })\n",
    "\n",
    "pd.DataFrame(emb_manifest).to_csv(os.path.join(EMB_DIR, 'manifest.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdcce1d-4fa3-4ce2-8dc3-0396b2f31c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/features.zip'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# will create /home/jovyan/features.zip containing everything under /home/jovyan/Features\n",
    "shutil.make_archive('/home/jovyan/features', 'zip', '/home/jovyan/Features')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
