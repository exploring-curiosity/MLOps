{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1035966-8a7e-4fe8-98b1-0348e213826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import torch\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.auto import tqdm\n",
    "from scipy.signal import butter, filtfilt\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "DATA_ROOT        = '/home/jovyan/Data/birdclef-2025'\n",
    "AUDIO_DIR        = os.path.join(DATA_ROOT, 'train_audio')\n",
    "CSV_PATH         = os.path.join(DATA_ROOT, 'train.csv')\n",
    "\n",
    "DEN_DIR          = '/home/jovyan/Features/denoised'\n",
    "MEL_DIR          = '/home/jovyan/Features/mel'\n",
    "EMB_DIR          = '/home/jovyan/Features/embeddings'\n",
    "MEL_AUG_DIR      = '/home/jovyan/Features/mel_aug'\n",
    "\n",
    "for d in (DEN_DIR, MEL_DIR, EMB_DIR, MEL_AUG_DIR):\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "PANNS_SR         = 32000\n",
    "CHUNK_SEC        = 10\n",
    "CHUNK_SAMPLES    = PANNS_SR * CHUNK_SEC\n",
    "\n",
    "N_FFT            = 2048\n",
    "HOP_LENGTH       = 1024\n",
    "N_MELS           = 64\n",
    "\n",
    "SAMPLE_FRAC      = 1.0\n",
    "\n",
    "# PANNs & augmentation params\n",
    "BIRD_CLASS_IDXS  = [\n",
    "    14,22,27,28,33,34,35,37,40,\n",
    "    72,73,80,84,\n",
    "    *range(98,107),108,\n",
    "    *range(111,122),\n",
    "    *range(126,133),\n",
    "    137,361,442,503\n",
    "]\n",
    "THRESH           = 0.5\n",
    "\n",
    "# band‑pass augmentation constants\n",
    "LOWCUT           = 2000     # Hz\n",
    "HIGHCUT          = 8000     # Hz\n",
    "BAND_ALPHA       = 2.0      # boost factor\n",
    "WINDOW_SEC      = 1.0\n",
    "WIN_SAMPLES     = int(WINDOW_SEC * PANNS_SR)\n",
    "\n",
    "PROP_DECREASE    = 0.9\n",
    "STATIONARY_NOISE = False\n",
    "\n",
    "CHUNKS_PER_BATCH = 64 \n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f325b11-e71b-460a-acc6-7f986e50df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mel_spectrogram(wave, sr=PANNS_SR):\n",
    "    m = librosa.feature.melspectrogram(\n",
    "        y=wave, sr=sr,\n",
    "        n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS\n",
    "    )\n",
    "    return librosa.power_to_db(m, ref=np.max)\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def augment_waveform_with_filter(wave, mask, sr,\n",
    "                                 lowcut=LOWCUT, highcut=HIGHCUT,\n",
    "                                 alpha=BAND_ALPHA):\n",
    "    \"\"\"\n",
    "    For each 1s window where mask==True, add a boosted\n",
    "    band‑pass filtered copy of wave in [lowcut,highcut].\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, sr, order=4)\n",
    "    wave_band = filtfilt(b, a, wave)\n",
    "    wave_aug  = wave.copy()\n",
    "    win_len   = int(WINDOW_SEC * sr)\n",
    "    for i, m in enumerate(mask):\n",
    "        if m:\n",
    "            start = i * win_len\n",
    "            end   = min((i+1) * win_len, len(wave))\n",
    "            wave_aug[start:end] = wave[start:end] + alpha * wave_band[start:end]\n",
    "    peak = np.max(np.abs(wave_aug))\n",
    "    if peak > 1.0:\n",
    "        wave_aug /= peak\n",
    "    return wave_aug\n",
    "\n",
    "def get_per_second_embeddings_and_mask(wave, model, device):\n",
    "    \"\"\"\n",
    "    Returns per-second embeddings and a bird_presence mask.\n",
    "    \"\"\"\n",
    "    win_len   = PANNS_SR\n",
    "    n_windows = math.ceil(len(wave) / win_len)\n",
    "    embs, mask = [], []\n",
    "    for w in range(n_windows):\n",
    "        seg = wave[w*win_len:(w+1)*win_len]\n",
    "        if len(seg) < win_len:\n",
    "            seg = np.pad(seg, (0, win_len-len(seg)), mode='constant')\n",
    "        inp = torch.from_numpy(seg).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            clipwise, emb = model.inference(inp)\n",
    "        probs  = clipwise.squeeze(0).cpu().numpy() if torch.is_tensor(clipwise) else np.squeeze(clipwise,0)\n",
    "        emb_np = emb.squeeze(0).cpu().numpy()      if torch.is_tensor(emb)      else np.squeeze(emb,0)\n",
    "        embs.append(emb_np)\n",
    "        score = probs[BIRD_CLASS_IDXS].max()\n",
    "        present = score > THRESH or int(np.argmax(probs)) in BIRD_CLASS_IDXS\n",
    "        mask.append(present)\n",
    "    return np.stack(embs), np.array(mask, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78bc5901-90f5-42e6-b5a5-05da6eb3feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── READ & SAMPLE METADATA ───────────────────────────────────────────────────\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "sampled = []\n",
    "for label, grp in meta.groupby('primary_label'):\n",
    "    n = max(1, int(len(grp) * SAMPLE_FRAC))\n",
    "    sampled.append(grp.sample(n=n, random_state=42))\n",
    "meta = pd.concat(sampled, ignore_index=True)\n",
    "\n",
    "# ─── CREATE SUBFOLDERS ────────────────────────────────────────────────────────\n",
    "subdirs = {os.path.dirname(f) for f in meta['filename']}\n",
    "for sub in subdirs:\n",
    "    if sub:\n",
    "        for base in (DEN_DIR, MEL_DIR, EMB_DIR, MEL_AUG_DIR):\n",
    "            os.makedirs(os.path.join(base, sub), exist_ok=True)\n",
    "\n",
    "# ─── PHASE 1: DENOISE & MEL ────────────────────────────────────────────────────\n",
    "den_manifest = []\n",
    "mel_manifest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1f634-bd84-4c1c-94ce-8a8e34fdb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phase1(record):\n",
    "    fname = record['filename']; label = record['primary_label']\n",
    "    src_fp = os.path.join(AUDIO_DIR, fname)\n",
    "    y, sr = sf.read(src_fp, dtype='float32')\n",
    "    if y.ndim>1: y=y.mean(1)\n",
    "    if sr!=PANNS_SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR); sr=PANNS_SR\n",
    "\n",
    "    base = os.path.splitext(os.path.basename(fname))[0]\n",
    "    n_chunks = math.ceil(len(y)/CHUNK_SAMPLES)\n",
    "    for ci in range(n_chunks):\n",
    "        seg = y[ci*CHUNK_SAMPLES:(ci+1)*CHUNK_SAMPLES]\n",
    "        if len(seg)<CHUNK_SAMPLES:\n",
    "            seg = np.pad(seg,(0,CHUNK_SAMPLES-len(seg)),'constant')\n",
    "        # denoise\n",
    "        den = nr.reduce_noise(y=seg, sr=sr, stationary=False, prop_decrease=PROP_DECREASE)\n",
    "        den /= (np.max(np.abs(den))+1e-9)\n",
    "\n",
    "        chunk_id = f\"{base}_chk{ci}\"\n",
    "        # save denoised audio\n",
    "        rel_audio = f\"/{label}/{chunk_id}.ogg\"\n",
    "        sf.write(os.path.join(DEN_DIR,label,chunk_id+'.ogg'), den, sr, format='OGG', subtype='VORBIS')\n",
    "        den_manifest.append({'chunk_id':chunk_id,'audio_path':rel_audio,'primary_label':label})\n",
    "        # save mel\n",
    "        mel = calculate_mel_spectrogram(den, sr)\n",
    "        rel_mel = f\"/{label}/{chunk_id}.npz\"\n",
    "        np.savez_compressed(os.path.join(MEL_DIR,label,chunk_id+'.npz'),\n",
    "                            mel=mel.astype(np.float16), primary_label=label)\n",
    "        mel_manifest.append({'chunk_id':chunk_id,'mel_path':rel_mel,'primary_label':label})\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca5f3b-da0e-48a3-978a-b2470f82aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e20884ae8042a4a48a0475ecc0cc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Denoise & MEL by species:   0%|          | 0/28564 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_items\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m records = meta[[\u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mprimary_label\u001b[39m\u001b[33m'\u001b[39m]].to_dict(\u001b[33m'\u001b[39m\u001b[33mrecords\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPool(os.cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_record\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDenoise & MEL by species\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[39m, in \u001b[36mtqdm_notebook.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    249\u001b[39m     it = \u001b[38;5;28msuper\u001b[39m().\u001b[34m__iter__\u001b[39m()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    353\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "records = meta[['filename','primary_label']].to_dict('records')\n",
    "with ThreadPool(os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap_unordered(process_phase1, records),\n",
    "              total=len(records), desc=\"Phase 1: denoise & mel\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104faf4-fc73-425b-919c-e8d9c3bd245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(den_manifest).to_csv(os.path.join(DEN_DIR,'manifest.csv'), index=False)\n",
    "pd.DataFrame(mel_manifest).to_csv(os.path.join(MEL_DIR,'manifest.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d10f6c-d426-4fc2-8e92-b38d9d27a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/jovyan/panns_data/Cnn14_mAP=0.431.pth\n",
      "Using CPU.\n"
     ]
    }
   ],
   "source": [
    "panns = AudioTagging(checkpoint_path=None, device=device)\n",
    "panns.model.eval()\n",
    "\n",
    "emb_manifest     = []\n",
    "mel_aug_manifest = []\n",
    "\n",
    "# Gather denoised audio paths]\n",
    "den_paths = sorted([\n",
    "    os.path.join(root,f)\n",
    "    for root,_,files in os.walk(DEN_DIR)\n",
    "    for f in files if f.endswith('.ogg')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7491f3ae-7e80-4c4b-b2ef-ee867f55eded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a268ea0fca47ad8a1ca67b8e9cfce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase1: multi‑chunk batches:   0%|          | 0/1803 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(0, len(den_paths), CHUNKS_PER_BATCH), desc=\"Phase1: multi‑chunk batches\"):\n",
    "    batch_files = den_paths[i:i+CHUNKS_PER_BATCH]\n",
    "    all_segs, mapping = [], []\n",
    "    # 1) Load + split into 1s windows\n",
    "    for fp in batch_files:\n",
    "        y, sr = sf.read(fp, dtype='float32')\n",
    "        if sr != PANNS_SR:\n",
    "            y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR)\n",
    "        n_win = math.ceil(len(y) / WIN_SAMPLES)\n",
    "        for w in range(n_win):\n",
    "            seg = y[w*WIN_SAMPLES:(w+1)*WIN_SAMPLES]\n",
    "            if len(seg) < WIN_SAMPLES:\n",
    "                seg = np.pad(seg, (0, WIN_SAMPLES-len(seg)), mode='constant')\n",
    "            all_segs.append(seg)\n",
    "            mapping.append((fp, w))\n",
    "\n",
    "    # 2) Batch‑infer all windows at once\n",
    "    segs_t = torch.from_numpy(np.stack(all_segs)).to(device)\n",
    "    with torch.no_grad():\n",
    "        clipwise_all, emb_all = panns.inference(segs_t)\n",
    "\n",
    "    # handle Tensor vs ndarray\n",
    "    if isinstance(clipwise_all, torch.Tensor):\n",
    "        probs = clipwise_all.cpu().numpy()\n",
    "    else:\n",
    "        probs = clipwise_all\n",
    "    if isinstance(emb_all, torch.Tensor):\n",
    "        embs = emb_all.cpu().numpy()\n",
    "    else:\n",
    "        embs = emb_all\n",
    "\n",
    "    # 3) Scatter back to files\n",
    "    by_file = {}\n",
    "    for (fp, w), p_arr, e_arr in zip(mapping, probs, embs):\n",
    "        if fp not in by_file:\n",
    "            by_file[fp] = {'embs': [], 'probs': []}\n",
    "        by_file[fp]['embs'].append(e_arr)\n",
    "        by_file[fp]['probs'].append(p_arr)\n",
    "\n",
    "    # 4) Save per‑file embeddings + mask\n",
    "    for fp, data in by_file.items():\n",
    "        embs_np  = np.stack(data['embs'])\n",
    "        probs_np = np.stack(data['probs'])\n",
    "        mask     = (probs_np[:, BIRD_CLASS_IDXS].max(axis=1) > THRESH) \\\n",
    "                   | np.isin(probs_np.argmax(axis=1), BIRD_CLASS_IDXS)\n",
    "        rel      = os.path.relpath(fp, DEN_DIR)\n",
    "        sub, fn  = os.path.split(rel)\n",
    "        cid      = os.path.splitext(fn)[0]\n",
    "        out_dir  = os.path.join(EMB_DIR, sub)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path = os.path.join(out_dir, f\"{cid}_emb.npz\")\n",
    "\n",
    "        np.savez_compressed(\n",
    "            out_path,\n",
    "            embedding=embs_np.astype(np.float32),\n",
    "            mask=mask,\n",
    "            primary_label=sub\n",
    "        )\n",
    "\n",
    "        emb_manifest.append({\n",
    "            'chunk_id':      cid,\n",
    "            'emb_path':      f\"/{sub}/{cid}_emb.npz\",\n",
    "            'primary_label': sub\n",
    "        })\n",
    "\n",
    "pd.DataFrame(emb_manifest).to_csv(\n",
    "    os.path.join(EMB_DIR, 'manifest.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8e37934-607f-457b-909a-4deee5e8468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_map = {}\n",
    "for root, _, files in os.walk(EMB_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith('_emb.npz'):\n",
    "            data = np.load(os.path.join(root, f))\n",
    "            mask = data['mask']\n",
    "            rel = os.path.relpath(os.path.join(root, f), EMB_DIR)\n",
    "            sub, fname = os.path.split(rel)\n",
    "            chunk_id = fname.replace('_emb.npz','')\n",
    "            den_path = os.path.join(DEN_DIR, sub, chunk_id + '.ogg')\n",
    "            mask_map[den_path] = mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "837976c4-40eb-4bb0-bddd-7282c3fce9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "den_paths = list(mask_map.keys())\n",
    "\n",
    "def process_part2(full_path):\n",
    "    # 1) Load denoised audio\n",
    "    y, sr = sf.read(full_path, dtype='float32')\n",
    "    if sr != PANNS_SR:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR)\n",
    "        sr = PANNS_SR\n",
    "\n",
    "    # 2) Get mask\n",
    "    mask = mask_map[full_path]\n",
    "\n",
    "    # 3) Augment on CPU\n",
    "    y_aug = augment_waveform_with_filter(y, mask, sr)\n",
    "\n",
    "    # 4) Re-denoise on CPU\n",
    "    y_aug_dn = nr.reduce_noise(\n",
    "        y=y_aug, sr=sr,\n",
    "        stationary=STATIONARY_NOISE,\n",
    "        prop_decrease=PROP_DECREASE\n",
    "    )\n",
    "\n",
    "    # 5) Compute MEL\n",
    "    mel_aug = calculate_mel_spectrogram(y_aug_dn, sr)\n",
    "\n",
    "    # 6) Save augmented MEL\n",
    "    rel = os.path.relpath(full_path, DEN_DIR)\n",
    "    sub, fname = os.path.split(rel)\n",
    "    chunk_id = os.path.splitext(fname)[0]\n",
    "    out_dir  = os.path.join(MEL_AUG_DIR, sub)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    np.savez_compressed(\n",
    "        os.path.join(out_dir, chunk_id + '.npz'),\n",
    "        mel=mel_aug.astype(np.float16),\n",
    "        primary_label=sub\n",
    "    )\n",
    "    mel_aug_manifest.append({\n",
    "        'chunk_id': chunk_id,\n",
    "        'mel_aug_path': f\"/{sub}/{chunk_id}.npz\",\n",
    "        'primary_label': sub\n",
    "    })\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1841f69d-b2ee-45b2-9c79-82294ea2a5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ce733b54d64ddd88c354395617ecde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase 2: augment+denoise+mel:   0%|          | 0/115357 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "with ThreadPool(os.cpu_count()) as pool:\n",
    "    list(tqdm(pool.imap_unordered(process_part2, den_paths),\n",
    "              total=len(den_paths),\n",
    "              desc=\"Phase 2: augment+denoise+mel\"))\n",
    "\n",
    "pd.DataFrame(mel_aug_manifest).to_csv(\n",
    "    os.path.join(MEL_AUG_DIR, 'manifest.csv'),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4bdcce1d-4fa3-4ce2-8dc3-0396b2f31c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/features.zip'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# will create /home/jovyan/features.zip containing everything under /home/jovyan/Features\n",
    "shutil.make_archive('/home/jovyan/features', 'zip', '/home/jovyan/Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0095d1a-a341-4e4f-9bb2-1700f56a103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ── CONFIG ─────────────────────────────────────────────────────────────────────\n",
    "BASE_FEAT    = '/home/jovyan/Features'\n",
    "DEN_MAN      = os.path.join(BASE_FEAT, 'denoised',   'manifest.csv')\n",
    "MEL_MAN      = os.path.join(BASE_FEAT, 'mel',        'manifest.csv')\n",
    "EMB_MAN      = os.path.join(BASE_FEAT, 'embeddings', 'manifest.csv')\n",
    "AUG_MAN      = os.path.join(BASE_FEAT, 'mel_aug',    'manifest.csv')\n",
    "OUT_DIR      = BASE_FEAT\n",
    "\n",
    "# ── 1) LOAD & MERGE ──────────────────────────────────────────────────────────\n",
    "den_df = pd.read_csv(DEN_MAN)[['chunk_id','audio_path','primary_label']]\n",
    "mel_df = pd.read_csv(MEL_MAN)[['chunk_id','mel_path']]\n",
    "emb_df = pd.read_csv(EMB_MAN)[['chunk_id','emb_path']]\n",
    "aug_df = pd.read_csv(AUG_MAN)[['chunk_id','mel_aug_path']]\n",
    "\n",
    "df = (den_df\n",
    "      .merge(mel_df, on='chunk_id')\n",
    "      .merge(emb_df, on='chunk_id')\n",
    "      .merge(aug_df, on='chunk_id'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34ea8146-ee2d-46ff-924b-94ef72bf3dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recording_id'] = df['chunk_id'].str.split('_chk').str[0]\n",
    "unique_recs = df[['recording_id','primary_label']].drop_duplicates()\n",
    "\n",
    "# first pick one recording per species\n",
    "rng = np.random.default_rng(42)\n",
    "seed_per_species = unique_recs.groupby('primary_label')['recording_id'] \\\n",
    "                              .apply(lambda ids: rng.choice(ids.values, 1)[0]) \\\n",
    "                              .tolist()\n",
    "\n",
    "all_recs = unique_recs['recording_id'].tolist()\n",
    "remaining = [r for r in all_recs if r not in seed_per_species]\n",
    "\n",
    "n_total = len(all_recs)\n",
    "n_train_target = int(round(0.70 * n_total))\n",
    "n_additional = max(0, n_train_target - len(seed_per_species))\n",
    "\n",
    "addl_train = rng.choice(remaining, size=n_additional, replace=False).tolist()\n",
    "train_recs = set(seed_per_species + addl_train)\n",
    "\n",
    "remaining_after_train = [r for r in all_recs if r not in train_recs]\n",
    "n_test = int(round(0.10 * n_total))\n",
    "test_recs = set(rng.choice(remaining_after_train, size=n_test, replace=False).tolist())\n",
    "\n",
    "val_recs = set(r for r in all_recs if r not in train_recs and r not in test_recs)\n",
    "\n",
    "df_train = df[df['recording_id'].isin(train_recs)].reset_index(drop=True)\n",
    "df_test  = df[df['recording_id'].isin(test_recs)].reset_index(drop=True)\n",
    "df_val   = df[df['recording_id'].isin(val_recs)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c41759a-a340-4565-b2aa-e824cf363dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 82976 chunks, 206 species\n",
      "Test: 11022 chunks, 173 species\n",
      "Val: 22733 chunks, 181 species\n",
      "\n",
      "Recordings → total 28564, train 19990, test 2856, val 5706\n"
     ]
    }
   ],
   "source": [
    "for name, split_df in [('train', df_train), ('test', df_test), ('val', df_val)]:\n",
    "    out = split_df.drop(columns=['recording_id'])\n",
    "    out.to_csv(os.path.join(OUT_DIR, f'manifest_{name}.csv'), index=False)\n",
    "    print(f\"{name.capitalize()}: {len(out)} chunks, {out['primary_label'].nunique()} species\")\n",
    "    \n",
    "print(f\"\\nRecordings → total {n_total}, train {len(train_recs)}, test {len(test_recs)}, val {len(val_recs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a628cffe-1e0a-4f06-9656-8562a87590d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled train manifest: 108451 chunks\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(OUT_DIR, 'manifest_train.csv'))\n",
    "train_df['recording_id'] = train_df['chunk_id'].str.split('_chk').str[0]\n",
    "\n",
    "# group recordings by species\n",
    "groups = (\n",
    "    train_df[['recording_id','primary_label']]\n",
    "    .drop_duplicates()\n",
    "    .groupby('primary_label')['recording_id']\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# target = median number of recordings per species\n",
    "target = int(np.median([len(v) for v in groups.values()]))\n",
    "\n",
    "oversampled_recs = []\n",
    "for sp, recs in groups.items():\n",
    "    oversampled_recs.extend(recs)\n",
    "    n_extra = max(0, target - len(recs))\n",
    "    if n_extra:\n",
    "        extras = rng.choice(recs, size=n_extra, replace=True)\n",
    "        oversampled_recs.extend(extras.tolist())\n",
    "\n",
    "# assemble oversampled train manifest\n",
    "frames = []\n",
    "for rec in oversampled_recs:\n",
    "    frames.append(train_df[train_df['recording_id'] == rec])\n",
    "oversampled_df = pd.concat(frames, ignore_index=True)\n",
    "oversampled_df = oversampled_df.drop(columns=['recording_id'])\n",
    "\n",
    "out_path = os.path.join(OUT_DIR, 'manifest_train_oversampled.csv')\n",
    "oversampled_df.to_csv(out_path, index=False)\n",
    "print(f\"Oversampled train manifest: {len(oversampled_df)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e792bf6-6fed-4a04-bf85-717264268a86",
   "metadata": {},
   "source": [
    "### Manually Renamed manifest_train_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a87f0d2-d9d7-4aba-9e29-9936024d103f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recordings per species (counts):\n",
      "  grekis: total=990, train=695, test=95, val=201\n",
      "  compau: total=808, train=561, test=77, val=170\n",
      "  trokin: total=787, train=531, test=86, val=170\n",
      "  roahaw: total=709, train=486, test=71, val=152\n",
      "  banana: total=610, train=427, test=53, val=130\n",
      "  whtdov: total=572, train=407, test=57, val=109\n",
      "  socfly1: total=543, train=368, test=50, val=126\n",
      "  yeofly1: total=525, train=372, test=55, val=98\n",
      "  bobfly1: total=514, train=368, test=47, val=101\n",
      "  wbwwre1: total=499, train=360, test=44, val=95\n",
      "  soulap1: total=487, train=330, test=50, val=107\n",
      "  sobtyr1: total=478, train=350, test=38, val=92\n",
      "  trsowl: total=470, train=335, test=49, val=87\n",
      "  laufal1: total=467, train=319, test=48, val=100\n",
      "  strcuc1: total=431, train=296, test=46, val=89\n",
      "  bbwduc: total=424, train=287, test=45, val=92\n",
      "  saffin: total=419, train=289, test=49, val=82\n",
      "  amekes: total=409, train=273, test=41, val=95\n",
      "  tropar: total=397, train=282, test=42, val=73\n",
      "  compot1: total=383, train=260, test=36, val=88\n",
      "  blbgra1: total=380, train=268, test=37, val=75\n",
      "  bubwre1: total=379, train=266, test=35, val=80\n",
      "  strfly1: total=377, train=261, test=30, val=86\n",
      "  gycwor1: total=365, train=264, test=28, val=73\n",
      "  greegr: total=340, train=237, test=32, val=71\n",
      "  linwoo1: total=330, train=222, test=32, val=76\n",
      "  pirfly1: total=324, train=237, test=35, val=55\n",
      "  littin1: total=323, train=239, test=25, val=59\n",
      "  bkmtou1: total=311, train=211, test=34, val=66\n",
      "  yercac1: total=302, train=210, test=34, val=58\n",
      "  butsal1: total=298, train=211, test=36, val=52\n",
      "  smbani: total=287, train=188, test=37, val=62\n",
      "  bugtan: total=280, train=201, test=28, val=51\n",
      "  chbant1: total=270, train=204, test=25, val=41\n",
      "  yebela1: total=267, train=180, test=28, val=59\n",
      "  rutjac1: total=261, train=174, test=32, val=55\n",
      "  cotfly1: total=260, train=175, test=34, val=51\n",
      "  whbman1: total=246, train=174, test=22, val=50\n",
      "  yehcar1: total=238, train=173, test=25, val=40\n",
      "  solsan: total=237, train=176, test=25, val=36\n",
      "  rumfly1: total=236, train=165, test=20, val=51\n",
      "  yecspi2: total=235, train=175, test=21, val=40\n",
      "  blhpar1: total=230, train=164, test=25, val=41\n",
      "  creoro1: total=229, train=163, test=24, val=42\n",
      "  paltan1: total=224, train=149, test=26, val=49\n",
      "  rinkin1: total=222, train=157, test=28, val=37\n",
      "  orcpar: total=218, train=148, test=22, val=48\n",
      "  stbwoo2: total=210, train=147, test=22, val=41\n",
      "  speowl1: total=201, train=152, test=20, val=29\n",
      "  yebfly1: total=188, train=125, test=18, val=45\n",
      "  plbwoo1: total=186, train=130, test=16, val=40\n",
      "  yebsee1: total=185, train=127, test=19, val=39\n",
      "  bkcdon: total=176, train=126, test=16, val=34\n",
      "  strher: total=169, train=116, test=14, val=39\n",
      "  y00678: total=169, train=121, test=12, val=36\n",
      "  babwar: total=167, train=111, test=21, val=35\n",
      "  gybmar: total=164, train=117, test=20, val=27\n",
      "  strowl1: total=164, train=110, test=17, val=37\n",
      "  cocwoo1: total=162, train=112, test=19, val=31\n",
      "  secfly1: total=158, train=112, test=13, val=33\n",
      "  thbeup1: total=153, train=112, test=19, val=22\n",
      "  pavpig2: total=151, train=102, test=20, val=32\n",
      "  baymac: total=149, train=108, test=12, val=29\n",
      "  rtlhum: total=148, train=100, test=15, val=33\n",
      "  purgal2: total=147, train=102, test=14, val=31\n",
      "  colcha1: total=145, train=96, test=13, val=36\n",
      "  crcwoo1: total=144, train=104, test=12, val=28\n",
      "  ywcpar: total=142, train=99, test=18, val=25\n",
      "  chfmac1: total=139, train=87, test=19, val=33\n",
      "  rugdov: total=138, train=92, test=12, val=34\n",
      "  gohman1: total=134, train=95, test=11, val=28\n",
      "  watjac1: total=133, train=89, test=14, val=30\n",
      "  grnkin: total=132, train=95, test=16, val=21\n",
      "  greani1: total=127, train=83, test=17, val=27\n",
      "  whfant1: total=126, train=96, test=10, val=20\n",
      "  cattyr: total=114, train=84, test=11, val=19\n",
      "  srwswa1: total=112, train=79, test=9, val=24\n",
      "  blbwre1: total=110, train=84, test=9, val=17\n",
      "  greibi1: total=109, train=85, test=10, val=17\n",
      "  mastit1: total=109, train=78, test=15, val=16\n",
      "  leagre: total=108, train=76, test=12, val=20\n",
      "  blcjay1: total=108, train=70, test=18, val=20\n",
      "  41663: total=108, train=73, test=9, val=26\n",
      "  snoegr: total=108, train=76, test=13, val=19\n",
      "  grbhaw1: total=107, train=68, test=13, val=26\n",
      "  blcant4: total=105, train=81, test=8, val=19\n",
      "  eardov1: total=105, train=72, test=13, val=20\n",
      "  whbant1: total=104, train=74, test=12, val=18\n",
      "  rufmot1: total=97, train=60, test=12, val=25\n",
      "  thlsch3: total=97, train=67, test=10, val=20\n",
      "  yectyr1: total=97, train=68, test=12, val=17\n",
      "  cargra1: total=94, train=70, test=9, val=15\n",
      "  bicwre1: total=93, train=73, test=10, val=10\n",
      "  anhing: total=91, train=67, test=9, val=15\n",
      "  recwoo1: total=90, train=58, test=13, val=19\n",
      "  shtfly1: total=90, train=62, test=11, val=17\n",
      "  neocor: total=90, train=66, test=8, val=16\n",
      "  ragmac1: total=89, train=60, test=9, val=20\n",
      "  amakin1: total=89, train=58, test=14, val=24\n",
      "  grasal4: total=85, train=64, test=9, val=12\n",
      "  gretin1: total=83, train=58, test=10, val=21\n",
      "  65448: total=82, train=58, test=6, val=21\n",
      "  spepar1: total=81, train=58, test=7, val=17\n",
      "  fotfly: total=80, train=59, test=7, val=14\n",
      "  ruther1: total=80, train=62, test=6, val=12\n",
      "  yehbla2: total=79, train=63, test=4, val=12\n",
      "  cregua1: total=77, train=58, test=12, val=7\n",
      "  21211: total=76, train=58, test=7, val=13\n",
      "  whttro1: total=75, train=58, test=9, val=15\n",
      "  brtpar1: total=74, train=58, test=10, val=11\n",
      "  blkvul: total=70, train=58, test=8, val=16\n",
      "  rubsee1: total=70, train=58, test=2, val=10\n",
      "  verfly: total=69, train=58, test=4, val=10\n",
      "  cinbec1: total=67, train=58, test=7, val=11\n",
      "  grepot1: total=67, train=58, test=5, val=17\n",
      "  labter1: total=67, train=58, test=5, val=16\n",
      "  palhor2: total=66, train=58, test=8, val=12\n",
      "  yelori1: total=60, train=58, test=1, val=14\n",
      "  517119: total=58, train=58, test=3, val=11\n",
      "  colara1: total=57, train=58, test=3, val=13\n",
      "  crbtan1: total=56, train=58, test=2, val=12\n",
      "  piepuf1: total=55, train=58, test=4, val=6\n",
      "  rebbla1: total=55, train=58, test=6, val=13\n",
      "  savhaw1: total=54, train=58, test=6, val=8\n",
      "  blchaw1: total=54, train=58, test=6, val=11\n",
      "  22973: total=53, train=58, test=7, val=11\n",
      "  crebob1: total=50, train=58, test=4, val=3\n",
      "  whwswa1: total=50, train=58, test=5, val=14\n",
      "  spbwoo1: total=48, train=58, test=5, val=16\n",
      "  22333: total=47, train=58, test=5, val=7\n",
      "  bucmot3: total=47, train=58, test=8, val=6\n",
      "  22976: total=44, train=58, test=3, val=14\n",
      "  cocher1: total=40, train=58, test=3, val=10\n",
      "  royfly1: total=40, train=58, test=7, val=6\n",
      "  tbsfin1: total=40, train=58, test=3, val=6\n",
      "  bobher1: total=39, train=58, test=2, val=5\n",
      "  plukit1: total=38, train=58, test=4, val=6\n",
      "  olipic1: total=38, train=58, test=4, val=8\n",
      "  rosspo1: total=34, train=58, test=1, val=7\n",
      "  whmtyr1: total=34, train=58, test=2, val=9\n",
      "  52884: total=33, train=58, test=2, val=4\n",
      "  blctit1: total=32, train=58, test=3, val=8\n",
      "  65373: total=32, train=58, test=3, val=7\n",
      "  50186: total=30, train=58, test=2, val=9\n",
      "  ampkin1: total=28, train=58, test=5, val=6\n",
      "  bafibi1: total=27, train=58, test=2, val=1\n",
      "  woosto: total=27, train=58, test=1, val=4\n",
      "  555086: total=25, train=58, test=1, val=3\n",
      "  grysee1: total=25, train=58, test=2, val=8\n",
      "  566513: total=23, train=58, test=1, val=7\n",
      "  65962: total=21, train=58, test=3, val=3\n",
      "  bubcur1: total=20, train=58, test=2, val=5\n",
      "  48124: total=20, train=58, test=3, val=5\n",
      "  piwtyr1: total=19, train=58, test=4, val=3\n",
      "  42007: total=19, train=58, test=1, val=6\n",
      "  715170: total=17, train=58, test=2, val=1\n",
      "  rutpuf1: total=17, train=58, test=0, val=3\n",
      "  65349: total=16, train=58, test=1, val=3\n",
      "  65344: total=16, train=58, test=1, val=3\n",
      "  41970: total=15, train=58, test=3, val=0\n",
      "  shghum1: total=15, train=58, test=0, val=4\n",
      "  67252: total=14, train=58, test=2, val=3\n",
      "  sahpar1: total=14, train=58, test=0, val=3\n",
      "  norscr1: total=14, train=58, test=3, val=3\n",
      "  24322: total=13, train=58, test=1, val=3\n",
      "  turvul: total=11, train=58, test=1, val=0\n",
      "  135045: total=10, train=58, test=1, val=1\n",
      "  1462737: total=7, train=58, test=1, val=1\n",
      "  787625: total=7, train=58, test=0, val=2\n",
      "  65547: total=7, train=58, test=1, val=2\n",
      "  24272: total=6, train=58, test=1, val=0\n",
      "  1564122: total=6, train=58, test=2, val=0\n",
      "  126247: total=6, train=58, test=1, val=2\n",
      "  65336: total=6, train=58, test=0, val=1\n",
      "  555142: total=6, train=58, test=0, val=1\n",
      "  plctan1: total=6, train=58, test=0, val=0\n",
      "  1346504: total=5, train=58, test=2, val=2\n",
      "  476538: total=5, train=58, test=0, val=1\n",
      "  46010: total=5, train=58, test=0, val=1\n",
      "  714022: total=5, train=58, test=0, val=0\n",
      "  963335: total=5, train=58, test=0, val=1\n",
      "  548639: total=5, train=58, test=0, val=2\n",
      "  66893: total=5, train=58, test=0, val=0\n",
      "  523060: total=4, train=58, test=0, val=0\n",
      "  868458: total=4, train=58, test=1, val=2\n",
      "  134933: total=4, train=58, test=0, val=0\n",
      "  1192948: total=4, train=58, test=1, val=0\n",
      "  1194042: total=3, train=58, test=0, val=0\n",
      "  1462711: total=3, train=58, test=0, val=1\n",
      "  24292: total=3, train=58, test=0, val=1\n",
      "  65419: total=3, train=58, test=0, val=0\n",
      "  67082: total=2, train=58, test=0, val=0\n",
      "  66016: total=2, train=58, test=0, val=0\n",
      "  66578: total=2, train=58, test=0, val=0\n",
      "  81930: total=2, train=58, test=0, val=0\n",
      "  476537: total=2, train=58, test=1, val=0\n",
      "  528041: total=2, train=58, test=0, val=0\n",
      "  66531: total=2, train=58, test=0, val=1\n",
      "  41778: total=2, train=58, test=0, val=0\n",
      "  47067: total=2, train=58, test=0, val=0\n",
      "  42087: total=2, train=58, test=0, val=0\n",
      "  42113: total=2, train=58, test=0, val=0\n",
      "  21038: total=2, train=58, test=0, val=0\n",
      "  1139490: total=2, train=58, test=0, val=1\n",
      "  21116: total=2, train=58, test=0, val=0\n",
      "  64862: total=2, train=58, test=0, val=0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRecordings per species (counts):\")\n",
    "for sp, cnt in species_counts.items():\n",
    "    train_count = (rec2sp.loc[list(oversampled_recs)] == sp).sum()\n",
    "    test_count  = (rec2sp.loc[list(test_recs)] == sp).sum()\n",
    "    val_count   = (rec2sp.loc[list(val_recs)] == sp).sum()\n",
    "    print(f\"  {sp}: total={cnt}, \"\n",
    "          f\"train={train_count}, \"\n",
    "          f\"test={test_count}, \"\n",
    "          f\"val={val_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
