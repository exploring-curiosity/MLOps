{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1035966-8a7e-4fe8-98b1-0348e213826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, numpy as np, pandas as pd, soundfile as sf, librosa, noisereduce as nr\n",
    "import torch\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import cpu_count\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.auto import tqdm\n",
    "from panns_inference import AudioTagging\n",
    "\n",
    "# Force spawn for multiprocessing (needed for CUDA-safe workers)\n",
    "mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# ─────── Hyperparameters, Paths & Subfolder Creation ───────\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_ROOT     = '/home/jovyan/Data/birdclef-2025'\n",
    "AUDIO_DIR     = os.path.join(DATA_ROOT, 'train_audio')\n",
    "CSV_PATH      = os.path.join(DATA_ROOT, 'train.csv')\n",
    "\n",
    "DEN_DIR       = '/home/jovyan/Features/denoised'\n",
    "EMB_DIR       = '/home/jovyan/Features/embeddings'\n",
    "os.makedirs(DEN_DIR, exist_ok=True)\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "PANNS_SR      = 32000       # target SR\n",
    "CHUNK_SEC     = 10          # seconds per chunk\n",
    "CHUNK_SAMPLES = PANNS_SR * CHUNK_SEC\n",
    "\n",
    "# Sampling fraction (e.g. 0.1 → 10% of files)\n",
    "SAMPLE_FRAC   = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78bc5901-90f5-42e6-b5a5-05da6eb3feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared base dirs and 178 nested subfolders under DEN_DIR and EMB_DIR.\n",
      "Processing 2856 files (10% of dataset)\n"
     ]
    }
   ],
   "source": [
    "# ─── Read & Sample Metadata ───\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "meta = meta.sample(frac=SAMPLE_FRAC, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# ─── Create matching subfolders in DEN_DIR & EMB_DIR ───\n",
    "subdirs = set(os.path.dirname(f) for f in meta['filename'])\n",
    "for sub in subdirs:\n",
    "    if not sub:\n",
    "        continue\n",
    "    os.makedirs(os.path.join(DEN_DIR, sub), exist_ok=True)\n",
    "    os.makedirs(os.path.join(EMB_DIR, sub), exist_ok=True)\n",
    "\n",
    "print(f\"Prepared base dirs and {len(subdirs)} nested subfolders under DEN_DIR and EMB_DIR.\")\n",
    "\n",
    "# build label→index map\n",
    "labels    = sorted(meta['primary_label'].unique())\n",
    "label2idx = {l:i for i,l in enumerate(labels)}\n",
    "meta['label_idx'] = meta['primary_label'].map(label2idx)\n",
    "\n",
    "print(f\"Processing {len(meta)} files ({SAMPLE_FRAC*100:.0f}% of dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de1f634-bd84-4c1c-94ce-8a8e34fdb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_denoise(row):\n",
    "    fname = row['filename']\n",
    "    lbl   = int(row['label_idx'])\n",
    "    # 1) load + mono\n",
    "    y, sr = sf.read(os.path.join(AUDIO_DIR, fname), dtype='float32')\n",
    "    if y.ndim>1: y = y.mean(axis=1)\n",
    "    # 2) resample\n",
    "    y32 = librosa.resample(y, orig_sr=sr, target_sr=PANNS_SR)\n",
    "    # 3) split into 10s chunks\n",
    "    n_chunks = math.ceil(len(y32)/CHUNK_SAMPLES)\n",
    "    for ci in range(n_chunks):\n",
    "        seg = y32[ci*CHUNK_SAMPLES:(ci+1)*CHUNK_SAMPLES]\n",
    "        if len(seg)<CHUNK_SAMPLES:\n",
    "            seg = np.pad(seg, (0, CHUNK_SAMPLES-len(seg)), mode='constant')\n",
    "        # 4) denoise\n",
    "        den = nr.reduce_noise(y=seg, sr=PANNS_SR,\n",
    "                              prop_decrease=0.9,\n",
    "                              stationary=False)\n",
    "        # 5) save\n",
    "        base    = os.path.splitext(fname)[0] + f'_chk{ci}.npz'\n",
    "        outpath = os.path.join(DEN_DIR, base)\n",
    "        np.savez_compressed(outpath,\n",
    "                            waveform=den.astype(np.float32),\n",
    "                            label=lbl)\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cca5f3b-da0e-48a3-978a-b2470f82aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bff22f6bb97451c9c04483ad6aa4022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase 1 (threads):   0%|          | 0/2856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with ThreadPool(mp.cpu_count()) as pool:\n",
    "    for _ in tqdm(pool.imap_unordered(process_denoise, meta.to_dict('records')),\n",
    "                  total=len(meta),\n",
    "                  desc=\"Phase 1 (threads)\"):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7d10f6c-d426-4fc2-8e92-b38d9d27a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: /home/jovyan/panns_data/Cnn14_mAP=0.431.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/panns_inference/inference.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a860467ec6a493aaf6cceabb9d4c4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Phase 2: embed:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "panns_model = AudioTagging(checkpoint_path=None, device=device)\n",
    "panns_model.model.eval()\n",
    "\n",
    "# 1) Gather all .npz paths under DEN_DIR (skip any directories)\n",
    "den_paths = []\n",
    "for root, _, files in os.walk(DEN_DIR):\n",
    "    for fname in files:\n",
    "        if fname.endswith('.npz'):\n",
    "            den_paths.append(os.path.join(root, fname))\n",
    "den_paths = sorted(den_paths)\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "for i in tqdm(range(0, len(den_paths), BATCH_SIZE), desc=\"Phase 2: embed\"):\n",
    "    batch_paths = den_paths[i:i+BATCH_SIZE]\n",
    "    waves, labels, rels = [], [], []\n",
    "\n",
    "    # 1) Load waveforms & labels\n",
    "    for full_path in batch_paths:\n",
    "        data = np.load(full_path)\n",
    "        waves.append(data['waveform'])\n",
    "        labels.append(int(data['label']))\n",
    "        # record relative path to mirror subfolders\n",
    "        rels.append(os.path.relpath(full_path, DEN_DIR))\n",
    "\n",
    "    # 2) Stack and send to GPU\n",
    "    waves_t = torch.from_numpy(np.stack(waves)).to(device)  # [B, CHUNK_SAMPLES]\n",
    "\n",
    "    # 3) Run inference\n",
    "    with torch.no_grad():\n",
    "        _, emb_out = panns_model.inference(waves_t)\n",
    "\n",
    "    # 4) Convert to NumPy\n",
    "    if isinstance(emb_out, torch.Tensor):\n",
    "        embs_np = emb_out.cpu().numpy()\n",
    "    elif isinstance(emb_out, np.ndarray):\n",
    "        embs_np = emb_out\n",
    "    else:\n",
    "        raise TypeError(f\"Unexpected embedding type: {type(emb_out)}\")\n",
    "\n",
    "    # 5) Save each embedding + label\n",
    "    for rel, emb_arr, lbl in zip(rels, embs_np, labels):\n",
    "        subdir, fname = os.path.split(rel)         # ('smbani', 'XC461360_chk0.npz')\n",
    "        base          = os.path.splitext(fname)[0] + '_emb.npz'\n",
    "        out_dir       = os.path.join(EMB_DIR, subdir)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        out_path      = os.path.join(out_dir, base)\n",
    "        np.savez_compressed(out_path,\n",
    "                            embedding=emb_arr.astype(np.float32),\n",
    "                            label=lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76494341-94ac-463a-b7f3-f3867ff09562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoised chunks: 11236\n",
      "Embedded chunks: 11236\n"
     ]
    }
   ],
   "source": [
    "print(\"Denoised chunks:\", len(den_paths))\n",
    "emb_count = sum(\n",
    "    1 for _root, _dirs, files in os.walk(EMB_DIR) for f in files\n",
    "    if f.endswith('_emb.npz')\n",
    ")\n",
    "print(\"Embedded chunks:\", emb_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bdcce1d-4fa3-4ce2-8dc3-0396b2f31c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/features.zip'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# will create /home/jovyan/features.zip containing everything under /home/jovyan/Features\n",
    "shutil.make_archive('/home/jovyan/features', 'zip', '/home/jovyan/Features')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
